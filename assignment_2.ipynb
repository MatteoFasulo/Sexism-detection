{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WeCeITXoxLf"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "\n",
        "**Keywords**: Sexism Detection, Multi-class Classification, LLMs, Prompting\n",
        "\n",
        "\n",
        "## Group\n",
        "\n",
        "* Luca Babboni - luca.babboni2@studio.unibo.it\n",
        "* Matteo Fasulo - matteo.fasulo@studio.unibo.it\n",
        "* Maksim Omelchenko - maksim.omelchenko@studio.unibo.it\n",
        "* Luca Tedeschini - luca.tedeschini3@studio.unibo.it\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck47wFhrLJnc"
      },
      "source": [
        "## Description\n",
        "\n",
        "This notebook addresses [EDOS Task A](https://github.com/rewire-online/edos) on sexism detection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mtjp0cGLJnc"
      },
      "source": [
        "## Problem definition\n",
        "\n",
        "Given an input text sentence, the task is to label the sentence as sexist or not sexist (binary classification).\n",
        "\n",
        "### Examples:\n",
        "\n",
        "**Text**: *``Schedule a date with her, then don't show up. Then text her \"GOTCHA B___H\".''*\n",
        "\n",
        "**Label**: Sexist\n",
        "\n",
        "**Text**: *``Thatâ€™s completely ridiculous a woman flashing her boobs is not sexual assault in the slightest.''*\n",
        "\n",
        "**Label**: Not sexist\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dqwRZx-QNGX"
      },
      "source": [
        "## Approach\n",
        "\n",
        "We will tackle the binary classification task with LLMs.\n",
        "\n",
        "In particular, we will consider zero and few-shot prompting approaches under the setting of In-Context Learning (ICL) to assess the capability of some popular open-source LLMs on this task. Furthermore, we will use Okapi BM25 score to rank the demonstrations and select the topK best ones to be used as examples inside the prompt.\n",
        "\n",
        "In this way, we will be able to evaluate the performance of the models both by selecting a random set of examples and by selecting the best ones according to the BM25 score. We believe that the latter approach will lead to better results, as it will provide the model with more relevant examples to learn from.\n",
        "\n",
        ">**Note** We are aware that selecting the best subset of examples using BM25 score is a dataset-dependent approach, and it may not generalize well to other datasets. However, we believe that it is a valid approach to evaluate the performance of the models on this specific dataset by varying the set of demonstrations used to prompt the model highlighting the importance of the selection of the examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS3igwXpQcAY"
      },
      "source": [
        "## Execution Instructions\n",
        "\n",
        "We are going to download LLMs from [Huggingface](https://huggingface.co/).\n",
        "\n",
        "Many of these open-source LLMs require you to accept their \"Community License Agreement\" to download them.\n",
        "\n",
        "In summary:\n",
        "\n",
        "- If not already, create an account of Huggingface (~2 mins)\n",
        "- Check a LLM model card page (e.g., [Mistral v3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)) and accept its \"Community License Agreement\".\n",
        "- Go to your account -> Settings -> Access Tokens -> Create new token -> \"Repositories permissions\" -> add the LLM model card you want to use.\n",
        "- Save the token (we'll need it later)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-X8hewlmS9v"
      },
      "source": [
        "### Libraries\n",
        "\n",
        "Assuming that we are working in a Colab environment, we need to update the BitsAndBytes library to the latest version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:04:31.769576Z",
          "iopub.status.busy": "2024-12-28T20:04:31.769394Z",
          "iopub.status.idle": "2024-12-28T20:04:39.032775Z",
          "shell.execute_reply": "2024-12-28T20:04:39.031660Z",
          "shell.execute_reply.started": "2024-12-28T20:04:31.769556Z"
        },
        "id": "GZ1vH4IZmS9w",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install -U bitsandbytes huggingface_hub bm25_pt statsmodels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au5cCyPHmS9x"
      },
      "source": [
        "Since the library requires a restart of the runtime, we need to run the following cell which kills the current runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "execution_failed": "2024-12-28T20:04:39.864Z"
        },
        "id": "jr_Zow9jmS9x",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnZYE__amS9y"
      },
      "source": [
        "At this point, we can just import all the libraries and start working on the assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:04:44.890748Z",
          "iopub.status.busy": "2024-12-28T20:04:44.890443Z",
          "iopub.status.idle": "2024-12-28T20:04:50.069906Z",
          "shell.execute_reply": "2024-12-28T20:04:50.069259Z",
          "shell.execute_reply.started": "2024-12-28T20:04:44.890719Z"
        },
        "id": "mDcr2AG-mS9y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import re\n",
        "import random\n",
        "import gc\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from bm25_pt import BM25\n",
        "\n",
        "import torch\n",
        "\n",
        "import huggingface_hub\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqEsPH_JSxw6"
      },
      "source": [
        "### Huggingface Login\n",
        "\n",
        "Once we have created an account and an access token, we need to login to Huggingface via code. Assuming that we are still inside a notebook environment, we can run the following cell to login."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "c1846a9dcb564594af39e1ec59c55b13",
            "9ce5dcc4380342ea8b86851216f5d28b",
            "e3baddf68f814e8e966639db841c4853",
            "56f90dbf06e94da99646800855b93fdf",
            "b1f8f2767ffd4277a3699eb5dd4768d2",
            "799f3b1e67db4da79fd568ff08f93310",
            "48ae5b8e2db14c719d1ce2df3c68c503",
            "cdb672ccb2cc43a0b92af7867bb9374a",
            "f905c709308c4f538ddb13f65f5c54cb",
            "fc154e11eed946a3b94e8e9d34e37763",
            "ca1b458b63c2469087a48b9671817bcb",
            "29f2d35361a54f3c8ade9658fe393159",
            "1696b5d3810e49e3a6cc561a318f959c",
            "bedd9eea5c1144558a533a6ead9934eb",
            "e4be8f67411045418f54977f3aa26001",
            "573b22dabd8b48c69b2f33412ac12f82",
            "dcbdaf0087974386bd528db17f0e47fb",
            "3d0d2d2f777042a080a1e51a12d97e58",
            "ef89f853f3f54571ac81284dc8d91ee4",
            "7c84e274297d47fcabad476c2bad98a5"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:04:53.197173Z",
          "iopub.status.busy": "2024-12-28T20:04:53.196791Z",
          "iopub.status.idle": "2024-12-28T20:04:53.222328Z",
          "shell.execute_reply": "2024-12-28T20:04:53.221422Z",
          "shell.execute_reply.started": "2024-12-28T20:04:53.197141Z"
        },
        "id": "_uWEUjs0THxP",
        "outputId": "f12aba7a-d9ba-4a95-a8b5-c580e878acd6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "huggingface_hub.notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(69)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As for the assignment 1, we will use a object-oriented approach to manage the models and the datasets by defining the class `SexismDetection`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:04:58.872886Z",
          "iopub.status.busy": "2024-12-28T20:04:58.872565Z",
          "iopub.status.idle": "2024-12-28T20:04:58.896816Z",
          "shell.execute_reply": "2024-12-28T20:04:58.896035Z",
          "shell.execute_reply.started": "2024-12-28T20:04:58.872857Z"
        },
        "id": "cdIbuDKOlfFH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class SexismDetector:\n",
        "    def __init__(self):\n",
        "        self.seed = 69\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.DATA_FOLDER = Path(\"data\")\n",
        "        self.CSV_FOLDER = Path('csv')\n",
        "\n",
        "        # Create data folder if it doesn't exist\n",
        "        if not self.DATA_FOLDER.exists():\n",
        "            self.DATA_FOLDER.mkdir(parents=True)\n",
        "            print(f\"Created folder {self.DATA_FOLDER}.\")\n",
        "\n",
        "        # Create CSV folder if it doesn't exist\n",
        "        if not self.CSV_FOLDER.exists():\n",
        "            self.CSV_FOLDER.mkdir(parents=True)\n",
        "            print(f\"Created folder {self.CSV_FOLDER}.\")\n",
        "\n",
        "        self.clear_cache()\n",
        "\n",
        "    def clear_cache(self) -> None:\n",
        "        \"\"\"\n",
        "        Clears the GPU cache and performs garbage collection.\n",
        "        This method uses PyTorch's `torch.cuda.empty_cache()` to release all unoccupied cached memory\n",
        "        currently held by the caching allocator so that those can be used in other GPU applications.\n",
        "        It also calls Python's garbage collector to free up memory that is no longer in use.\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "    def download_corpus(self, url: str) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Downloads a corpus from the given URL and saves it as a CSV file in the data folder.\n",
        "        Args:\n",
        "            url (str): The URL of the corpus to download.\n",
        "        Returns:\n",
        "            pd.DataFrame: A DataFrame containing the contents of the downloaded CSV file.\n",
        "        Raises:\n",
        "            requests.exceptions.RequestException: If there is an issue with the HTTP request.\n",
        "        \"\"\"\n",
        "        filename = url.split(\"/\")[-1]\n",
        "        if not (self.DATA_FOLDER / filename).exists():\n",
        "            print(f\"Created folder {self.DATA_FOLDER}.\")\n",
        "\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        with open(self.DATA_FOLDER / filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(response.text)\n",
        "\n",
        "        return pd.read_csv(self.DATA_FOLDER / filename, encoding='utf-8')\n",
        "\n",
        "    def load_model(self, model_card: str, with_4_bit: bool = True) -> tuple:\n",
        "        \"\"\"\n",
        "        Loads a pre-trained model and its tokenizer with optional 4-bit quantization.\n",
        "\n",
        "        Args:\n",
        "            model_card (str): The identifier of the pre-trained model to load.\n",
        "            with_4_bit (bool, optional): If True, loads the model with 4-bit quantization.\n",
        "                                         If False, loads the model with 8-bit quantization.\n",
        "                                         Defaults to True.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the loaded model and tokenizer.\n",
        "        \"\"\"\n",
        "        # Clear cache\n",
        "        self.clear_cache()\n",
        "\n",
        "        # Setup the quantization config\n",
        "        quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "        if with_4_bit:\n",
        "            quantization_config = BitsAndBytesConfig(\n",
        "                load_in_4bit=True,\n",
        "                bnb_4bit_quant_type=\"fp4\",\n",
        "                bnb_4bit_compute_dtype=torch.bfloat16\n",
        "            )\n",
        "        # Load tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
        "        # Load the model\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_card, quantization_config=quantization_config)\n",
        "        # Set the model to evaluation (inference) mode\n",
        "        model.eval()\n",
        "\n",
        "        return model, tokenizer\n",
        "\n",
        "    def prepare_prompts(self, texts: pd.Series, prompt_template: list, tokenizer: AutoTokenizer) -> list:\n",
        "        \"\"\"\n",
        "        Prepares prompts by applying a chat template to a series of input texts.\n",
        "\n",
        "        Args:\n",
        "            texts (pd.Series): A pandas Series containing the input texts.\n",
        "            prompt_template (list): A list representing the prompt template with placeholders.\n",
        "            tokenizer (AutoTokenizer): An instance of the AutoTokenizer used to tokenize the prompts.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of tokenized prompts ready for generation.\n",
        "        \"\"\"\n",
        "        # Store the prompts\n",
        "        prompts = []\n",
        "        # Iterate over the input texts\n",
        "        for text in texts:\n",
        "\n",
        "            # Create a deepcopy of the prompt template\n",
        "            prompt_with_text = deepcopy(prompt_template)\n",
        "\n",
        "            # Replace the placeholder with the input text\n",
        "            prompt_with_text[1]['content'] = prompt_with_text[1]['content'].replace('{text}', text)\n",
        "\n",
        "            # Apply the chat template to the input text\n",
        "            full_prompt = tokenizer.apply_chat_template(\n",
        "                prompt_with_text,\n",
        "                tokenize=True,\n",
        "                add_generation_prompt=True,\n",
        "                return_dict=True,\n",
        "                return_tensors=\"pt\")\n",
        "            # Move the full prompt to the device\n",
        "            full_prompt = full_prompt.to(self.device)\n",
        "            # Append the full prompt to the list of prompts\n",
        "            prompts.append(full_prompt)\n",
        "\n",
        "        return prompts\n",
        "\n",
        "    def generate_responses(self, model: AutoModelForCausalLM, tokenizer: AutoTokenizer, prompt_examples: list, max_new_tokens: int = 1000) -> list:\n",
        "        \"\"\"\n",
        "        Generates responses for a list of prompt examples using a specified language model and tokenizer.\n",
        "\n",
        "        Args:\n",
        "            model (AutoModelForCausalLM): The language model to use for generating responses.\n",
        "            tokenizer (AutoTokenizer): The tokenizer associated with the language model.\n",
        "            prompt_examples (list): A list of prompt examples to generate responses for.\n",
        "            max_new_tokens (int, optional): The maximum number of new tokens to generate for each prompt. Defaults to 1000.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of generated responses corresponding to each prompt example.\n",
        "        \"\"\"\n",
        "        answers = []\n",
        "        for prompt in tqdm(prompt_examples):\n",
        "            response = model.generate(**prompt, max_new_tokens=max_new_tokens, pad_token_id=tokenizer.eos_token_id)\n",
        "            answers.append(response)\n",
        "        return answers\n",
        "\n",
        "    def process_response(self, response: torch.Tensor, tokenizer: AutoTokenizer) -> int:\n",
        "        \"\"\"\n",
        "        Processes the response tensor and determines if it contains a positive indication.\n",
        "\n",
        "        Args:\n",
        "            response (torch.Tensor): The tensor containing the response from the model.\n",
        "            tokenizer (AutoTokenizer): The tokenizer used to decode the response tensor.\n",
        "\n",
        "        Returns:\n",
        "            int: Returns 1 if the decoded response contains 'YES' after 'ANSWER', otherwise returns 0.\n",
        "        \"\"\"\n",
        "        response_text = tokenizer.decode(response[0])\n",
        "        if 'YES' in response_text.split('ANSWER')[-1]:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def get_generated_response(self, response: torch.Tensor, tokenizer: AutoTokenizer) -> str:\n",
        "        \"\"\"\n",
        "        Decodes a tensor response into a cleaned string.\n",
        "\n",
        "        Args:\n",
        "            response (torch.Tensor): The tensor containing the response to decode.\n",
        "            tokenizer (AutoTokenizer): The tokenizer used to decode the response.\n",
        "\n",
        "        Returns:\n",
        "            str: The cleaned and decoded response string.\n",
        "        \"\"\"\n",
        "        response_text = tokenizer.decode(response[0])\n",
        "        response_text = response_text.split('[/INST]')[-1]\n",
        "        cleaned_string = re.sub(r'</s>', '', response_text).strip()\n",
        "        return cleaned_string\n",
        "\n",
        "    def compute_metrics(self, responses: list, y_true: list, tokenizer: AutoTokenizer) -> dict:\n",
        "        \"\"\"\n",
        "        Compute the accuracy and fail ratio of the model's predictions.\n",
        "\n",
        "        Args:\n",
        "            responses (list): A list of responses generated by the model.\n",
        "            y_true (list): A list of true labels corresponding to the responses.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dictionary containing the accuracy and fail ratio of the predictions.\n",
        "                - 'accuracy' (float): The proportion of correct predictions.\n",
        "                - 'fail_ratio' (float): The proportion of incorrect predictions.\n",
        "        \"\"\"\n",
        "        y_pred = [self.process_response(response=response, tokenizer=tokenizer) for response in responses]\n",
        "        accuracy = (np.array(y_pred) == np.array(y_true)).mean()\n",
        "        fail_ratio = (np.array(y_pred) != np.array(y_true)).mean()\n",
        "        return {'accuracy': accuracy, 'fail_ratio': fail_ratio}\n",
        "\n",
        "    def build_few_shot_demonstrations(\n",
        "        self, \n",
        "        demonstrations: pd.DataFrame, \n",
        "        num_per_class: int = 2,\n",
        "    ) -> list:\n",
        "        \"\"\"\n",
        "        Build few-shot demonstrations for each text instance.\n",
        "\n",
        "        Args:\n",
        "            demonstrations (pd.DataFrame): A DataFrame containing the demonstration texts and their labels.\n",
        "            num_per_class (int): The number of samples to extract for each class (positive and negative).\n",
        "\n",
        "        Returns:\n",
        "            list: A list where each element corresponds to a list of few-shot demonstrations for a text instance.\n",
        "                Each demonstration is represented as a list containing the text and its label.\n",
        "        \"\"\"\n",
        "        if isinstance(num_per_class, int):\n",
        "            num_per_class = [num_per_class, num_per_class]\n",
        "\n",
        "            # Extract a random sample of positive and negative demonstrations\n",
        "            yes_samples = demonstrations[demonstrations['label_sexist'] == 'sexist'].sample(num_per_class[0], random_state=self.seed)\n",
        "            no_samples = demonstrations[demonstrations['label_sexist'] == 'not sexist'].sample(num_per_class[1], random_state=self.seed)\n",
        "\n",
        "            # Combine the samples into a list of few-shot demonstrations\n",
        "            few_shot_demonstrations = list(pd.concat([yes_samples['text'], no_samples['text']]))\n",
        "            few_shot_demonstrations = [[demonstration, label] for demonstration, label in zip(few_shot_demonstrations, [1] * num_per_class[0] + [0] * num_per_class[1])]\n",
        "\n",
        "            # Shuffle the few-shot demonstrations\n",
        "            random.shuffle(few_shot_demonstrations)\n",
        "\n",
        "            return few_shot_demonstrations\n",
        "\n",
        "    def prepare_prompts_few_shot(self, texts: pd.Series, demonstrations: list, prompt_template: list, tokenizer: AutoTokenizer) -> list:\n",
        "        \"\"\"\n",
        "        Prepares few-shot learning prompts for a given set of texts using a specified prompt template and tokenizer.\n",
        "\n",
        "        Args:\n",
        "            texts (pd.Series): A pandas Series containing the texts to be used for generating prompts.\n",
        "            demonstrations (list): A list of tuples where each tuple contains a tweet (str) and its corresponding label (int).\n",
        "            prompt_template (list): A list representing the prompt template to be used for generating prompts.\n",
        "            tokenizer (AutoTokenizer): An instance of the AutoTokenizer to be used for tokenizing the prompts.\n",
        "\n",
        "        Returns:\n",
        "            list: A list of tokenized prompts ready for few-shot learning.\n",
        "        \"\"\"\n",
        "        # Store the prompts\n",
        "        prompts = []\n",
        "        # Iterate over the input texts\n",
        "        for text in texts:\n",
        "            # Create a deepcopy of the prompt template\n",
        "            prompt_with_text = deepcopy(prompt_template)\n",
        "            demonstration = ''\n",
        "            for tweet, label in demonstrations:\n",
        "                if label == 1:\n",
        "                    demonstration += '\\tTEXT: ' + tweet + '\\n\\tANSWER: YES\\n' # positive\n",
        "                else:\n",
        "                    demonstration += '\\tTEXT: ' + tweet + '\\n\\tANSWER: NO\\n' # negative\n",
        "\n",
        "            # Remove the first tab character\n",
        "            demonstration = demonstration[1:]\n",
        "            # Replace the placeholders with the input text and few-shot demonstrations\n",
        "            prompt_with_text[1]['content'] = prompt_with_text[1]['content'].replace('{examples}', demonstration)\n",
        "            prompt_with_text[1]['content'] = prompt_with_text[1]['content'].replace('{text}', text)\n",
        "            # Apply the chat template to the input text\n",
        "            full_prompt = tokenizer.apply_chat_template(\n",
        "                prompt_with_text,\n",
        "                tokenize=True,\n",
        "                add_generation_prompt=True,\n",
        "                return_dict=True,\n",
        "                return_tensors=\"pt\")\n",
        "            # Move the full prompt to the device\n",
        "            full_prompt = full_prompt.to(self.device)\n",
        "            # Append the full prompt to the list of prompts\n",
        "            prompts.append(full_prompt)\n",
        "\n",
        "        return prompts\n",
        "\n",
        "    def few_shot_experiment(\n",
        "            self,\n",
        "            name: str,\n",
        "            model: AutoModelForCausalLM,\n",
        "            tokenizer: AutoTokenizer,\n",
        "            data: pd.DataFrame,\n",
        "            demonstrations: pd.DataFrame,\n",
        "            prompt_template: list,\n",
        "            original_labels: list,\n",
        "            models_predictions: pd.DataFrame,\n",
        "            model_metrics: pd.DataFrame,\n",
        "            shots: int = 2,\n",
        "            store_model_predictions: bool = False\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        Conducts a few-shot learning experiment using a given model and tokenizer.\n",
        "\n",
        "        Args:\n",
        "            name (str): The name of the model being used.\n",
        "            model (AutoModelForCausalLM): The language model to be used for generating responses.\n",
        "            tokenizer (AutoTokenizer): The tokenizer associated with the language model.\n",
        "            data (pd.DataFrame): A DataFrame containing the input texts.\n",
        "            demonstrations (pd.DataFrame): A DataFrame of demonstration examples for few-shot learning.\n",
        "            prompt_template (list): A list of prompt templates to be used for generating prompts.\n",
        "            original_labels (list): The original labels for the data.\n",
        "            models_predictions (pd.DataFrame): DataFrame to store the model's predictions.\n",
        "            model_metrics (pd.DataFrame): DataFrame to store the model's performance metrics.\n",
        "            shots (int, optional): The number of shots (examples per class) to use for few-shot learning. Defaults to 2.\n",
        "            store_model_predictions (bool, optional): Whether to store the model's predictions. Defaults to False.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # Build few-shot demonstrations\n",
        "        few_shot_demonstrations = self.build_few_shot_demonstrations(demonstrations, num_per_class=shots)\n",
        "        # Prepare few-shot prompts\n",
        "        prompts_few_shot = self.prepare_prompts_few_shot(texts=data['text'], demonstrations=few_shot_demonstrations, prompt_template=prompt_template, tokenizer=tokenizer)\n",
        "\n",
        "        # Print few-shot prompt example\n",
        "        print('Example of few-shot prompt')\n",
        "        print(tokenizer.decode(prompts_few_shot[0].input_ids[0]))\n",
        "        print('-' * 100)\n",
        "\n",
        "        # Inference\n",
        "        print('Inference:')\n",
        "        # Generate responses\n",
        "        answers = self.generate_responses(model=model, tokenizer=tokenizer, prompt_examples=prompts_few_shot)\n",
        "\n",
        "        # Store model predictions\n",
        "        if store_model_predictions:\n",
        "            batch_predictions = [self.process_response(response=item, tokenizer=tokenizer) for item in answers]\n",
        "            generated_answers = [self.get_generated_response(response=item, tokenizer=tokenizer) for item in answers]\n",
        "            models_predictions[f'{name}_labels'] = batch_predictions\n",
        "            models_predictions[f'{name}_answers'] = generated_answers\n",
        "\n",
        "        # Compute metrics\n",
        "        metrics = self.compute_metrics(responses=answers, y_true=original_labels, tokenizer=tokenizer)\n",
        "        print('\\n')\n",
        "\n",
        "        # Store model metrics\n",
        "        model_metrics.loc[len(model_metrics)] = {'model': name, 'accuracy': metrics['accuracy'], 'fail_ratio': metrics['fail_ratio']}\n",
        "\n",
        "        # Print model metrics\n",
        "        print(f'Model: {name}\\tMetrics: {metrics}')\n",
        "\n",
        "    def few_shot_experiment_bm25(\n",
        "            self,\n",
        "            name: str,\n",
        "            model: AutoModelForCausalLM,\n",
        "            tokenizer: AutoTokenizer,\n",
        "            data: pd.DataFrame,\n",
        "            demonstrations: pd.DataFrame,\n",
        "            prompt_template: list,\n",
        "            original_labels: list,\n",
        "            models_predictions: pd.DataFrame,\n",
        "            model_metrics: pd.DataFrame,\n",
        "            shots: int = 2,\n",
        "            store_model_predictions: bool = False\n",
        "        ) -> None:\n",
        "        \"\"\"\n",
        "        Conducts a few-shot learning experiment using a given model and tokenizer.\n",
        "\n",
        "        Args:\n",
        "            name (str): The name of the model being used.\n",
        "            model (AutoModelForCausalLM): The language model to be used for generating responses.\n",
        "            tokenizer (AutoTokenizer): The tokenizer associated with the language model.\n",
        "            data (pd.DataFrame): A DataFrame containing the input texts.\n",
        "            demonstrations (pd.DataFrame): A DataFrame of demonstration examples for few-shot learning.\n",
        "            prompt_template (list): A list of prompt templates to be used for generating prompts.\n",
        "            original_labels (list): The original labels for the data.\n",
        "            models_predictions (pd.DataFrame): DataFrame to store the model's predictions.\n",
        "            model_metrics (pd.DataFrame): DataFrame to store the model's performance metrics.\n",
        "            shots (int, optional): The number of shots (examples per class) to use for few-shot learning. Defaults to 2.\n",
        "            store_model_predictions (bool, optional): Whether to store the model's predictions. Defaults to False.\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        # Build few-shot demonstrations\n",
        "        if isinstance(shots, int):\n",
        "            num_per_class = [shots, shots]\n",
        "\n",
        "        answers = []\n",
        "        \n",
        "        # Check if the tokenizer has a padding token\n",
        "        if not tokenizer.pad_token:\n",
        "            # Assign the padding token to the tokenizer end-of-sequence token\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "        \n",
        "        # Instantiate the BM25 model\n",
        "        bm25_sexist = BM25(tokenizer=tokenizer, device=self.device)\n",
        "        bm25_not_sexist = BM25(tokenizer=tokenizer, device=self.device)\n",
        "\n",
        "        # Index the demonstrations\n",
        "        bm25_sexist.index(demonstrations[demonstrations['label_sexist'] == 'sexist']['text'].values.tolist())\n",
        "        bm25_not_sexist.index(demonstrations[demonstrations['label_sexist'] == 'not sexist']['text'].values.tolist())\n",
        "\n",
        "        # Iterate over the input texts\n",
        "        for text in tqdm(data['text'], desc='Few-shot learning'):\n",
        "            # Compute BM25 scores between the text and all demonstrations\n",
        "            scores_sexist = bm25_sexist.score(text)\n",
        "            scores_not_sexist = bm25_not_sexist.score(text)\n",
        "\n",
        "            # Get the top k indices\n",
        "            k = sum(num_per_class) * 2  # Double to increase chances of getting desired samples\n",
        "            top_k_sexist = torch.topk(scores_sexist, k=k)\n",
        "            top_k_not_sexist = torch.topk(scores_not_sexist, k=k)\n",
        "\n",
        "            # Retrieve the top k demonstrations\n",
        "            top_k_sexist_ids = self.local_to_global_idx(topk_tensor=top_k_sexist, original_data=demonstrations, label_type='sexist')\n",
        "            top_k_not_sexist_ids = self.local_to_global_idx(topk_tensor=top_k_not_sexist, original_data=demonstrations, label_type='not sexist')\n",
        "\n",
        "            # Extract the top k demonstrations\n",
        "            yes_samples = demonstrations.loc[top_k_sexist_ids][:num_per_class[0]]\n",
        "            no_samples = demonstrations.loc[top_k_not_sexist_ids][:num_per_class[1]]\n",
        "\n",
        "            # Combine samples into a list of demonstrations\n",
        "            few_shot_demonstrations = pd.concat([yes_samples, no_samples])\n",
        "            few_shot_demonstrations = few_shot_demonstrations.sample(frac=1, random_state=self.seed)  # Shuffle\n",
        "\n",
        "            # Create a list of tuples (text, label)\n",
        "            demonstrations_list = [\n",
        "                [row['text'], 1 if row['label_sexist'] == 'sexist' else 0]\n",
        "                for _, row in few_shot_demonstrations.iterrows()\n",
        "            ]\n",
        "\n",
        "            # Create a deepcopy of the prompt template\n",
        "            prompt_with_text = deepcopy(prompt_template)\n",
        "            demonstration = ''\n",
        "            for tweet, label in demonstrations_list:\n",
        "                if label == 1:\n",
        "                    demonstration += '\\tTEXT: ' + tweet + '\\n\\tANSWER: YES\\n' # positive\n",
        "                else:\n",
        "                    demonstration += '\\tTEXT: ' + tweet + '\\n\\tANSWER: NO\\n' # negative\n",
        "\n",
        "            # Remove the first tab character\n",
        "            demonstration = demonstration[1:]\n",
        "            # Replace the placeholders with the input text and few-shot demonstrations\n",
        "            prompt_with_text[1]['content'] = prompt_with_text[1]['content'].replace('{examples}', demonstration)\n",
        "            prompt_with_text[1]['content'] = prompt_with_text[1]['content'].replace('{text}', text)\n",
        "\n",
        "            #print(prompt_with_text[1]['content'])\n",
        "\n",
        "            # Apply the chat template to the input text\n",
        "            full_prompt = tokenizer.apply_chat_template(\n",
        "                prompt_with_text,\n",
        "                tokenize=True,\n",
        "                add_generation_prompt=True,\n",
        "                return_dict=True,\n",
        "                return_tensors=\"pt\")\n",
        "            # Move the full prompt to the device\n",
        "            full_prompt = full_prompt.to(self.device)\n",
        "\n",
        "            # Generate responses\n",
        "            response = model.generate(**full_prompt, max_new_tokens=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "            answers.append(response)\n",
        "\n",
        "        # Store model predictions\n",
        "        if store_model_predictions:\n",
        "            batch_predictions = [self.process_response(response=item, tokenizer=tokenizer) for item in answers]\n",
        "            generated_answers = [self.get_generated_response(response=item, tokenizer=tokenizer) for item in answers]\n",
        "            models_predictions[f'{name}_labels'] = batch_predictions\n",
        "            models_predictions[f'{name}_answers'] = generated_answers\n",
        "\n",
        "        # Compute metrics\n",
        "        metrics = self.compute_metrics(responses=answers, y_true=original_labels, tokenizer=tokenizer)\n",
        "        print('\\n')\n",
        "\n",
        "        # Store model metrics\n",
        "        model_metrics.loc[len(model_metrics)] = {'model': name, 'accuracy': metrics['accuracy'], 'fail_ratio': metrics['fail_ratio']}\n",
        "\n",
        "        # Print model metrics\n",
        "        print(f'Model: {name}\\tMetrics: {metrics}')\n",
        "    \n",
        "    def local_to_global_idx(self, topk_tensor: torch.Tensor, original_data: pd.DataFrame, label_type: str) -> list:\n",
        "        \"\"\"\n",
        "        Converts local tensor indices to global indices based on the original DataFrame.\n",
        "        Args:\n",
        "            topk_tensor (torch.Tensor): A tensor containing the top-k indices.\n",
        "            original_data (pd.DataFrame): The original DataFrame containing the data.\n",
        "            label_type (str): The type of label to filter by ('sexist' or 'not sexist').\n",
        "        Returns:\n",
        "            list: A list of global indices corresponding to the original DataFrame.\n",
        "        \"\"\"\n",
        "        # Make a copy of the tensor indices\n",
        "        topk_tensor_indices = topk_tensor.indices.clone()\n",
        "        # Detatch the copy to the host memory and convert to numpy\n",
        "        topk_tensor_indices = topk_tensor_indices.cpu().numpy()\n",
        "        # Iterate over the tensor indices\n",
        "        for idx, demo_idx in enumerate(topk_tensor_indices):\n",
        "            # Check the label type\n",
        "            if label_type == 'sexist':\n",
        "                # Extract the sexist slice, reset indexes to local format and locate the correct one\n",
        "                example = original_data[original_data['label_sexist'] == 'sexist'].reset_index(drop=True).iloc[demo_idx]\n",
        "            else:\n",
        "                # Extract the non-sexist slice, reset indexes to local format and locate the correct one\n",
        "                example = original_data[original_data['label_sexist'] == 'not sexist'].reset_index(drop=True).iloc[demo_idx]\n",
        "\n",
        "            # Get the rewire_id of the example (text ID)\n",
        "            rewire_id = example['rewire_id']\n",
        "            # Get the original index of the example\n",
        "            original_idx = original_data[original_data['rewire_id'] == rewire_id].index[0]\n",
        "            # Store the original index in the tensor indices array\n",
        "            topk_tensor_indices[idx] = original_idx\n",
        "        \n",
        "        # Convert the tensor indices to a list\n",
        "        return topk_tensor_indices.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg4BFphulfFI"
      },
      "source": [
        "First we will define the class object for the dataset and then we will load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:05:04.680173Z",
          "iopub.status.busy": "2024-12-28T20:05:04.679782Z",
          "iopub.status.idle": "2024-12-28T20:05:04.902331Z",
          "shell.execute_reply": "2024-12-28T20:05:04.901361Z",
          "shell.execute_reply.started": "2024-12-28T20:05:04.680130Z"
        },
        "id": "jMD9BpkrlfFJ",
        "outputId": "f9880868-18a6-4508-938b-2fd15cc6386d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector = SexismDetector()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1W2gaAWlfFJ"
      },
      "source": [
        "Here we will load the test data given the URL of the file and encode it into a pandas DataFrame.\n",
        "\n",
        "The function will return the DataFrame as defined below.\n",
        "\n",
        "```python\n",
        "def download_corpus(self, url: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Downloads a corpus from the given URL and saves it as a CSV file in the data folder.\n",
        "    Args:\n",
        "        url (str): The URL of the corpus to download.\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing the contents of the downloaded CSV file.\n",
        "    Raises:\n",
        "        requests.exceptions.RequestException: If there is an issue with the HTTP request.\n",
        "    \"\"\"\n",
        "    filename = url.split(\"/\")[-1]\n",
        "    if not (self.DATA_FOLDER / filename).exists():\n",
        "        print(f\"Created folder {self.DATA_FOLDER}.\")\n",
        "\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    with open(self.DATA_FOLDER / filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(response.text)\n",
        "    \n",
        "    return pd.read_csv(self.DATA_FOLDER / filename, encoding='utf-8')\n",
        "```\n",
        "\n",
        "> **Note**: The function is part of the class, but we decided to explicitly define it here for clarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:05:06.237444Z",
          "iopub.status.busy": "2024-12-28T20:05:06.237126Z",
          "iopub.status.idle": "2024-12-28T20:05:06.284884Z",
          "shell.execute_reply": "2024-12-28T20:05:06.284253Z",
          "shell.execute_reply.started": "2024-12-28T20:05:06.237415Z"
        },
        "id": "vlJz89U4WEQt",
        "outputId": "c29b4d96-8c56-42c3-f5f1-8550d90b0123",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "path_test = 'https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/refs/heads/main/2024-2025/Assignment%202/data/a2_test.csv'\n",
        "df = detector.download_corpus(url=path_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:05:06.576245Z",
          "iopub.status.busy": "2024-12-28T20:05:06.575959Z",
          "iopub.status.idle": "2024-12-28T20:05:06.591566Z",
          "shell.execute_reply": "2024-12-28T20:05:06.590812Z",
          "shell.execute_reply.started": "2024-12-28T20:05:06.576220Z"
        },
        "id": "WDDxbr-CWKwu",
        "outputId": "e8e9ab9b-6396-43c8-8f96-91e3cea3529e",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cXaP301XYFo"
      },
      "source": [
        "# Model 1 - Mistral V3 7B\n",
        "As first model we are gonna analyze the performance of Mistral V3 7B parameter model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJp08l4yLJnd"
      },
      "source": [
        "## Task 1 - Model setup\n",
        "\n",
        "In this section we will first load the model from Huggingface and then quantize it to fit into a single GPU either with 4bit or 8bit precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKR7cV1zlfFL"
      },
      "source": [
        "We defined a function which given the model card and the quantization type, loads the model and the tokenizer so that we can use them for the inference.\n",
        "\n",
        "The following function is used to load the model and the tokenizer.\n",
        "\n",
        "```python\n",
        "def load_model(self, model_card: str, with_4_bit: bool = True) -> tuple:\n",
        "    \"\"\"\n",
        "    Loads a pre-trained model and its tokenizer with optional 4-bit quantization.\n",
        "\n",
        "    Args:\n",
        "        model_card (str): The identifier of the pre-trained model to load.\n",
        "        with_4_bit (bool, optional): If True, loads the model with 4-bit quantization.\n",
        "                                        If False, loads the model with 8-bit quantization.\n",
        "                                        Defaults to True.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the loaded model and tokenizer.\n",
        "    \"\"\"\n",
        "    # Clear cache\n",
        "    self.clear_cache()\n",
        "\n",
        "    # Setup the quantization config\n",
        "    quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "    if with_4_bit:\n",
        "        quantization_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_quant_type=\"fp4\",\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16\n",
        "        )\n",
        "    # Load tokenizer\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
        "    # Load the model\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_card, quantization_config=quantization_config)\n",
        "    # Set the model to evaluation (inference) mode\n",
        "    model.eval()\n",
        "\n",
        "    return model, tokenizer\n",
        "```\n",
        "\n",
        ">**Note**: The default quantization is set to 4-bit to allow the model to fit into a single GPU (RTX 3080) with 10GB of memory. However, the final run of our notebook is done with 8-bit quantization to ensure that the model can fit into a single GPU on Colab T4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH4pTdCwlfFL"
      },
      "source": [
        "Now we can define the model card and load the model and the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540,
          "referenced_widgets": [
            "e7e02bcdc58c4f3ab657899598039db2",
            "3e73fb6444fe4c37a84e8d8a3166d81f",
            "707bbc12cdf34926a7d6c004a90fddb2",
            "f249ae54f3b2494d9c42655c0865e43c",
            "d14c60256ed349408bbea3fd8627099a",
            "9922cee19aea466e8d35ae2bb12c5704",
            "b5d7268e12f24b52a9c78fb67aa91bb2",
            "01a966d833764428beb9eb27ca9e66ac",
            "4749732f61bc4e9187ff9b73ed1ac326",
            "b51abf5140b14f868360d1f369443205",
            "53e5631f7fe840e5a8cb6b866128e289",
            "bb8066b897c34a08a7e598f1ff415581",
            "33fe0340c8444e66baa57791e5b78b7c",
            "6405bd33d63a4d01874ba4c9e0d80334",
            "e55cbf7058034c77aa3732114a3062bc",
            "4b576ac2b32b47569d1d2f657a1faddf",
            "29011283fb684c92b1514af8ecfed00d",
            "679dad99050f4752894873f340cb28ec",
            "378cab34ebc84d19b5d1bc2a5b821b81",
            "0cdd166cdab34680bf4073de7ab66734",
            "58a5ddce0c2f4e15a0f5c96bd54bc582",
            "ad18037f907c45c0b06d01c321ec9ac3",
            "cfffe93c1c21468fae715a221ca621c6",
            "99c07023bc5e4fd4b3e9239a01c47ef8",
            "fc786a345cf84842a3bf45a892fe0472",
            "83919ed633074a41b10cb19b437a1cf6",
            "03706daf585e4925b4b8ff3cdea8da4b",
            "070bc0be124b425383339e1e1e4345a3",
            "c4e2938c32b447c4bd001bf08463cfc0",
            "a6e94766f4444e1db218779be8d644d3",
            "98e2609c40734c02844521ed7aa913da",
            "8a4f975cd13841959d7f86954290e410",
            "566f69e1aaad4befa54bde823530dd79",
            "45e5574034df4a78a02e011f27afaea7",
            "fbbca39e31e14a928d7dbaceb853094c",
            "46a80def55984e998ec8d25942937e65",
            "10e1689b054f4045a27262d695fa6970",
            "4f00afd02d8e4f92b6c57fa4b07d4d5d",
            "a13162d1ad2a4b08be7049ee1c769815",
            "139343a7a50c4157b6ee591fe2989dc1",
            "6a085448595148e2852b6b29f6e33d74",
            "2c101e3822164cb5819db2d5b8d53c28",
            "f33bfb43e73b42e49f58ab212d5968af",
            "1fd6d85a0f8f4be5936650333629c87d",
            "9082afc9336f45c09e8c9f558386dfb8",
            "326fbebbf7a04fc185ca8e60f8102f08",
            "23d525aeaa9346758a9a6f30e3ac36c8",
            "3ae253a883ea434b876678caba0e422f",
            "7fbf7300e0b04706aa7e7174a7932e5d",
            "87326148b4e448e8833b7ef49160f5d6",
            "7f097d11ba024ed78304aa75c9fec82e",
            "a4d09a4ddcfa404685b4262b46535e44",
            "d2fbd239a5694809ade9f572317a9d5c",
            "6e31371665be4ebba2a9a4fc6ad20988",
            "13499f7313134e7ca62a532fedc63935",
            "2e3ec463febf4247a46713cc0e541dbc",
            "7c90816ffb284abb9e06338ef503a388",
            "a3044c90edc1439c975d781db74d34ce",
            "5924a914d5d4402b9d16abaa65d79122",
            "4cd9b0a4a06948bb9061a8e13c4e2b36",
            "9d361d076dd34acfbe8bbfd090557784",
            "d6dc5923c5d1460aa5b7942d1dbe3b30",
            "9645f62f81e54311bf28dca6e326fc85",
            "af134f8efc514910b31959193380477a",
            "67fe55893d3d42acb4a0834886779e8a",
            "7cfb55d2c8e3461bb6ab3c506586d40f",
            "e6f316d2166f43ed8866674316a2f180",
            "136c81e4f9ac47dd9977393eb2bd3f48",
            "02db4ca1d06240e3a8464de7583e50d0",
            "fa88becfa81c426aaef4d213a8934c70",
            "e52242c71523404bbba94c882f03f38e",
            "ff1b1bed15ca4f19bdbe515c90315b0f",
            "93545824c8d344e1ab999608079211b1",
            "7d431770b8e742d097eacabaaf021612",
            "74c1ad5ae6a646eab554f9df2e831f5d",
            "f857c50ac5c844cc89cbecf7d34d3a30",
            "38ef02aef23f465082823c1c3a55892d",
            "1c2202f66d9f43718eb6f06fad444ed4",
            "793a7c6c811f437083fa8966506c59d6",
            "a88fa8d92a7e4985a16056568751c96f",
            "c17106b93e6d405bb59ab7501ca278cf",
            "33ddabd699d24a5e8f1280da3b6c9ae0",
            "5f0d7e2219394a65acd584d2da7be07c",
            "40eaf3df6eeb4c27a00d05aa0b0cb8e9",
            "4af40d2cb18342378b31634d7b4f6c44",
            "d239d39e287e4e029456c429d4e4830b",
            "c54ed8a8467642fc88b4761f17827eca",
            "631af03304b7489d914cbf92179e3589",
            "eed0579f667a41d3bc42e025e3611f1f",
            "cc8ebb87f20d41c3aa2c6586300e26a4",
            "d18296a6e2d241b6b6add26b66b4aed2",
            "65e2b468d6d34adfbd3e8a766ae33a93",
            "37b9d27c191c4b3da761602e76f8357c",
            "c38dbfc357204d7fb9d39b20d0a7f31b",
            "ddf4597c344c496ea14b590c975fd5e5",
            "645cdf9d6e3c42efa529f422b9104e1b",
            "ec612d375113460b9672dbd4ee4232a8",
            "ba3723bd7a61465082c5e855307fe864",
            "2d00ddd632274ce287a9f496f8240a85",
            "eb0bc66a21dd419e8128e8e5c6bd205d",
            "6cec09cbe65a4bac8d76a2419507d4c3",
            "d8727efa45544e369527ad890a0fd0f2",
            "a078a0446362449c912df1ca7d91e2a0",
            "ab9e24119e514ba6b83b6a01774a08ae",
            "f676cb45031c4a6b8763d83e161879a7",
            "532e49cbb43e41d1a90aeea73dab64e4",
            "8acbc26eca184a8a8cee960c70b05ce7",
            "19549c07581f4278bf802be3babda7ea",
            "d2dcefc86aa94809a250702cf1d41dbc",
            "014baa6da7184be38baccde7905ba1ae",
            "6fb1bfea101648abad6443367659b5c9",
            "fee44c9704f14a45a3c54b1b9f81c0d5",
            "d0e9118f6a294629901d1f75fbc9379b",
            "ad141eda52a94c5198d520de981a1882",
            "41885048145548d5898ff07bc70a0c64",
            "f408f27d951c4135a8e89f5e4108174f",
            "9e6c1b6464624743b97745a9f3384a38",
            "f6e458302d9e43cdb49f6902669b3378",
            "1da98c60074e47be8bf1878202f318d6",
            "8f8611ce898b4440a7f5685c9a2110d0",
            "ebabcafabaea4a7c9e78abf250ea888f",
            "95cc2f53b48143a19ee9535c429edcea",
            "906fec0adf4644d5b256c00ee7ff8ed9",
            "5f18d58d903e4acbbb83cdfddfa39d0c",
            "51360958ec1848449cc1e660696cc089",
            "d11d471487d644afa77b8a3eabcc70a7",
            "f797239b31ff47119dbc1478ffb8b1d6",
            "8605f3de15c747e3b8a91418ecfad922",
            "ef5f43fe138643ebb7cf47ec0441b18d",
            "aa29655c8e364403b93fc7843552d593",
            "7a6409687e9a4517befc6dd7f9090be3",
            "4b71317122a44cff801f2124cd8182f4"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:05:10.861314Z",
          "iopub.status.busy": "2024-12-28T20:05:10.861019Z",
          "iopub.status.idle": "2024-12-28T20:11:16.546642Z",
          "shell.execute_reply": "2024-12-28T20:11:16.545966Z",
          "shell.execute_reply.started": "2024-12-28T20:05:10.861290Z"
        },
        "id": "U6G3bdIXW-c1",
        "outputId": "444364d1-5584-4f60-b3dd-c092da097752",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_card = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
        "model, tokenizer = detector.load_model(model_card, with_4_bit=False)\n",
        "\n",
        "device = model.device\n",
        "print(f'Model loaded on {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzNNzb1VLJnd"
      },
      "source": [
        "## Task 2 - Prompt setup\n",
        "\n",
        "Prompting requires an input pre-processing phase where we convert each input example into a specific instruction prompt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GaBtKXomY_m"
      },
      "source": [
        "**Prompt Template**\n",
        "\n",
        "Use the following prompt template to process input texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:11:25.387570Z",
          "iopub.status.busy": "2024-12-28T20:11:25.387105Z",
          "iopub.status.idle": "2024-12-28T20:11:25.391509Z",
          "shell.execute_reply": "2024-12-28T20:11:25.390506Z",
          "shell.execute_reply.started": "2024-12-28T20:11:25.387544Z"
        },
        "id": "7e8P-Kk8me6q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "prompt = [\n",
        "    {\n",
        "        'role': 'system',\n",
        "        'content': 'You are an annotator for sexism detection.'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': \"\"\"Your task is to classify input text as containing sexism or not. Respond only YES or NO.\n",
        "\n",
        "        TEXT:\n",
        "        {text}\n",
        "\n",
        "        ANSWER:\n",
        "        \"\"\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YIf7GxglfFN"
      },
      "source": [
        "The following function is our implementation of the `prepare_prompts` function. It takes a pandas Series of texts, a prompt template, and a tokenizer as input and returns a list of tokenized prompts ready for generation.\n",
        "\n",
        "```python\n",
        "def prepare_prompts(self, texts: pd.Series, prompt_template: list, tokenizer: AutoTokenizer) -> list:\n",
        "    \"\"\"\n",
        "    Prepares prompts by applying a chat template to a series of input texts.\n",
        "\n",
        "    Args:\n",
        "        texts (pd.Series): A pandas Series containing the input texts.\n",
        "        prompt_template (list): A list representing the prompt template with placeholders.\n",
        "        tokenizer (AutoTokenizer): An instance of the AutoTokenizer used to tokenize the prompts.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tokenized prompts ready for generation.\n",
        "    \"\"\"\n",
        "    # Store the prompts\n",
        "    prompts = []\n",
        "    # Iterate over the input texts\n",
        "    for text in texts:\n",
        "\n",
        "        # Create a deepcopy of the prompt template\n",
        "        prompt_with_text = deepcopy(prompt_template)\n",
        "\n",
        "        # Replace the placeholder with the input text\n",
        "        prompt_with_text[1]['content'] = prompt_with_text[1]['content'].replace('{text}', text)\n",
        "\n",
        "        # Apply the chat template to the input text\n",
        "        full_prompt = tokenizer.apply_chat_template(\n",
        "            prompt_with_text,\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=True,\n",
        "            return_dict=True,\n",
        "            return_tensors=\"pt\")\n",
        "        # Move the full prompt to the device\n",
        "        full_prompt = full_prompt.to(self.device)\n",
        "        # Append the full prompt to the list of prompts\n",
        "        prompts.append(full_prompt)\n",
        "\n",
        "    return prompts\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiDAgicGlfFN"
      },
      "source": [
        "Now we can apply the function to the test dataset and print one of the prompts to check if it is correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:11:27.991926Z",
          "iopub.status.busy": "2024-12-28T20:11:27.991517Z",
          "iopub.status.idle": "2024-12-28T20:11:28.264547Z",
          "shell.execute_reply": "2024-12-28T20:11:28.263744Z",
          "shell.execute_reply.started": "2024-12-28T20:11:27.991872Z"
        },
        "id": "c_aGPnEimS92",
        "outputId": "4cd90abb-8aa3-483d-83c9-f1d36de259cd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "prompts = detector.prepare_prompts(texts=df['text'], prompt_template=prompt, tokenizer=tokenizer)\n",
        "\n",
        "print(f\"Prompt example: \\n{tokenizer.decode(prompts[0].input_ids[0], skip_special_tokens=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgBhkBwuLJnd"
      },
      "source": [
        "## Task 3 - Inference\n",
        "\n",
        "We are now ready to define the inference loop where we prompt the model with each pre-processed sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyxUadMGlfFN"
      },
      "source": [
        "First we will define the `generate_responses` function which given the model, the tokenizer, the prompt examples and the maximum number of tokens to generate, generates the responses for each prompt example.\n",
        "\n",
        "In particular, we will use the following function to generate the responses\n",
        "\n",
        "```python\n",
        "def generate_responses(self, model: AutoModelForCausalLM, tokenizer: AutoTokenizer, prompt_examples: list, max_new_tokens: int = 1000) -> list:\n",
        "    \"\"\"\n",
        "    Generates responses for a list of prompt examples using a specified language model and tokenizer.\n",
        "\n",
        "    Args:\n",
        "        model (AutoModelForCausalLM): The language model to use for generating responses.\n",
        "        tokenizer (AutoTokenizer): The tokenizer associated with the language model.\n",
        "        prompt_examples (list): A list of prompt examples to generate responses for.\n",
        "        max_new_tokens (int, optional): The maximum number of new tokens to generate for each prompt. Defaults to 1000.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of generated responses corresponding to each prompt example.\n",
        "    \"\"\"\n",
        "    answers = []\n",
        "    for prompt in tqdm(prompt_examples):\n",
        "        response = model.generate(**prompt, max_new_tokens=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "        answers.append(response)\n",
        "    return answers\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPY75_sylfFO"
      },
      "source": [
        "We will also define a function to process the response (`process_response`) and determine if it contains a positive indication. The function takes the response tensor and the tokenizer as input and returns 1 if the decoded response contains 'YES' after 'ANSWER', otherwise returns 0.\n",
        "\n",
        "```python\n",
        "def process_response(self, response: torch.Tensor, tokenizer: AutoTokenizer) -> int:\n",
        "    \"\"\"\n",
        "    Processes the response tensor and determines if it contains a positive indication.\n",
        "\n",
        "    Args:\n",
        "        response (torch.Tensor): The tensor containing the response from the model.\n",
        "        tokenizer (AutoTokenizer): The tokenizer used to decode the response tensor.\n",
        "\n",
        "    Returns:\n",
        "        int: Returns 1 if the decoded response contains 'YES' after 'ANSWER', otherwise returns 0.\n",
        "    \"\"\"\n",
        "    response_text = tokenizer.decode(response[0])\n",
        "    if 'YES' in response_text.split('ANSWER')[-1]:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrWtGBgblfFO"
      },
      "source": [
        "Now we can generate all the responses for the test dataset and process them to get the predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:11:31.753737Z",
          "iopub.status.busy": "2024-12-28T20:11:31.753279Z",
          "iopub.status.idle": "2024-12-28T20:15:38.261558Z",
          "shell.execute_reply": "2024-12-28T20:15:38.260805Z",
          "shell.execute_reply.started": "2024-12-28T20:11:31.753712Z"
        },
        "id": "Q6PWskXKmS93",
        "outputId": "756c55b8-cfc4-400b-b084-5db0df5cc31f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "answers = detector.generate_responses(model=model, tokenizer=tokenizer, prompt_examples=prompts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_NwPb8OlfFP"
      },
      "source": [
        "The predictions will be computed in a list-comprehension fashion, same applies for the generation of the answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:16:46.116147Z",
          "iopub.status.busy": "2024-12-28T20:16:46.115451Z",
          "iopub.status.idle": "2024-12-28T20:16:46.190909Z",
          "shell.execute_reply": "2024-12-28T20:16:46.190288Z",
          "shell.execute_reply.started": "2024-12-28T20:16:46.116110Z"
        },
        "id": "wopoW3-rmS93",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "batch_predictions = [detector.process_response(response=item, tokenizer=tokenizer) for item in answers]\n",
        "generated_answers = [detector.get_generated_response(response=item, tokenizer=tokenizer) for item in answers]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u_hs9EglfFP"
      },
      "source": [
        "We will also recover the original labels of the test dataset to compute the accuracy of the model later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:16:48.238467Z",
          "iopub.status.busy": "2024-12-28T20:16:48.238175Z",
          "iopub.status.idle": "2024-12-28T20:16:48.242817Z",
          "shell.execute_reply": "2024-12-28T20:16:48.241894Z",
          "shell.execute_reply.started": "2024-12-28T20:16:48.238443Z"
        },
        "id": "C56bN3DSpzoh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "original_labels = [1 if label == 'sexist' else 0 for label in df['label_sexist']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By defining a pandas dataframe to store the model prediction, later we will be able to compare the predictions with the original labels across all models in a single dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:16:49.053150Z",
          "iopub.status.busy": "2024-12-28T20:16:49.052834Z",
          "iopub.status.idle": "2024-12-28T20:16:49.067734Z",
          "shell.execute_reply": "2024-12-28T20:16:49.067008Z",
          "shell.execute_reply.started": "2024-12-28T20:16:49.053125Z"
        },
        "id": "KHDrhy10pY8p",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "models_predictions = pd.DataFrame({\n",
        "    'text': df['text'],\n",
        "    'original_labels': original_labels,\n",
        "    'Mistralv3_zero_shot_labels': batch_predictions,\n",
        "    'Mistralv3_zero_shot_answers': generated_answers\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also inspect the dataframe and see the predictions and the original labels for each of the model we are going to analyze."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:16:50.040007Z",
          "iopub.status.busy": "2024-12-28T20:16:50.039706Z",
          "iopub.status.idle": "2024-12-28T20:16:50.048461Z",
          "shell.execute_reply": "2024-12-28T20:16:50.047662Z",
          "shell.execute_reply.started": "2024-12-28T20:16:50.039983Z"
        },
        "id": "rQUxJZULbGto",
        "outputId": "4bcce9c5-007e-4948-bafc-bcc35522315c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "models_predictions.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyZ8WU09zz-a"
      },
      "source": [
        "## Task 4 - Metrics\n",
        "\n",
        "In order to evaluate selected LLMs, we need to compute performance metrics.\n",
        "\n",
        "In particular, we are interested in computing **accuracy** since the provided data is balanced with respect to classification classes.\n",
        "\n",
        "Moreover, we want to compute the ratio of failed responses generated by models.\n",
        "\n",
        "That is, how frequent the LLM fails to follow instructions and provides incorrect responses that do not address the classification task.\n",
        "\n",
        "We denote this metric as **fail-ratio**.\n",
        "\n",
        "In summary, we parse generated responses as follows:\n",
        "- 1 if the model says YES\n",
        "- 0 if the model says NO\n",
        "- 0 if the model does not answer in either way"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6lSSa8dlfFS"
      },
      "source": [
        "We will define the function `compute_metrics` which given the predictions and the original labels, computes the accuracy and the fail-ratio of the model.\n",
        "\n",
        "```python\n",
        "def compute_metrics(self, responses: list, y_true: list) -> dict:\n",
        "    \"\"\"\n",
        "    Compute the accuracy and fail ratio of the model's predictions.\n",
        "\n",
        "    Args:\n",
        "        responses (list): A list of responses generated by the model.\n",
        "        y_true (list): A list of true labels corresponding to the responses.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the accuracy and fail ratio of the predictions.\n",
        "            - 'accuracy' (float): The proportion of correct predictions.\n",
        "            - 'fail_ratio' (float): The proportion of incorrect predictions.\n",
        "    \"\"\"\n",
        "    y_pred = [self.process_response(response) for response in responses]\n",
        "    accuracy = (np.array(y_pred) == np.array(y_true)).mean()\n",
        "    fail_ratio = (np.array(y_pred) != np.array(y_true)).mean()\n",
        "    return {'accuracy': accuracy, 'fail_ratio': fail_ratio}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d1hCKoAlfFS"
      },
      "source": [
        "Now we can compute the metrics for the Mistral v3 model given the previous predictions and the original labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:16:54.363127Z",
          "iopub.status.busy": "2024-12-28T20:16:54.362770Z",
          "iopub.status.idle": "2024-12-28T20:16:54.404061Z",
          "shell.execute_reply": "2024-12-28T20:16:54.402990Z",
          "shell.execute_reply.started": "2024-12-28T20:16:54.363089Z"
        },
        "id": "rrIxiMwXryA0",
        "outputId": "509f588e-aff3-4d41-a608-7be261f76596",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mistal_base_metrics = detector.compute_metrics(responses=answers, y_true=original_labels, tokenizer=tokenizer)\n",
        "print(f\"Mistral v3 Zero-Shot Metrics: {mistal_base_metrics}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, the zero-shot Mistal v3 model has an accuracy of 0.61 which is quite low, but this is expected since the model did not receive any example on how the task should be performed.\n",
        "\n",
        "Then we will define another dataframe which will store the model metrics in terms of accuracy and fail ration so that we can compare all the models easily in a single dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:16:55.363081Z",
          "iopub.status.busy": "2024-12-28T20:16:55.362721Z",
          "iopub.status.idle": "2024-12-28T20:16:55.368893Z",
          "shell.execute_reply": "2024-12-28T20:16:55.368047Z",
          "shell.execute_reply.started": "2024-12-28T20:16:55.363047Z"
        },
        "id": "RDTwjbnfzes0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create the new dataset for storing the metrics\n",
        "model_metrics = pd.DataFrame(columns=['model', 'accuracy', 'fail_ratio'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we will add the metrics of the zero shot Mistral v3 model to the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:16:55.868826Z",
          "iopub.status.busy": "2024-12-28T20:16:55.868610Z",
          "iopub.status.idle": "2024-12-28T20:16:55.873333Z",
          "shell.execute_reply": "2024-12-28T20:16:55.872517Z",
          "shell.execute_reply.started": "2024-12-28T20:16:55.868807Z"
        },
        "id": "xmhkJaPblfFU",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Add the computed metrics to the metric dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'Mistralv3_0_shot', **mistal_base_metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can inspect the dataframe to see the metrics of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:16:56.455457Z",
          "iopub.status.busy": "2024-12-28T20:16:56.455170Z",
          "iopub.status.idle": "2024-12-28T20:16:56.466671Z",
          "shell.execute_reply": "2024-12-28T20:16:56.465816Z",
          "shell.execute_reply.started": "2024-12-28T20:16:56.455431Z"
        },
        "id": "ufKvwOZObXIC",
        "outputId": "48e698e4-24d3-4ac7-a5d2-39e037dea567",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHyvV4QD2vZS"
      },
      "source": [
        "## Task 5 - Few-shot Inference\n",
        "\n",
        "So far, we have tested models in a zero-shot fashion: we provide the input text to classify and instruct the model to generate a response.\n",
        "\n",
        "We are now interested in performing few-shot prompting to see the impact of providing demonstration examples.\n",
        "\n",
        "To do so, we slightly change the prompt template as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:16:57.934407Z",
          "iopub.status.busy": "2024-12-28T20:16:57.934101Z",
          "iopub.status.idle": "2024-12-28T20:16:57.938294Z",
          "shell.execute_reply": "2024-12-28T20:16:57.937419Z",
          "shell.execute_reply.started": "2024-12-28T20:16:57.934384Z"
        },
        "id": "pEqsOHz63ReW",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "prompt_few_shot = [\n",
        "    {\n",
        "        'role': 'system',\n",
        "        'content': 'You are an annotator for sexism detection.'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': \"\"\"Your task is to classify input text as containing sexism or not. Respond only YES or NO.\n",
        "\n",
        "        EXAMPLES:\n",
        "        {examples}\n",
        "\n",
        "        TEXT:\n",
        "        {text}\n",
        "\n",
        "        ANSWER:\n",
        "        \"\"\"\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SnaxuwN3ySF"
      },
      "source": [
        "The new prompt template reports some demonstration examples to instruct the model.\n",
        "\n",
        "We provide an equal number of demonstrations per class as shown in the example below.\n",
        "\n",
        "```python\n",
        "prompt = [\n",
        "    {\n",
        "        'role': 'system',\n",
        "        'content': 'You are an annotator for sexism detection.'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': \"\"\"Your task is to classify input text as containing sexism or not. Respond only YES or NO.\n",
        "\n",
        "        EXAMPLES:\n",
        "        TEXT: **example 1**\n",
        "        ANSWER: YES\n",
        "        TEXT: **example 2**\n",
        "        ANSWER: NO\n",
        "\n",
        "        TEXT:\n",
        "        {text}\n",
        "\n",
        "        ANSWER:\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "```  \n",
        "\n",
        ">**Note**: We did not experiment with different numbers of demonstrations per class, but we believe that it could be an interesting experiment to perform in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NdDXMpdp4r3"
      },
      "source": [
        "### Task 5.1 - Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZ-_V_mklfFW"
      },
      "source": [
        "First we will load as a pandas DataFrame the demonstrations dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:17:01.289252Z",
          "iopub.status.busy": "2024-12-28T20:17:01.288916Z",
          "iopub.status.idle": "2024-12-28T20:17:01.488022Z",
          "shell.execute_reply": "2024-12-28T20:17:01.487172Z",
          "shell.execute_reply.started": "2024-12-28T20:17:01.289227Z"
        },
        "id": "6bbJtxNst2FF",
        "outputId": "46bce444-f464-48be-8c41-071d5c5d5fc8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "path_demonstrations = 'https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/refs/heads/main/2024-2025/Assignment%202/data/demonstrations.csv'\n",
        "demonstrations = detector.download_corpus(url=path_demonstrations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:17:01.516644Z",
          "iopub.status.busy": "2024-12-28T20:17:01.516419Z",
          "iopub.status.idle": "2024-12-28T20:17:01.524096Z",
          "shell.execute_reply": "2024-12-28T20:17:01.523381Z",
          "shell.execute_reply.started": "2024-12-28T20:17:01.516623Z"
        },
        "id": "Gqr7bR_MlfFX",
        "outputId": "d1120863-b016-4abe-cd2b-a62c172bef9c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "demonstrations.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5D10YdFlfFX"
      },
      "source": [
        "Then we can define the build_few_shot_demonstrations function which given the demonstrations DataFrame, and the number of demonstrations per class, returns the demonstrations for the few shot prompting by taking a sample of the demonstrations for each class.\n",
        "\n",
        "```python\n",
        "def build_few_shot_demonstrations(self, demonstrations: pd.DataFrame, num_per_class: int = 2, custom_example_ids: list = []) -> list:\n",
        "    \"\"\"\n",
        "    Build few-shot demonstrations for a classification task.\n",
        "\n",
        "    This method extracts a specified number of positive and negative samples from the provided DataFrame\n",
        "    and combines them into a list of few-shot demonstrations. The demonstrations are then shuffled.\n",
        "\n",
        "    Args:\n",
        "        demonstrations (pd.DataFrame): A DataFrame containing the text samples and their corresponding labels.\n",
        "                                        The DataFrame must have at least two columns: 'text' and 'label_sexist'.\n",
        "        num_per_class (int): The number of samples to extract for each class (positive and negative). If an integer\n",
        "                                is provided, the same number of samples will be extracted for both classes. If a list\n",
        "                                of two integers is provided, the first integer specifies the number of positive samples\n",
        "                                and the second integer specifies the number of negative samples. Default is 2.\n",
        "        custom_example_ids (list, optional): A list of custom example IDs to include in the few-shot demonstrations. This will be used later to check specific examples manually or by passing top demonstration examples according to a ranking criterion. Defaults to an empty list.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of few-shot demonstrations, where each demonstration is a list containing the text and its label.\n",
        "                The label is 1 for positive samples (sexist) and 0 for negative samples (not sexist).\n",
        "    \"\"\"\n",
        "    if isinstance(num_per_class, int):\n",
        "        num_per_class = [num_per_class, num_per_class]\n",
        "\n",
        "    if len(custom_example_ids) == 0:\n",
        "        # Extract a random sample of positive and negative demonstrations\n",
        "        yes_samples = demonstrations[demonstrations['label_sexist'] == 'sexist'].sample(num_per_class[0], random_state=self.seed)\n",
        "        no_samples = demonstrations[demonstrations['label_sexist'] == 'not sexist'].sample(num_per_class[1], random_state=self.seed)\n",
        "    else:\n",
        "        # Extract custom examples\n",
        "        yes_samples = demonstrations[demonstrations.index.isin(custom_example_ids)]\n",
        "        no_samples = demonstrations[~demonstrations.index.isin(custom_example_ids)]\n",
        "\n",
        "    # Combine the samples into a list of few-shot demonstrations\n",
        "    few_shot_demonstrations = list(pd.concat([yes_samples['text'], no_samples['text']]))\n",
        "    few_shot_demonstrations = [[demonstration, label] for demonstration, label in zip(few_shot_demonstrations,\n",
        "                                                                                        [1] * num_per_class[0] + [0] * num_per_class[1])]\n",
        "    # Shuffle the few-shot demonstrations\n",
        "    random.shuffle(few_shot_demonstrations)\n",
        "\n",
        "    return few_shot_demonstrations\n",
        "```\n",
        "\n",
        ">**Note**: The function has an optional parameter to include custom examples in the few-shot demonstrations. This will be used to pass the top demonstration examples according to a ranking criterion and compare the performance of the models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5cXSQQdqCmZ"
      },
      "source": [
        "### Task 5.2 - Few shot with randomly sampled examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv5E7-ah4QUB"
      },
      "source": [
        "#### Learning by 2-shot randomly sampled examples\n",
        "\n",
        "In this section we will provide 2 randomly sampled examples (1 per class) to the model and check the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:17:04.645063Z",
          "iopub.status.busy": "2024-12-28T20:17:04.644708Z",
          "iopub.status.idle": "2024-12-28T20:29:42.227597Z",
          "shell.execute_reply": "2024-12-28T20:29:42.226666Z",
          "shell.execute_reply.started": "2024-12-28T20:17:04.645032Z"
        },
        "id": "TblPYnh7YFPz",
        "outputId": "9add991b-9d68-46f6-affa-f9de93cd9771",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Mistralv3_2_shot',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    shots=1,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSDUqAWDuVQ-"
      },
      "source": [
        "#### Learning by 4-shot randomly sampled examples\n",
        "\n",
        "In this section we will provide 4 randomly sampled examples (2 per class) to the model and check the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:29:42.230883Z",
          "iopub.status.busy": "2024-12-28T20:29:42.230660Z",
          "iopub.status.idle": "2024-12-28T20:35:50.609486Z",
          "shell.execute_reply": "2024-12-28T20:35:50.608706Z",
          "shell.execute_reply.started": "2024-12-28T20:29:42.230863Z"
        },
        "id": "T47iRshnY2Ph",
        "outputId": "bfeef7d4-b558-457c-93e1-f2df397d865c",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Mistralv3_4_shot',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    shots=2,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3vNuk3GuadK"
      },
      "source": [
        "#### Learning by 8-shot randomly sampled examples\n",
        "\n",
        "In this section we will provide 8 randomly sampled examples (4 per class) to the model and check the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T20:35:50.614412Z",
          "iopub.status.busy": "2024-12-28T20:35:50.614174Z",
          "iopub.status.idle": "2024-12-28T20:42:21.823854Z",
          "shell.execute_reply": "2024-12-28T20:42:21.822895Z",
          "shell.execute_reply.started": "2024-12-28T20:35:50.614385Z"
        },
        "id": "GO-put-jY7CW",
        "outputId": "cd7b03c3-ed4d-46da-ace8-5611feef16f7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Mistralv3_8_shot',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    shots=4,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAURpN5_oEsV"
      },
      "source": [
        "### Task 5.3 - Few shot with topK demonstration examples\n",
        "\n",
        "In this part, we aim to improve the selection of demonstration examples by using the Okapi BM25 score to rank and select the topK best examples for inclusion in the prompt.\n",
        "\n",
        "Given that our test set remains unchanged, we will identify the most \"similar\" examples to use as demonstrations for the model. Similarity can be defined in various ways, but in this case, we will use the Okapi BM25 score for ranking.\n",
        "\n",
        "The Okapi BM25 score is a ranking function used by search engines to rank documents based on their relevance to a given search query. Typically, it is employed in Information Retrieval (IR) systems to rank documents according to their relevance to a query.\n",
        "\n",
        "In our scenario, instead of a query, we have a set of examples. We will use the BM25 score to rank the relevance of each demonstration example concerning the entire test set. The score is calculated by evaluating the similarity between each demonstration and each element in the test set. These similarity scores are then averaged to obtain the final score for each demonstration. In this way, the final score will be the relevance of a given demonstration with respect to the entire test set.\n",
        "\n",
        "The intuition behind this approach is that the model will benefit more from examples that are more relevant to the test set highlighting the importance of the selection of the examples under the setting of In-Context Learning.\n",
        "\n",
        ">**Note** Since we are not allowed to change the prompt content, the only degree of freedom inside our setting is the selection of the demonstration examples. BM25 score is indeed a dataset-dependent approach and may not generalize well to other datasets. We believe that this is still a good showcase of the importance of selecting the best examples to prompt the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `top_k_demonstrations` function performs the aforementioned steps to select the topK best examples according to the BM25 score.\n",
        "\n",
        "In this case, k is set to 4 (thus extracting 4 positive and 4 negative examples) to provide the model with a balanced set of demonstrations. Each time we will just take a slice of the topK demonstrations to provide to the model so that in the 2-shot case we will take the first 1 demonstration per class, in the 4-shot case we will take the first 2 and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "detector.few_shot_experiment_bm25(\n",
        "    name='Mistralv3_2_shot_bm25',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    shots=1,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "detector.few_shot_experiment_bm25(\n",
        "    name='Mistralv3_4_shot_bm25',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    shots=2,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "detector.few_shot_experiment_bm25(\n",
        "    name='Mistralv3_8_shot_bm25',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    shots=4,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-l_ksVXLMDE"
      },
      "source": [
        "#### Learning by 2-shot with topK demonstration examples\n",
        "\n",
        "In this section we will provide the topK demonstration examples to the model and check the performance of the model with 2-shot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:42:21.881880Z",
          "iopub.status.busy": "2024-12-28T20:42:21.881673Z",
          "iopub.status.idle": "2024-12-28T20:52:14.842647Z",
          "shell.execute_reply": "2024-12-28T20:52:14.841723Z",
          "shell.execute_reply.started": "2024-12-28T20:42:21.881861Z"
        },
        "id": "rkc4vAlXv_gw",
        "outputId": "8e41830b-d15b-4067-a38e-b13ce84f7fe0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Mistralv3_2_shot_custom',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    custom_example_ids=topK_examples,\n",
        "    shots=1,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "928N3aykLPNJ"
      },
      "source": [
        "#### Learning by 4-shot with topK demonstration examples\n",
        "\n",
        "In this section we will provide the topK demonstration examples to the model and check the performance of the model with 4-shot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T20:52:14.847109Z",
          "iopub.status.busy": "2024-12-28T20:52:14.846853Z",
          "iopub.status.idle": "2024-12-28T21:01:01.025429Z",
          "shell.execute_reply": "2024-12-28T21:01:01.024543Z",
          "shell.execute_reply.started": "2024-12-28T20:52:14.847088Z"
        },
        "id": "hlVkL_ic3D14",
        "outputId": "708f942a-7607-42bc-e957-dbd066f1d03d",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Mistralv3_4_shot_custom',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    custom_example_ids=topK_examples,\n",
        "    shots=2,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U42p8NPWL0EO"
      },
      "source": [
        "#### Learning by 8-shot with topK demonstration examples\n",
        "\n",
        "In this section we will provide the topK demonstration examples to the model and check the performance of the model with 8-shot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:01:01.029918Z",
          "iopub.status.busy": "2024-12-28T21:01:01.029676Z",
          "iopub.status.idle": "2024-12-28T21:08:07.805225Z",
          "shell.execute_reply": "2024-12-28T21:08:07.804505Z",
          "shell.execute_reply.started": "2024-12-28T21:01:01.029895Z"
        },
        "id": "kgvxsyQ83XAy",
        "outputId": "420c5c66-2e3b-41d3-a81b-9020a5a43365",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Mistralv3_8_shot_custom',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    custom_example_ids=topK_examples,\n",
        "    shots=4,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:08:07.810262Z",
          "iopub.status.busy": "2024-12-28T21:08:07.810020Z",
          "iopub.status.idle": "2024-12-28T21:08:07.818992Z",
          "shell.execute_reply": "2024-12-28T21:08:07.818245Z",
          "shell.execute_reply.started": "2024-12-28T21:08:07.810240Z"
        },
        "id": "REsKX_yMlfFb",
        "outputId": "a2f750c8-2ade-4562-df73-3adca3c68097",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk4fkuU63rud"
      },
      "source": [
        "# Model 2 - Llama 3.1 8B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sBEW4Bt4XZc"
      },
      "source": [
        "## Task 1 - Model setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First of all, since the GPU memory is limited, we will delete the variable associated with the model. In this way, the variable will be moved to the heap memory thus allowing us to call the garbage collector to free the heap memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:21:43.883875Z",
          "iopub.status.busy": "2024-12-28T21:21:43.883591Z",
          "iopub.status.idle": "2024-12-28T21:21:43.887585Z",
          "shell.execute_reply": "2024-12-28T21:21:43.886628Z",
          "shell.execute_reply.started": "2024-12-28T21:21:43.883852Z"
        },
        "id": "pkMLSp8dlfFd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To be completely sure, we will also clear the cache of the GPU and then call the garbage collector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:21:45.185668Z",
          "iopub.status.busy": "2024-12-28T21:21:45.185338Z",
          "iopub.status.idle": "2024-12-28T21:21:45.525534Z",
          "shell.execute_reply": "2024-12-28T21:21:45.524709Z",
          "shell.execute_reply.started": "2024-12-28T21:21:45.185645Z"
        },
        "id": "2l2acxzNlfFd",
        "outputId": "85c7beb3-3d48-4a24-b214-c56f2882a2e9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Starting from this point, we will experiment with LLama 3.1 8B model. The model is loaded in the same way of the Mistral v3 using 8-bit quantization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231,
          "referenced_widgets": [
            "c3fbb07748d4401484c5bc660c069999",
            "58c1dcec11ba436f8e194fd6e9028732",
            "cd593e0d5cbd4a95b7a293fc672e458f",
            "dca2b2d544544178b6e94146a78942ae",
            "8b759e275c114c48842447b021321d5f",
            "40d30b719ff74703a12110df71e97981",
            "32cceb0bdd164546acfa4a4edc31097b"
          ]
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T21:21:54.135349Z",
          "iopub.status.busy": "2024-12-28T21:21:54.135037Z",
          "iopub.status.idle": "2024-12-28T21:29:15.992673Z",
          "shell.execute_reply": "2024-12-28T21:29:15.991763Z",
          "shell.execute_reply.started": "2024-12-28T21:21:54.135322Z"
        },
        "id": "JxLvpCzs31tB",
        "outputId": "95fed91c-de77-4e5e-a106-044e8c5a4160",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#load Llama3.1 8B model\n",
        "model_card = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
        "model, tokenizer = detector.load_model(model_card, with_4_bit=False)\n",
        "\n",
        "device = model.device\n",
        "print(f'Model loaded on {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iScyBUeZ4Sa_"
      },
      "source": [
        "## Task 2 - Prompt setup\n",
        "\n",
        "Prompt setup follows precisely the same steps as for the Mistral v3 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T21:30:14.279106Z",
          "iopub.status.busy": "2024-12-28T21:30:14.278756Z",
          "iopub.status.idle": "2024-12-28T21:30:14.488818Z",
          "shell.execute_reply": "2024-12-28T21:30:14.487964Z",
          "shell.execute_reply.started": "2024-12-28T21:30:14.279076Z"
        },
        "id": "HFjp7Bre4SAN",
        "outputId": "3eca832a-bfe0-4d65-f6dc-ed70854a8a23",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "prompts = detector.prepare_prompts(texts=df['text'], prompt_template=prompt, tokenizer=tokenizer)\n",
        "\n",
        "print(f\"Prompt example: \\n{tokenizer.decode(prompts[0].input_ids[0], skip_special_tokens=True)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B14-Hife4ffk"
      },
      "source": [
        "## Task 3 - Inference\n",
        "\n",
        "First we will generate the responses for the test dataset and process them to get the predictions. In this way we end up in having the zero-shot predictions for the Llama 3.1 8B model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:30:16.589924Z",
          "iopub.status.busy": "2024-12-28T21:30:16.589606Z",
          "iopub.status.idle": "2024-12-28T21:31:49.590917Z",
          "shell.execute_reply": "2024-12-28T21:31:49.590025Z",
          "shell.execute_reply.started": "2024-12-28T21:30:16.589895Z"
        },
        "id": "W_YXwBmeDy7l",
        "outputId": "52f910f8-96a0-4835-c157-bd922e37ab60",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "answers = detector.generate_responses(model=model, tokenizer=tokenizer, prompt_examples=prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:32:34.745716Z",
          "iopub.status.busy": "2024-12-28T21:32:34.745412Z",
          "iopub.status.idle": "2024-12-28T21:32:34.813613Z",
          "shell.execute_reply": "2024-12-28T21:32:34.813009Z",
          "shell.execute_reply.started": "2024-12-28T21:32:34.745693Z"
        },
        "id": "kZ8WN74e4ega",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "batch_predictions = [detector.process_response(response=item, tokenizer=tokenizer) for item in answers]\n",
        "generated_answers = [detector.get_generated_response(response=item, tokenizer=tokenizer) for item in answers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_predictions['Llama3_zero_shot_labels'] = batch_predictions\n",
        "models_predictions['Llama3_zero_shot_answers'] = generated_answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyy6Cb9a7iFi"
      },
      "source": [
        "## Task 4 - Metrics\n",
        "\n",
        "We can compute the metrics associated with the zero-shot Llama 3.1 8B model and add them to the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:32:55.042977Z",
          "iopub.status.busy": "2024-12-28T21:32:55.042656Z",
          "iopub.status.idle": "2024-12-28T21:32:55.079566Z",
          "shell.execute_reply": "2024-12-28T21:32:55.078831Z",
          "shell.execute_reply.started": "2024-12-28T21:32:55.042915Z"
        },
        "id": "YCaZEj3VlfFf",
        "outputId": "279fce7d-ecfa-4268-abaf-a946ecd35416",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "llama_base_metrics = detector.compute_metrics(responses=answers, y_true=original_labels, tokenizer=tokenizer)\n",
        "print(f\"Llama3 Zero-Shot Metrics: {llama_base_metrics}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:32:56.369897Z",
          "iopub.status.busy": "2024-12-28T21:32:56.369610Z",
          "iopub.status.idle": "2024-12-28T21:32:56.375240Z",
          "shell.execute_reply": "2024-12-28T21:32:56.374275Z",
          "shell.execute_reply.started": "2024-12-28T21:32:56.369873Z"
        },
        "id": "TbbHQg5WlfFf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Add the computed metrics to the metric dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'Llama3_0_shot', **llama_base_metrics}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6AQAD-S8xUr"
      },
      "source": [
        "## Task 5 - Few-shot Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TniAc_RPs8p1"
      },
      "source": [
        "### Task 5.1 - Few shot with randomly sampled examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSSUZfqA5dZ5"
      },
      "source": [
        "#### Learning by 2-shot randomly sampled examples\n",
        "\n",
        "In this section we will provide 2 randomly sampled examples (1 per class) to the model and check the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:47:03.859210Z",
          "iopub.status.busy": "2024-12-28T21:47:03.858848Z",
          "iopub.status.idle": "2024-12-28T21:48:49.093268Z",
          "shell.execute_reply": "2024-12-28T21:48:49.092394Z",
          "shell.execute_reply.started": "2024-12-28T21:47:03.859180Z"
        },
        "id": "io7Q75EAlfFg",
        "outputId": "95e6e381-729d-47b0-a4a7-6a8412e04341",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Llama3_2_shot',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    shots=1,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cTQNJHK84PF"
      },
      "source": [
        "#### Learning by 4-shot randomly sampled examples\n",
        "\n",
        "In this section we will provide 4 randomly sampled examples (2 per class) to the model and check the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:48:49.096980Z",
          "iopub.status.busy": "2024-12-28T21:48:49.096719Z",
          "iopub.status.idle": "2024-12-28T21:50:55.274034Z",
          "shell.execute_reply": "2024-12-28T21:50:55.273217Z",
          "shell.execute_reply.started": "2024-12-28T21:48:49.096946Z"
        },
        "id": "HnVClc6U8wTn",
        "outputId": "b7db7ef7-bafd-4f0d-9a30-8729430ab1b4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Llama3_4_shot',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    shots=2,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uaGQ3vL9UqQ"
      },
      "source": [
        "#### Learning by 8-shot randomly sampled examples\n",
        "\n",
        "In this section we will provide 8 randomly sampled examples (4 per class) to the model and check the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:50:55.278732Z",
          "iopub.status.busy": "2024-12-28T21:50:55.278513Z",
          "iopub.status.idle": "2024-12-28T21:53:29.155548Z",
          "shell.execute_reply": "2024-12-28T21:53:29.154620Z",
          "shell.execute_reply.started": "2024-12-28T21:50:55.278711Z"
        },
        "id": "7zG6LSBm9UL3",
        "outputId": "3a6387e6-8a43-4d77-dec0-7392325225c3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Llama3_8_shot',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    shots=4,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckkc8Dox9hiW"
      },
      "source": [
        "### Task 5.2 - Few shot with topK demonstration examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "top_k_sexist, top_k_non_sexist = detector.top_k_demonstrations(tokenizer=tokenizer, test_data=df, demonstrations=demonstrations, k=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then define a dictionary which will store the topK demonstration examples IDs allowing us to retrieve them inside the dataset. In this way we can pass only these top demonstration examples to the model to be included in the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "topK_examples = {\n",
        "    \"sexist\" : detector.local_to_global_idx(top_k_sexist, demonstrations, label_type='sexist'),\n",
        "    \"not_sexist\" : detector.local_to_global_idx(top_k_non_sexist, demonstrations, label_type='not sexist')\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-bpIPdhU9Cu"
      },
      "source": [
        "#### Learning by 2-shot with topK demonstration examples\n",
        "\n",
        "In this section we will provide the topK demonstration examples to the model and check the performance of the model with 2-shot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:53:29.162033Z",
          "iopub.status.busy": "2024-12-28T21:53:29.161775Z",
          "iopub.status.idle": "2024-12-28T21:55:13.414711Z",
          "shell.execute_reply": "2024-12-28T21:55:13.413921Z",
          "shell.execute_reply.started": "2024-12-28T21:53:29.162009Z"
        },
        "id": "ERtEAGzhlfFh",
        "outputId": "ae36821a-e888-4826-e7c2-d2766273f6ea",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Llama3_2_shot_custom',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    custom_example_ids=topK_examples,\n",
        "    shots=1,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMfyudXHVqNp"
      },
      "source": [
        "#### Learning by 4-shot with topK demonstration examples\n",
        "\n",
        "In this section we will provide the topK demonstration examples to the model and check the performance of the model with 4-shot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T21:55:13.416255Z",
          "iopub.status.busy": "2024-12-28T21:55:13.416029Z",
          "iopub.status.idle": "2024-12-28T21:57:07.222065Z",
          "shell.execute_reply": "2024-12-28T21:57:07.221253Z",
          "shell.execute_reply.started": "2024-12-28T21:55:13.416235Z"
        },
        "id": "5dH3hmLR-Bw3",
        "outputId": "142f42f8-e1ef-43f6-d612-7491380033e6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Llama3_4_shot_custom',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    custom_example_ids=topK_examples,\n",
        "    shots=2,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebU-gjSDWo5I"
      },
      "source": [
        "#### Learning by 8-shot with topK demonstration examples\n",
        "\n",
        "In this section we will provide the topK demonstration examples to the model and check the performance of the model with 8-shot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T21:57:07.223503Z",
          "iopub.status.busy": "2024-12-28T21:57:07.223227Z",
          "iopub.status.idle": "2024-12-28T21:59:37.412266Z",
          "shell.execute_reply": "2024-12-28T21:59:37.411518Z",
          "shell.execute_reply.started": "2024-12-28T21:57:07.223479Z"
        },
        "id": "QFL7Wh1t-Luj",
        "outputId": "0657af4d-695f-44f4-c4f1-8ba43f65c30b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "detector.few_shot_experiment(\n",
        "    name='Llama3_8_shot_custom',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=df,\n",
        "    demonstrations=demonstrations,\n",
        "    prompt_template=prompt_few_shot,\n",
        "    original_labels=original_labels,\n",
        "    models_predictions=models_predictions,\n",
        "    model_metrics=model_metrics,\n",
        "    custom_example_ids=topK_examples,\n",
        "    shots=4,\n",
        "    store_model_predictions=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "### Exporting the results\n",
        "\n",
        "Finally, we will export the results of the models in a CSV file so that we can analyze them later and plot all the confusion matrices of every model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:59:37.420922Z",
          "iopub.status.busy": "2024-12-28T21:59:37.420727Z",
          "iopub.status.idle": "2024-12-28T21:59:37.503346Z",
          "shell.execute_reply": "2024-12-28T21:59:37.502764Z",
          "shell.execute_reply.started": "2024-12-28T21:59:37.420904Z"
        },
        "id": "nAm3C6zfaJxI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "models_predictions.to_csv(f'{detector.CSV_FOLDER}{os.sep}models_predictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The same is performed for the metrics of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:59:37.504745Z",
          "iopub.status.busy": "2024-12-28T21:59:37.504461Z",
          "iopub.status.idle": "2024-12-28T21:59:37.509302Z",
          "shell.execute_reply": "2024-12-28T21:59:37.508472Z",
          "shell.execute_reply.started": "2024-12-28T21:59:37.504713Z"
        },
        "id": "lgb1w1LDaPId",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_metrics.to_csv(f'{detector.CSV_FOLDER}{os.sep}model_metrics.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHuT1a1GLJnd"
      },
      "source": [
        "# Task 6 -  Error Analysis and results comparison\n",
        "\n",
        "We are now interested in evaluating model responses and comparing their performance.\n",
        "\n",
        "This analysis helps us in understanding\n",
        "\n",
        "- Classification task performance gap: are the models good at this task?\n",
        "- Generation quality: which kind of responses do models generate?\n",
        "- Errors: which kind of mistakes do models do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kjEAHD4LJne"
      },
      "source": [
        "**Instructions**\n",
        "\n",
        "In order to get Task 6 points, we require you to:\n",
        "\n",
        "* Compare classification performance of selected LLMs in a Table.\n",
        "* Compute confusion matrices for selected LLMs.\n",
        "* Briefly summarize your observations on generated responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_p_value(pipeline1_preds : pd.Series, pipeline2_preds : pd.Series, true_labels: pd.Series):\n",
        "    \"\"\"\n",
        "    Compute the p-value for statistical significance of improvement between two binary classification pipelines.\n",
        "\n",
        "    Parameters:\n",
        "        pipeline1_preds (pd.Series): Predictions from pipeline 1 (binary values: 0 or 1).\n",
        "        pipeline2_preds (pd.Series): Predictions from pipeline 2 (binary values: 0 or 1).\n",
        "        true_labels (pd.Series): Ground truth labels (binary values: 0 or 1).\n",
        "\n",
        "    Returns:\n",
        "        float: The p-value for the McNemar's test.\n",
        "    \"\"\"\n",
        "    # Convert inputs to numpy arrays\n",
        "    pipeline1_preds = np.array(pipeline1_preds)\n",
        "    pipeline2_preds = np.array(pipeline2_preds)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    # Create the contingency table\n",
        "    both_correct = np.sum((pipeline1_preds == true_labels) & (pipeline2_preds == true_labels))\n",
        "    only_pipeline1_correct = np.sum((pipeline1_preds == true_labels) & (pipeline2_preds != true_labels))\n",
        "    only_pipeline2_correct = np.sum((pipeline1_preds != true_labels) & (pipeline2_preds == true_labels))\n",
        "    both_incorrect = np.sum((pipeline1_preds != true_labels) & (pipeline2_preds != true_labels))\n",
        "\n",
        "    contingency_table = np.array([[both_correct, only_pipeline2_correct],\n",
        "                                   [only_pipeline1_correct, both_incorrect]])\n",
        "\n",
        "    # Perform McNemar's test\n",
        "    result = mcnemar(contingency_table, exact=True)\n",
        "\n",
        "    return result.pvalue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction1 = models_predictions['Mistralv3_2_shot_labels']\n",
        "prediction2 = models_predictions['Mistralv3_2_shot_custom_labels']\n",
        "p_value = compute_p_value(prediction1, prediction2, models_predictions['original_labels'])\n",
        "\n",
        "significance_level = 0.05 # or 0.01 for even more significance probability \n",
        "\n",
        "if p_value < significance_level:\n",
        "    print(f\"{prediction1.name} and {prediction2.name} results ARE significantly different (p-value = {p_value:.4f}).\")\n",
        "else:\n",
        "    print(f\"{prediction1.name} and {prediction2.name} results are NOT significantly different (p-value = {p_value:.4f}).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nq55NqJGkZA2"
      },
      "source": [
        "### Task 6.1 - Performance evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX4l16sPldpk"
      },
      "source": [
        "In order to being able to analyze all the answer given by the LLMs without re running all the answer evaluation we saved all the data inside the `models_predictions.csv` dataset, that can be easily imported using pandas.\n",
        "\n",
        "\n",
        "We are gonna then proceed doing some evaluation of the model, and show what are the most common error and which model is the best performing one  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T21:59:37.546830Z",
          "iopub.status.busy": "2024-12-28T21:59:37.546553Z",
          "iopub.status.idle": "2024-12-28T21:59:37.593223Z",
          "shell.execute_reply": "2024-12-28T21:59:37.592415Z",
          "shell.execute_reply.started": "2024-12-28T21:59:37.546789Z"
        },
        "id": "wCs-nUEkkc3w",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "models_predictions = pd.read_csv(f'{detector.CSV_FOLDER}{os.sep}models_predictions.csv')\n",
        "model_metrics = pd.read_csv(f'{detector.CSV_FOLDER}{os.sep}model_metrics.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T21:59:37.594329Z",
          "iopub.status.busy": "2024-12-28T21:59:37.594023Z",
          "iopub.status.idle": "2024-12-28T21:59:37.603104Z",
          "shell.execute_reply": "2024-12-28T21:59:37.602417Z",
          "shell.execute_reply.started": "2024-12-28T21:59:37.594299Z"
        },
        "id": "JR-i3l97qJbw",
        "outputId": "341a879d-5088-413b-cf20-872241fb5796",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Sort the dataframe by accuracy in descending order\n",
        "model_metrics_sorted = model_metrics.sort_values('accuracy', ascending=False)\n",
        "\n",
        "# Display the sorted scores\n",
        "model_metrics_sorted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHbPEudylwqi"
      },
      "source": [
        "When comparing **Mistral v3 4-shot** with the **Mistral v3 zero shot** (base-model), there is a significant difference in performance. The Mistral model promped with a 4 shot technique scored an accuracy of 0.75, while the Mistral v3 model promped with a zero-shot technique scored 0.613. This substantial improvement can be attributed to the additional context provided by the four examples, which enhances the model's predictive accuracy. In contrast, the zero-shot model relies solely on its pre-trained knowledge without specific examples to guide its predictions, resulting in lower performance.\n",
        "\n",
        "However, increasing the number of examples in the prompt beyond a certain point can significantly decrease the model's performance. This decline can be due to several factors, such as context overload where the model struggles to process too much information, and the introduction of noise and variability from additional examples. These factors can overwhelm the model, reducing its ability to generalize and make accurate predictions.\n",
        "\n",
        "From this empiric expents we shown that  while some additional context is beneficial, too many examples can be detrimental to the model's performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp6UX2_hkGAF"
      },
      "source": [
        "### Task 6.2 - Model performace evaluation with zero shot inference\n",
        "To begin the error analysis, we first evaluate which model performed better using zero-shot inference. This initial step is crucial as it allows us to identify the most effective model without any prior training on specific examples. By determining the best-performing model in a zero-shot context, we establish a strong baseline for comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-28T22:05:18.241327Z",
          "iopub.status.busy": "2024-12-28T22:05:18.241019Z",
          "iopub.status.idle": "2024-12-28T22:05:18.248641Z",
          "shell.execute_reply": "2024-12-28T22:05:18.247694Z",
          "shell.execute_reply.started": "2024-12-28T22:05:18.241303Z"
        },
        "id": "WHbCXr2SrKeZ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def print_models_confusion_matrix(models_list, models_predictions):\n",
        "\n",
        "  figsize_x = len(models_list) * 8\n",
        "  figsize_y = 5\n",
        "  fig, axes = plt.subplots(1, len(models_list), figsize=(figsize_x, figsize_y))\n",
        "\n",
        "  actual = models_predictions['original_labels']\n",
        "\n",
        "  for i, model in enumerate(models_list):\n",
        "\n",
        "    predicted = models_predictions[model]\n",
        "    cm = confusion_matrix(actual, predicted)\n",
        "    cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"not sexist\", \"sexist\"])\n",
        "\n",
        "    cm_display.plot(ax=axes[i])\n",
        "    axes[i].set_title(model)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def print_misslabeled_tweets(model_name, model_list, misslabel_type=\"fp\", text_limit=10):\n",
        "  if misslabel_type == 'fp':\n",
        "    print(f\"Not sexist labeled tweet classified as sexist by {model_name}\")\n",
        "    flag = 0\n",
        "  elif misslabel_type == 'fn':\n",
        "    print(f\"Sexist labeled tweet classified as not sexist by {model_name}\")\n",
        "    flag = 1\n",
        "  else:\n",
        "    print(f\"ERROR, misslabel_type must be set to 'fp'or 'fn'\")\n",
        "    return\n",
        "\n",
        "  for model in model_list:\n",
        "    miss_labeled = models_predictions[models_predictions['original_labels'] != models_predictions[model]]\n",
        "    filtered_df = miss_labeled[miss_labeled['original_labels'] == flag]\n",
        "\n",
        "    print(f\"\\nAnalyzing {model}:\")\n",
        "    for i, (row_index, row) in enumerate(filtered_df.iterrows()):\n",
        "      print(f\"row {row_index}) {row['text']} \")\n",
        "      if i >= text_limit:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        },
        "execution": {
          "iopub.execute_input": "2024-12-28T22:05:29.326944Z",
          "iopub.status.busy": "2024-12-28T22:05:29.326609Z",
          "iopub.status.idle": "2024-12-28T22:05:29.775706Z",
          "shell.execute_reply": "2024-12-28T22:05:29.774483Z",
          "shell.execute_reply.started": "2024-12-28T22:05:29.326918Z"
        },
        "id": "3uMU30ZQeYMs",
        "outputId": "a1f26459-f0b0-4246-f72c-c408a583a097",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print_models_confusion_matrix(['Mistralv3_zero_shot_labels', 'Llama3_zero_shot_labels'], models_predictions)\n",
        "\n",
        "zero_shot_df = model_metrics[model_metrics['model'].str.contains('zero shot', case=False)]\n",
        "zero_shot_df.sort_values('accuracy', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwuPtOaRfBVK"
      },
      "source": [
        "LLaMA 3 outperforms Mistral v3 in zero-shot inference.\n",
        "The confusion matrix reveals that most errors made by both models involve misclassifying non-sexist tweets as sexist.\n",
        "\n",
        "Notably, Mistral v3 misclassifies over 75% of non-sexist tweets as sexist, whereas LLaMA 3 misclassifies only 64% of non-sexist tweets as sexist.\n",
        "Additionally, only a very small portion of comments classified as sexist are misclassified as non-sexist: 1.3% for Mistral v3 and 4.7% for LLaMA 3.\n",
        "\n",
        "This discrepancy may be due to several factors. The training data might be imbalanced, with more examples of sexist comments, leading to better recognition of sexist patterns. Sexist comments could also have more distinctive linguistic features, making them easier to identify. Additionally, biases in annotation and the need for nuanced understanding of non-sexist comments might contribute to the models' difficulties.\n",
        "\n",
        "One possible reason for the models being trained on unbalanced data is that the developers aimed to address the generation of unsuitable content. The techniques employed to prevent the generation of such content might have inadvertently led to a significant imbalance between the recognition of the two classes. This imbalance could result in the models being more adept at identifying one class over the other, thus affecting their overall performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHudvuHckxvk",
        "outputId": "262a17d9-b8e0-46a5-f969-de66425cc34e"
      },
      "outputs": [],
      "source": [
        "print_misslabeled_tweets('Mistralv3', ['Mistralv3_zero_shot_labels'], misslabel_type=\"fn\", text_limit=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txc_B5gymLWV",
        "outputId": "661cf93a-ff79-42c8-9d34-9d3c11867319"
      },
      "outputs": [],
      "source": [
        "print_misslabeled_tweets('Llama3', ['Llama3_zero_shot_labels'], misslabel_type=\"fn\", text_limit=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMvwKsjmktv2"
      },
      "source": [
        "The comments misclassified by Mistral v3 are clearly mislabeled, whereas those misclassified by LLaMA 3 are clearly false negatives. This suggests that Mistral v3 received training that better enables it to identify sexist comments compared to LLaMA 3. This difference in performance may be attributed to the specific techniques used during training, which might have focused more on recognizing and preventing the generation of unsuitable content. Consequently, this focus could have led to an imbalance in the training data, enhancing Mistral v3's ability to detect sexist comments but also increasing the likelihood of misclassifying non-sexist comments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA4LOEw5m5qy"
      },
      "source": [
        "### Task 6.3 - Model performance evaluation with few shot inference\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYdduFX3W32e"
      },
      "source": [
        "In the next session, we will compare the performance of the base models with various few-shot techniques. The base model will serve as a baseline to evaluate the extent of improvements achieved through few-shot prompting. We aim to determine whether a model that performs poorly with zero-shot inference can improve when provided with a few examples in the prompt. Additionally, we will identify the most effective few-shot technique for the task of labeling comments as sexist or non-sexist. This analysis will help us understand the potential of few-shot learning in enhancing model accuracy for this specific classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-E0qrkKYwDh"
      },
      "source": [
        "#### Few shot with ramdomly sampled examplse from the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "KJXmivjBwIjz",
        "outputId": "13dccef8-c0ef-4a96-e39d-65fd0d29efe3"
      },
      "outputs": [],
      "source": [
        "mistral_models_labels = ['Mistralv3_zero_shot_labels', 'Mistralv3_2_shot_labels', 'Mistralv3_4_shot_labels', 'Mistralv3_8_shot_labels']\n",
        "print_models_confusion_matrix(mistral_models_labels, models_predictions)\n",
        "mistral_base_prompting =  model_metrics[model_metrics['model'].str.contains('Mistral', case=False) & ~model_metrics['model'].str.endswith('custom')]\n",
        "mistral_base_prompting.sort_values('accuracy', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMdSkEkRbpmB"
      },
      "source": [
        "The results indicate that Mistral v3's performance improves with two-shot examples, achieving an accuracy of 0.693333 compared to the zero-shot baseline of 0.613333. However, increasing the number of examples to four or eight does not yield further improvements, with the eight-shot model performing identically to the zero-shot model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "fPIxBGqCcrl8",
        "outputId": "e6dc57b6-ec03-41df-f092-2704cdc58cfb"
      },
      "outputs": [],
      "source": [
        "llama_models_labels = ['Llama3_zero_shot_labels', 'Llama3_2_shot_labels', 'Llama3_4_shot_labels', 'Llama3_8_shot_labels']\n",
        "print_models_confusion_matrix(llama_models_labels, models_predictions)\n",
        "llama3_base_prompting =  model_metrics[model_metrics['model'].str.contains('Llama3', case=False) & ~model_metrics['model'].str.endswith('custom')]\n",
        "llama3_base_prompting.sort_values('accuracy', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le0Eyc9AfqI7"
      },
      "source": [
        "The table shows that LLaMA 3's performance improves with two-shot and four-shot examples, achieving the highest accuracy of 0.690000 with four-shot examples. However, the eight-shot model performs worse than the zero-shot model, with a decline in accuracy to 0.623333. This suggests that while a few examples can enhance performance, too many examples can degrade it.\n",
        "\n",
        "\n",
        "We suspect that the inconsistent performance in both models is due to the poor quality of the examples used in multiple-shot learning. These examples were randomly extracted from the dataset, which may have led to suboptimal training and the observed lack of improvement. It is important to note that, despite being random, the models were prompted with the same textual prompt for each respective prompting technique.\n",
        "\n",
        "To eliminate the potential problems associated with random selection and better assess the models' performance and to verify the previus claims, we conducted another evaluation of the prompt. This time, the examples injected into the prompt were manually checked by us in order to avoid issues arising from mislabeled or non-meaningful examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFK_mzpujbDJ"
      },
      "source": [
        "#### Few shot with topK demonstration examples from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "kq8lznLKdG6G",
        "outputId": "776d96a0-b378-4e45-92e6-7cb75c1343da"
      },
      "outputs": [],
      "source": [
        "mistral_models_labels = ['Mistralv3_zero_shot_labels', 'Mistralv3_2_shot_custom_labels', 'Mistralv3_4_shot_custom_labels', 'Mistralv3_8_shot_custom_labels']\n",
        "print_models_confusion_matrix(mistral_models_labels, models_predictions)\n",
        "mistral_base_prompting = model_metrics[model_metrics['model'].str.contains('Mistral', case=False) &\n",
        "                                                    (model_metrics['model'].str.endswith('custom') | model_metrics['model'].str.endswith('zero shot'))]\n",
        "mistral_base_prompting.sort_values('accuracy', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "_yNc_Yq9dXGN",
        "outputId": "bdd6e9e6-d161-432d-f99e-210a9fea2404"
      },
      "outputs": [],
      "source": [
        "llama_models_labels = ['Llama3_zero_shot_labels', 'Llama3_2_shot_custom_labels', 'Llama3_4_shot_custom_labels', 'Llama3_8_shot_custom_labels']\n",
        "print_models_confusion_matrix(llama_models_labels, models_predictions)\n",
        "mistral_base_prompting = model_metrics[model_metrics['model'].str.contains('Llama3', case=False) &\n",
        "                                                    (model_metrics['model'].str.endswith('custom') | model_metrics['model'].str.endswith('zero shot'))]\n",
        "mistral_base_prompting.sort_values('accuracy', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcGnr1J-Qory"
      },
      "source": [
        "The performance of Mistral v3 and LLaMA 3 with manually labeled examples in the prompt shows significant improvements over their zero-shot baselines. For Mistral v3, the zero-shot model has an accuracy of 0.61 and a fail ratio of 0.38. With two-shot manually labeled examples, the accuracy improves to 0.64, and further increases to 0.67 with four-shot examples. The eight-shot model achieves the highest accuracy of 0.72 and the lowest fail ratio of 0.28.\n",
        "\n",
        "Similarly, LLaMA 3's zero-shot model has an accuracy of 0.65 and a fail ratio of 0.34. The accuracy slightly improves to 0.65 with two-shot examples and further to 0.66 with four-shot examples. The eight-shot model achieves an accuracy of 0.66, which is slightly lower than the four-shot model but still better than the zero-shot baseline.\n",
        "\n",
        "These results confirm that manually labeled examples significantly enhance the performance of both models compared to randomly selected examples, highlighting the importance of carefully choosing the examples to be injected into the prompt."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZIKbtOwWtPh"
      },
      "source": [
        "### Task 6.4 Best prompting technique error analisys  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U46u1_X3mUgP"
      },
      "source": [
        "The objective of this section is to visualize the errors made by the two models using their best prompting techniques identified in the previous section. This analysis will help us identify the types of errors most commonly committed by the models, providing insights into areas where further improvements are needed.\n",
        "\n",
        "We start analysing the comment misslcassified as non sexist (false negative)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaHe3izlV93M",
        "outputId": "3deb1a1b-b3d2-4310-e234-68e80c3592ce"
      },
      "outputs": [],
      "source": [
        "print_misslabeled_tweets('Mistralv3', [\"Mistralv3_8_shot_custom_labels\"], misslabel_type=\"fn\", text_limit=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqrsu8GsRih5",
        "outputId": "fa91ed29-b56f-4418-d8e4-92998d4bdbe5"
      },
      "outputs": [],
      "source": [
        "print_misslabeled_tweets('Llama3', [\"Llama3_4_shot_custom_labels\"], misslabel_type=\"fn\", text_limit=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lt0aVM2QeMA"
      },
      "source": [
        "Add comment here of the false negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoZWrCC2QdxN",
        "outputId": "94b3e481-7026-42a6-a6eb-ce60da980e4d"
      },
      "outputs": [],
      "source": [
        "print_misslabeled_tweets('Mistralv3', [\"Mistralv3_8_shot_custom_labels\"], misslabel_type=\"fp\", text_limit=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syFNva4dW4GB",
        "outputId": "3e0e61b2-ce9e-401d-e109-4d593582d332"
      },
      "outputs": [],
      "source": [
        "print_misslabeled_tweets('Llama3', [\"Llama3_4_shot_custom_labels\"], misslabel_type=\"fp\", text_limit=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QWlVXJgLJne"
      },
      "source": [
        "# Task 7 - Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fsdV99TLJne"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-hUXYaLLJne"
      },
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves in Figure format.\n",
        "* The error analysis section should summarize your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fURV8zfPLJne"
      },
      "source": [
        "# Submission\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "* **Submit** your python notebook.\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn1tUeYzLJne"
      },
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYAOVGvKhtTQ"
      },
      "source": [
        "### Model cards\n",
        "\n",
        "You can pick any open-source model card you like.\n",
        "\n",
        "We recommend starting from those reported in this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWG72N-LLJne"
      },
      "source": [
        "### Implementation\n",
        "\n",
        "Everything can be done via ``transformers`` APIs.\n",
        "\n",
        "However, you are free to test frameworks, such as [LangChain](https://www.langchain.com/), [LlamaIndex](https://www.llamaindex.ai/) [LitParrot](https://github.com/awesome-software/lit-parrot), provided that you correctly address task instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cplnq3dLJne"
      },
      "source": [
        "### Bonus Points\n",
        "\n",
        "0.5 bonus points are arbitrarily assigned based on significant contributions such as:\n",
        "\n",
        "- Outstanding error analysis\n",
        "- Masterclass code organization\n",
        "- Suitable extensions\n",
        "- Evaluate A1 dataset and perform comparison\n",
        "\n",
        "Note that bonus points are only assigned if all task points are attributed (i.e., 6/6)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coy_pJ40LJne"
      },
      "source": [
        "### Prompt Template\n",
        "\n",
        "Do not change the provided prompt template.\n",
        "\n",
        "You are only allowed to change it in case of a possible extension."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSiH0Xqj79wc"
      },
      "source": [
        "### Optimizations\n",
        "\n",
        "Any kind of code optimization (e.g., speedup model inference or reduce computational cost) is more than welcome!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jpr-LSK7LJnh"
      },
      "source": [
        "# The End"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30823,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "014baa6da7184be38baccde7905ba1ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01a966d833764428beb9eb27ca9e66ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02db4ca1d06240e3a8464de7583e50d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d431770b8e742d097eacabaaf021612",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74c1ad5ae6a646eab554f9df2e831f5d",
            "value": 3
          }
        },
        "03706daf585e4925b4b8ff3cdea8da4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070bc0be124b425383339e1e1e4345a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c92115bffe84ae69056998a6230e17a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cdd166cdab34680bf4073de7ab66734": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0cfd0ba75b3a41158dad72ee67f82e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b1452393ee435497e6cabf451f5e16",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f086c3e01d764d0b80d4c72c186d345e",
            "value": 300
          }
        },
        "10e1689b054f4045a27262d695fa6970": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f33bfb43e73b42e49f58ab212d5968af",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1fd6d85a0f8f4be5936650333629c87d",
            "value": "â€‡414/414â€‡[00:00&lt;00:00,â€‡29.3kB/s]"
          }
        },
        "13499f7313134e7ca62a532fedc63935": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "136c81e4f9ac47dd9977393eb2bd3f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff1b1bed15ca4f19bdbe515c90315b0f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_93545824c8d344e1ab999608079211b1",
            "value": "Downloadingâ€‡shards:â€‡100%"
          }
        },
        "139343a7a50c4157b6ee591fe2989dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1696b5d3810e49e3a6cc561a318f959c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16b1452393ee435497e6cabf451f5e16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19549c07581f4278bf802be3babda7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c2202f66d9f43718eb6f06fad444ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_793a7c6c811f437083fa8966506c59d6",
              "IPY_MODEL_a88fa8d92a7e4985a16056568751c96f",
              "IPY_MODEL_c17106b93e6d405bb59ab7501ca278cf"
            ],
            "layout": "IPY_MODEL_33ddabd699d24a5e8f1280da3b6c9ae0"
          }
        },
        "1da98c60074e47be8bf1878202f318d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1fd6d85a0f8f4be5936650333629c87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23ba882e113846d08ab8477badade4b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23d525aeaa9346758a9a6f30e3ac36c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4d09a4ddcfa404685b4262b46535e44",
            "max": 601,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2fbd239a5694809ade9f572317a9d5c",
            "value": 601
          }
        },
        "29011283fb684c92b1514af8ecfed00d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29f2d35361a54f3c8ade9658fe393159": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c101e3822164cb5819db2d5b8d53c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d00ddd632274ce287a9f496f8240a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e3ec463febf4247a46713cc0e541dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c90816ffb284abb9e06338ef503a388",
              "IPY_MODEL_a3044c90edc1439c975d781db74d34ce",
              "IPY_MODEL_5924a914d5d4402b9d16abaa65d79122"
            ],
            "layout": "IPY_MODEL_4cd9b0a4a06948bb9061a8e13c4e2b36"
          }
        },
        "326fbebbf7a04fc185ca8e60f8102f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87326148b4e448e8833b7ef49160f5d6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7f097d11ba024ed78304aa75c9fec82e",
            "value": "config.json:â€‡100%"
          }
        },
        "33ddabd699d24a5e8f1280da3b6c9ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33fe0340c8444e66baa57791e5b78b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29011283fb684c92b1514af8ecfed00d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_679dad99050f4752894873f340cb28ec",
            "value": "tokenizer.model:â€‡100%"
          }
        },
        "378cab34ebc84d19b5d1bc2a5b821b81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b9d27c191c4b3da761602e76f8357c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38ef02aef23f465082823c1c3a55892d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a6d00a0e8664b798bebc7e07eac63c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ae253a883ea434b876678caba0e422f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e31371665be4ebba2a9a4fc6ad20988",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_13499f7313134e7ca62a532fedc63935",
            "value": "â€‡601/601â€‡[00:00&lt;00:00,â€‡42.4kB/s]"
          }
        },
        "3d0d2d2f777042a080a1e51a12d97e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef89f853f3f54571ac81284dc8d91ee4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7c84e274297d47fcabad476c2bad98a5",
            "value": "Connecting..."
          }
        },
        "3e73fb6444fe4c37a84e8d8a3166d81f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9922cee19aea466e8d35ae2bb12c5704",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b5d7268e12f24b52a9c78fb67aa91bb2",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "40eaf3df6eeb4c27a00d05aa0b0cb8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41885048145548d5898ff07bc70a0c64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45e5574034df4a78a02e011f27afaea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbbca39e31e14a928d7dbaceb853094c",
              "IPY_MODEL_46a80def55984e998ec8d25942937e65",
              "IPY_MODEL_10e1689b054f4045a27262d695fa6970"
            ],
            "layout": "IPY_MODEL_4f00afd02d8e4f92b6c57fa4b07d4d5d"
          }
        },
        "46a80def55984e998ec8d25942937e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a085448595148e2852b6b29f6e33d74",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c101e3822164cb5819db2d5b8d53c28",
            "value": 414
          }
        },
        "4749732f61bc4e9187ff9b73ed1ac326": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48ae5b8e2db14c719d1ce2df3c68c503": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "4af40d2cb18342378b31634d7b4f6c44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b576ac2b32b47569d1d2f657a1faddf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b71317122a44cff801f2124cd8182f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cd9b0a4a06948bb9061a8e13c4e2b36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f00afd02d8e4f92b6c57fa4b07d4d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51360958ec1848449cc1e660696cc089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a6409687e9a4517befc6dd7f9090be3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4b71317122a44cff801f2124cd8182f4",
            "value": "â€‡116/116â€‡[00:00&lt;00:00,â€‡6.92kB/s]"
          }
        },
        "532e49cbb43e41d1a90aeea73dab64e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53e5631f7fe840e5a8cb6b866128e289": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "566f69e1aaad4befa54bde823530dd79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56f90dbf06e94da99646800855b93fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_29f2d35361a54f3c8ade9658fe393159",
            "style": "IPY_MODEL_1696b5d3810e49e3a6cc561a318f959c",
            "value": false
          }
        },
        "573b22dabd8b48c69b2f33412ac12f82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a5ddce0c2f4e15a0f5c96bd54bc582": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5924a914d5d4402b9d16abaa65d79122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67fe55893d3d42acb4a0834886779e8a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7cfb55d2c8e3461bb6ab3c506586d40f",
            "value": "â€‡23.9k/23.9kâ€‡[00:00&lt;00:00,â€‡553kB/s]"
          }
        },
        "5f0d7e2219394a65acd584d2da7be07c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f18d58d903e4acbbb83cdfddfa39d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef5f43fe138643ebb7cf47ec0441b18d",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa29655c8e364403b93fc7843552d593",
            "value": 116
          }
        },
        "631af03304b7489d914cbf92179e3589": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6405bd33d63a4d01874ba4c9e0d80334": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_378cab34ebc84d19b5d1bc2a5b821b81",
            "max": 587404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cdd166cdab34680bf4073de7ab66734",
            "value": 587404
          }
        },
        "645cdf9d6e3c42efa529f422b9104e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e2b468d6d34adfbd3e8a766ae33a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba3723bd7a61465082c5e855307fe864",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2d00ddd632274ce287a9f496f8240a85",
            "value": "â€‡5.00G/5.00Gâ€‡[01:58&lt;00:00,â€‡42.2MB/s]"
          }
        },
        "679dad99050f4752894873f340cb28ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67fe55893d3d42acb4a0834886779e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a085448595148e2852b6b29f6e33d74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cec09cbe65a4bac8d76a2419507d4c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f676cb45031c4a6b8763d83e161879a7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_532e49cbb43e41d1a90aeea73dab64e4",
            "value": "model-00003-of-00003.safetensors:â€‡100%"
          }
        },
        "6e31371665be4ebba2a9a4fc6ad20988": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fb1bfea101648abad6443367659b5c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fee44c9704f14a45a3c54b1b9f81c0d5",
              "IPY_MODEL_d0e9118f6a294629901d1f75fbc9379b",
              "IPY_MODEL_ad141eda52a94c5198d520de981a1882"
            ],
            "layout": "IPY_MODEL_41885048145548d5898ff07bc70a0c64"
          }
        },
        "707bbc12cdf34926a7d6c004a90fddb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01a966d833764428beb9eb27ca9e66ac",
            "max": 140874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4749732f61bc4e9187ff9b73ed1ac326",
            "value": 140874
          }
        },
        "74c1ad5ae6a646eab554f9df2e831f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "793a7c6c811f437083fa8966506c59d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f0d7e2219394a65acd584d2da7be07c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_40eaf3df6eeb4c27a00d05aa0b0cb8e9",
            "value": "model-00001-of-00003.safetensors:â€‡100%"
          }
        },
        "799f3b1e67db4da79fd568ff08f93310": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_573b22dabd8b48c69b2f33412ac12f82",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_dcbdaf0087974386bd528db17f0e47fb",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7a6409687e9a4517befc6dd7f9090be3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c84e274297d47fcabad476c2bad98a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c90816ffb284abb9e06338ef503a388": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d361d076dd34acfbe8bbfd090557784",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d6dc5923c5d1460aa5b7942d1dbe3b30",
            "value": "model.safetensors.index.json:â€‡100%"
          }
        },
        "7cfb55d2c8e3461bb6ab3c506586d40f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d431770b8e742d097eacabaaf021612": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f097d11ba024ed78304aa75c9fec82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fbf7300e0b04706aa7e7174a7932e5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83919ed633074a41b10cb19b437a1cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4f975cd13841959d7f86954290e410",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_566f69e1aaad4befa54bde823530dd79",
            "value": "â€‡1.96M/1.96Mâ€‡[00:00&lt;00:00,â€‡4.46MB/s]"
          }
        },
        "8605f3de15c747e3b8a91418ecfad922": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87326148b4e448e8833b7ef49160f5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4f975cd13841959d7f86954290e410": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8acbc26eca184a8a8cee960c70b05ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8611ce898b4440a7f5685c9a2110d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "906fec0adf4644d5b256c00ee7ff8ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f797239b31ff47119dbc1478ffb8b1d6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8605f3de15c747e3b8a91418ecfad922",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "9082afc9336f45c09e8c9f558386dfb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_326fbebbf7a04fc185ca8e60f8102f08",
              "IPY_MODEL_23d525aeaa9346758a9a6f30e3ac36c8",
              "IPY_MODEL_3ae253a883ea434b876678caba0e422f"
            ],
            "layout": "IPY_MODEL_7fbf7300e0b04706aa7e7174a7932e5d"
          }
        },
        "93545824c8d344e1ab999608079211b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95cc2f53b48143a19ee9535c429edcea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_906fec0adf4644d5b256c00ee7ff8ed9",
              "IPY_MODEL_5f18d58d903e4acbbb83cdfddfa39d0c",
              "IPY_MODEL_51360958ec1848449cc1e660696cc089"
            ],
            "layout": "IPY_MODEL_d11d471487d644afa77b8a3eabcc70a7"
          }
        },
        "9645f62f81e54311bf28dca6e326fc85": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98e2609c40734c02844521ed7aa913da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9922cee19aea466e8d35ae2bb12c5704": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99c07023bc5e4fd4b3e9239a01c47ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_070bc0be124b425383339e1e1e4345a3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c4e2938c32b447c4bd001bf08463cfc0",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "9ce5dcc4380342ea8b86851216f5d28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdb672ccb2cc43a0b92af7867bb9374a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f905c709308c4f538ddb13f65f5c54cb",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "9d361d076dd34acfbe8bbfd090557784": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e6c1b6464624743b97745a9f3384a38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a078a0446362449c912df1ca7d91e2a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2dcefc86aa94809a250702cf1d41dbc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_014baa6da7184be38baccde7905ba1ae",
            "value": "â€‡4.55G/4.55Gâ€‡[01:48&lt;00:00,â€‡39.7MB/s]"
          }
        },
        "a13162d1ad2a4b08be7049ee1c769815": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3044c90edc1439c975d781db74d34ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9645f62f81e54311bf28dca6e326fc85",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af134f8efc514910b31959193380477a",
            "value": 23950
          }
        },
        "a46fcfcd0136402895074ecd171f7ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a6d00a0e8664b798bebc7e07eac63c4",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e43c93543e8e40639a85a3cab07ebd41",
            "value": "â€‡0/300â€‡[00:00&lt;?,â€‡?it/s]"
          }
        },
        "a4d09a4ddcfa404685b4262b46535e44": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6e94766f4444e1db218779be8d644d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a88fa8d92a7e4985a16056568751c96f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4af40d2cb18342378b31634d7b4f6c44",
            "max": 4949453792,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d239d39e287e4e029456c429d4e4830b",
            "value": 4949453792
          }
        },
        "aa29655c8e364403b93fc7843552d593": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab9e24119e514ba6b83b6a01774a08ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad141eda52a94c5198d520de981a1882": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f8611ce898b4440a7f5685c9a2110d0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ebabcafabaea4a7c9e78abf250ea888f",
            "value": "â€‡3/3â€‡[01:05&lt;00:00,â€‡21.47s/it]"
          }
        },
        "ad18037f907c45c0b06d01c321ec9ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af134f8efc514910b31959193380477a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af23346b567f406481d1233a6d41fd37": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b1f8f2767ffd4277a3699eb5dd4768d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_bedd9eea5c1144558a533a6ead9934eb",
            "style": "IPY_MODEL_e4be8f67411045418f54977f3aa26001",
            "tooltip": ""
          }
        },
        "b51abf5140b14f868360d1f369443205": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5d7268e12f24b52a9c78fb67aa91bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba3723bd7a61465082c5e855307fe864": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8066b897c34a08a7e598f1ff415581": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_33fe0340c8444e66baa57791e5b78b7c",
              "IPY_MODEL_6405bd33d63a4d01874ba4c9e0d80334",
              "IPY_MODEL_e55cbf7058034c77aa3732114a3062bc"
            ],
            "layout": "IPY_MODEL_4b576ac2b32b47569d1d2f657a1faddf"
          }
        },
        "bedd9eea5c1144558a533a6ead9934eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c17106b93e6d405bb59ab7501ca278cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c54ed8a8467642fc88b4761f17827eca",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_631af03304b7489d914cbf92179e3589",
            "value": "â€‡4.95G/4.95Gâ€‡[01:57&lt;00:00,â€‡41.2MB/s]"
          }
        },
        "c1846a9dcb564594af39e1ec59c55b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_48ae5b8e2db14c719d1ce2df3c68c503"
          }
        },
        "c38dbfc357204d7fb9d39b20d0a7f31b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4e2938c32b447c4bd001bf08463cfc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c54ed8a8467642fc88b4761f17827eca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca1b458b63c2469087a48b9671817bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc273064518d4a00b9124d5c1f46cb2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5f0ba3e1b0846b6848ed9060d3f21d4",
              "IPY_MODEL_0cfd0ba75b3a41158dad72ee67f82e08",
              "IPY_MODEL_a46fcfcd0136402895074ecd171f7ff2"
            ],
            "layout": "IPY_MODEL_af23346b567f406481d1233a6d41fd37"
          }
        },
        "cc8ebb87f20d41c3aa2c6586300e26a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c38dbfc357204d7fb9d39b20d0a7f31b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ddf4597c344c496ea14b590c975fd5e5",
            "value": "model-00002-of-00003.safetensors:â€‡100%"
          }
        },
        "cdb672ccb2cc43a0b92af7867bb9374a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfffe93c1c21468fae715a221ca621c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99c07023bc5e4fd4b3e9239a01c47ef8",
              "IPY_MODEL_fc786a345cf84842a3bf45a892fe0472",
              "IPY_MODEL_83919ed633074a41b10cb19b437a1cf6"
            ],
            "layout": "IPY_MODEL_03706daf585e4925b4b8ff3cdea8da4b"
          }
        },
        "d0e9118f6a294629901d1f75fbc9379b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6e458302d9e43cdb49f6902669b3378",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1da98c60074e47be8bf1878202f318d6",
            "value": 3
          }
        },
        "d11d471487d644afa77b8a3eabcc70a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d14c60256ed349408bbea3fd8627099a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18296a6e2d241b6b6add26b66b4aed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_645cdf9d6e3c42efa529f422b9104e1b",
            "max": 4999819336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec612d375113460b9672dbd4ee4232a8",
            "value": 4999819336
          }
        },
        "d239d39e287e4e029456c429d4e4830b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2dcefc86aa94809a250702cf1d41dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2fbd239a5694809ade9f572317a9d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5f0ba3e1b0846b6848ed9060d3f21d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c92115bffe84ae69056998a6230e17a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_23ba882e113846d08ab8477badade4b7",
            "value": "â€‡â€‡0%"
          }
        },
        "d6dc5923c5d1460aa5b7942d1dbe3b30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8727efa45544e369527ad890a0fd0f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8acbc26eca184a8a8cee960c70b05ce7",
            "max": 4546807800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19549c07581f4278bf802be3babda7ea",
            "value": 4546807800
          }
        },
        "dcbdaf0087974386bd528db17f0e47fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddf4597c344c496ea14b590c975fd5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3baddf68f814e8e966639db841c4853": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_fc154e11eed946a3b94e8e9d34e37763",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ca1b458b63c2469087a48b9671817bcb",
            "value": ""
          }
        },
        "e43c93543e8e40639a85a3cab07ebd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4be8f67411045418f54977f3aa26001": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e52242c71523404bbba94c882f03f38e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e55cbf7058034c77aa3732114a3062bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a5ddce0c2f4e15a0f5c96bd54bc582",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ad18037f907c45c0b06d01c321ec9ac3",
            "value": "â€‡587k/587kâ€‡[00:00&lt;00:00,â€‡19.2MB/s]"
          }
        },
        "e6f316d2166f43ed8866674316a2f180": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_136c81e4f9ac47dd9977393eb2bd3f48",
              "IPY_MODEL_02db4ca1d06240e3a8464de7583e50d0",
              "IPY_MODEL_fa88becfa81c426aaef4d213a8934c70"
            ],
            "layout": "IPY_MODEL_e52242c71523404bbba94c882f03f38e"
          }
        },
        "e7e02bcdc58c4f3ab657899598039db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e73fb6444fe4c37a84e8d8a3166d81f",
              "IPY_MODEL_707bbc12cdf34926a7d6c004a90fddb2",
              "IPY_MODEL_f249ae54f3b2494d9c42655c0865e43c"
            ],
            "layout": "IPY_MODEL_d14c60256ed349408bbea3fd8627099a"
          }
        },
        "eb0bc66a21dd419e8128e8e5c6bd205d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cec09cbe65a4bac8d76a2419507d4c3",
              "IPY_MODEL_d8727efa45544e369527ad890a0fd0f2",
              "IPY_MODEL_a078a0446362449c912df1ca7d91e2a0"
            ],
            "layout": "IPY_MODEL_ab9e24119e514ba6b83b6a01774a08ae"
          }
        },
        "ebabcafabaea4a7c9e78abf250ea888f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec612d375113460b9672dbd4ee4232a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eed0579f667a41d3bc42e025e3611f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc8ebb87f20d41c3aa2c6586300e26a4",
              "IPY_MODEL_d18296a6e2d241b6b6add26b66b4aed2",
              "IPY_MODEL_65e2b468d6d34adfbd3e8a766ae33a93"
            ],
            "layout": "IPY_MODEL_37b9d27c191c4b3da761602e76f8357c"
          }
        },
        "ef5f43fe138643ebb7cf47ec0441b18d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef89f853f3f54571ac81284dc8d91ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f086c3e01d764d0b80d4c72c186d345e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": "blue",
            "description_width": ""
          }
        },
        "f249ae54f3b2494d9c42655c0865e43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b51abf5140b14f868360d1f369443205",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_53e5631f7fe840e5a8cb6b866128e289",
            "value": "â€‡141k/141kâ€‡[00:00&lt;00:00,â€‡7.59MB/s]"
          }
        },
        "f33bfb43e73b42e49f58ab212d5968af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f408f27d951c4135a8e89f5e4108174f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f676cb45031c4a6b8763d83e161879a7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6e458302d9e43cdb49f6902669b3378": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f797239b31ff47119dbc1478ffb8b1d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f857c50ac5c844cc89cbecf7d34d3a30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f905c709308c4f538ddb13f65f5c54cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa88becfa81c426aaef4d213a8934c70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f857c50ac5c844cc89cbecf7d34d3a30",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_38ef02aef23f465082823c1c3a55892d",
            "value": "â€‡3/3â€‡[05:46&lt;00:00,â€‡114.21s/it]"
          }
        },
        "fbbca39e31e14a928d7dbaceb853094c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a13162d1ad2a4b08be7049ee1c769815",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_139343a7a50c4157b6ee591fe2989dc1",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "fc154e11eed946a3b94e8e9d34e37763": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc786a345cf84842a3bf45a892fe0472": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6e94766f4444e1db218779be8d644d3",
            "max": 1961548,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98e2609c40734c02844521ed7aa913da",
            "value": 1961548
          }
        },
        "fee44c9704f14a45a3c54b1b9f81c0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f408f27d951c4135a8e89f5e4108174f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9e6c1b6464624743b97745a9f3384a38",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "ff1b1bed15ca4f19bdbe515c90315b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
