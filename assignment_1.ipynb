{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmIZOuDv-bQk"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoFasulo/Sexism-detection/blob/main/assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vYXSXHf-bQp"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install requests umap nltk gensim"
      ],
      "metadata": {
        "id": "rT1NnYib-cZs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8HsAwNAc-bQp"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "import re\n",
        "import json\n",
        "from typing import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import umap\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import gensim\n",
        "import gensim.downloader as gloader\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4MUwVBe-bQt"
      },
      "source": [
        "# Class definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "w4OPhRgq-bQu"
      },
      "outputs": [],
      "source": [
        "class SexismDetector:\n",
        "    def __init__(self):\n",
        "\n",
        "        URL_PATTERN_STR = r\"\"\"(?i)((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info\n",
        "                      |int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|\n",
        "                      bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|\n",
        "                      cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|\n",
        "                      gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|\n",
        "                      la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|\n",
        "                      nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|\n",
        "                      sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|\n",
        "                      uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]\n",
        "                      *?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’])|(?:(?<!@)\n",
        "                      [a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name\n",
        "                      |post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn\n",
        "                      |bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg\n",
        "                      |eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id\n",
        "                      |ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|\n",
        "                      md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|\n",
        "                      ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|\n",
        "                      sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|\n",
        "                      za|zm|zw)\\b/?(?!@)))\"\"\"\n",
        "        self.URL_PATTERN = re.compile(URL_PATTERN_STR, re.IGNORECASE)\n",
        "        self.HASHTAG_PATTERN = re.compile(r'#\\w*')\n",
        "        self.MENTION_PATTERN = re.compile(r'@\\w*')\n",
        "        self.EMOJIS_PATTERN = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
        "        self.SPECIAL_CHARACTERS_PATTERN = re.compile(r'&lt;/?[a-z]+&gt;')\n",
        "        self.AND_PATTERN = re.compile(r'&amp;')\n",
        "        self.WORD_PATTERN = re.compile(r'[^a-zA-Z\\s]')\n",
        "        self.SEED = 42\n",
        "        self.DATA_FOLDER = Path('data')\n",
        "        self.columns_to_maintain = ['id_EXIST', 'lang', 'tweet', 'hard_label_task1']\n",
        "        self.UNK_TOKEN = '[UNK]'\n",
        "        self.PAD_TOKEN = '[PAD]'\n",
        "\n",
        "    def download_corpus(self, url: str, filename: str):\n",
        "        if not self.DATA_FOLDER.exists():\n",
        "            self.DATA_FOLDER.mkdir(parents=True)\n",
        "            print(f\"Created folder {self.DATA_FOLDER}.\")\n",
        "\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        with open(self.DATA_FOLDER / filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(response.text)\n",
        "\n",
        "    def load_corpus(self, filename: str, *args, **kwargs):\n",
        "        return pd.read_json(self.DATA_FOLDER / filename, *args, **kwargs)\n",
        "\n",
        "    @staticmethod\n",
        "    def majority_voting(votes: list[str]) -> str:\n",
        "        total_num_votes = len(votes)\n",
        "        yes_votes = votes.count(\"YES\")\n",
        "        no_votes = total_num_votes - yes_votes\n",
        "\n",
        "        if yes_votes > no_votes:\n",
        "            return \"YES\"\n",
        "        elif no_votes > yes_votes:\n",
        "            return \"NO\"\n",
        "        else:\n",
        "            return \"NEUTRAL\" # This will be the case when there is a tie (removed later)\n",
        "\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        text = self.URL_PATTERN.sub('', text)\n",
        "        text = self.MENTION_PATTERN.sub('', text)\n",
        "        text = self.HASHTAG_PATTERN.sub('', text)\n",
        "        text = self.EMOJIS_PATTERN.sub('', text)\n",
        "        text = self.SPECIAL_CHARACTERS_PATTERN.sub('', text)\n",
        "        text = self.AND_PATTERN.sub('and', text)\n",
        "        text = text.strip()\n",
        "        text = self.WORD_PATTERN.sub(' ', text)\n",
        "        text = text.strip()\n",
        "        return text\n",
        "\n",
        "    def lemmatize_text(self, text: str) -> str:\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        downloaded = False\n",
        "        while not downloaded:\n",
        "            try:\n",
        "                lemmatizer.lemmatize(text)\n",
        "                downloaded = True\n",
        "            except LookupError:\n",
        "                print(\"Downloading WordNet...\")\n",
        "                nltk.download('wordnet')\n",
        "        return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "    @staticmethod\n",
        "    def text_diff(original_text: str, preprocessed_text: str, random: bool = True):\n",
        "        if random:\n",
        "            idx = np.random.randint(0, preprocessed_text.shape[0])\n",
        "        else:\n",
        "            idx = 0\n",
        "\n",
        "        print(f\"Original tweet:\\n{original_text['tweet'].iloc[idx]}\")\n",
        "        print(f\"Processed tweet:\\n{preprocessed_text['tweet'].iloc[idx]}\")\n",
        "\n",
        "    def load_glove(self, model_name: str = 'glove-wiki-gigaword', embedding_dim: int = 50):\n",
        "        self.EMBEDDING_DIM = embedding_dim\n",
        "        return gloader.load(f\"{model_name}-{embedding_dim}\")\n",
        "\n",
        "    def get_vocab(self, data: pd.DataFrame, word_listing: list = None) -> OrderedDict:\n",
        "        idx_to_word = OrderedDict()\n",
        "        word_to_idx = OrderedDict()\n",
        "\n",
        "        tokenizer = nltk.tokenize.NLTKWordTokenizer()\n",
        "\n",
        "        if word_listing is None:\n",
        "            curr_idx = 0\n",
        "            for sentence in data['tweet'].values:\n",
        "                tokens = tokenizer.tokenize(sentence)\n",
        "                for token in tokens:\n",
        "                    if token not in word_to_idx:\n",
        "                        word_to_idx[token] = curr_idx\n",
        "                        idx_to_word[curr_idx] = token\n",
        "                        curr_idx += 1\n",
        "\n",
        "        else:\n",
        "            word_to_idx[self.UNK_TOKEN] = 0\n",
        "            idx_to_word[0] = self.UNK_TOKEN\n",
        "\n",
        "            curr_idx = 1\n",
        "            for sentence in data['tweet'].values:\n",
        "                tokens = sentence.split()\n",
        "                for token in word_listing:\n",
        "                    if token not in word_to_idx:\n",
        "                        word_to_idx[token] = curr_idx\n",
        "                        idx_to_word[curr_idx] = token\n",
        "                        curr_idx += 1\n",
        "\n",
        "        return idx_to_word, word_to_idx\n",
        "\n",
        "    def get_augmented_vocab(self, emb_model: gensim.models.keyedvectors.KeyedVectors, train_words: list, save: bool = False) -> gensim.models.keyedvectors.KeyedVectors:\n",
        "        embedding_vocab = set(emb_model.key_to_index.keys())\n",
        "\n",
        "        new_tokens = []\n",
        "        new_vectors = []\n",
        "        for token in train_words:\n",
        "            if token not in embedding_vocab:\n",
        "                embedding_vocab.add(token)\n",
        "            try:\n",
        "                embedding_vec = emb_model.get_vector(token)\n",
        "            except (KeyError, ValueError):\n",
        "                embedding_vec = np.random.uniform(low=-0.05, high=0.05, size=self.EMBEDDING_DIM)\n",
        "\n",
        "            new_tokens.append(token)\n",
        "            new_vectors.append(embedding_vec)\n",
        "\n",
        "        emb_model.add_vectors(new_tokens, new_vectors)\n",
        "\n",
        "        if save:\n",
        "            vocab_path = self.DATA_FOLDER / 'vocab2.json'\n",
        "            print(f\"Saving vocab to {vocab_path}\")\n",
        "            with vocab_path.open('w', encoding='utf-8') as f:\n",
        "                json.dump(emb_model.key_to_index, f, indent=4)\n",
        "            print(\"Vocab saved!\")\n",
        "\n",
        "        return emb_model\n",
        "\n",
        "    def get_oov_stats(self, embedding_model: gensim.models.keyedvectors.KeyedVectors, word_listing: list) -> None:\n",
        "        OOV_count = set(word_listing).difference(set(embedding_model.key_to_index.keys()))\n",
        "        OOV_percentage = float(len(OOV_count)) * 100 / len(word_listing)\n",
        "\n",
        "        print(f\"Total OOV terms: {len(OOV_count)} ({OOV_percentage:.2f}%)\")\n",
        "\n",
        "    @staticmethod\n",
        "    def visualize_embeddings(embeddings: np.ndarray,\n",
        "                         word_annotations,\n",
        "                         word_to_idx):\n",
        "        \"\"\"\n",
        "        Plots given reduce word embeddings (2D). Users can highlight specific words (word_annotations list).\n",
        "\n",
        "        :param embeddings: word embedding matrix of shape (words, 2) retrieved via a dimensionality reduction technique.\n",
        "        :param word_annotations: list of words to be annotated.\n",
        "        :param word_to_idx: vocabulary map (word -> index) (dict)\n",
        "        \"\"\"\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
        "\n",
        "        if word_annotations:\n",
        "            print(f\"Annotating words: {word_annotations}\")\n",
        "\n",
        "            word_indexes = []\n",
        "            for word in word_annotations:\n",
        "                word_index = word_to_idx[word]\n",
        "                word_indexes.append(word_index)\n",
        "\n",
        "            word_indexes = np.array(word_indexes)\n",
        "\n",
        "            other_embeddings = embeddings[np.setdiff1d(np.arange(embeddings.shape[0]), word_indexes)]\n",
        "            target_embeddings = embeddings[word_indexes]\n",
        "\n",
        "            ax.scatter(other_embeddings[:, 0], other_embeddings[:, 1], alpha=0.1, c='blue')\n",
        "            ax.scatter(target_embeddings[:, 0], target_embeddings[:, 1], alpha=1.0, c='red')\n",
        "            ax.scatter(target_embeddings[:, 0], target_embeddings[:, 1], alpha=1, facecolors='none', edgecolors='r', s=1000)\n",
        "\n",
        "            for word, word_index in zip(word_annotations, word_indexes):\n",
        "                word_x, word_y = embeddings[word_index, 0], embeddings[word_index, 1]\n",
        "                ax.annotate(word, xy=(word_x, word_y))\n",
        "        else:\n",
        "            ax.scatter(embeddings[:, 0], embeddings[:, 1], alpha=0.1, c='blue')\n",
        "\n",
        "        # We avoid outliers ruining the visualization if they are quite far away\n",
        "        axis_x_limit = (np.min(embeddings[:, 0]), np.max(embeddings[:, 0]))\n",
        "        axis_y_limit = (np.min(embeddings[:, 1]), np.max(embeddings[:, 1]))\n",
        "        plt.xlim(left=axis_x_limit[0] - 0.5, right=axis_x_limit[1] + 0.5)\n",
        "        plt.ylim(bottom=axis_y_limit[0] - 0.5, top=axis_y_limit[1] + 0.5)\n",
        "        ax.set_xlim(axis_x_limit[0], axis_x_limit[1])\n",
        "        ax.set_ylim(axis_y_limit[0], axis_y_limit[1])\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce_SVD(embeddings: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Applies SVD dimensionality reduction.\n",
        "\n",
        "        :param embeddings: word embedding matrix of shape (words, dim). In the case\n",
        "                        of a word-word co-occurrence matrix the matrix shape would\n",
        "                        be (words, words).\n",
        "\n",
        "        :return\n",
        "            - 2-dimensional word embedding matrix of shape (words, 2)\n",
        "        \"\"\"\n",
        "        print(\"Running SVD reduction method...\")\n",
        "        svd = TruncatedSVD(n_components=2, n_iter=10)\n",
        "        reduced = svd.fit_transform(embeddings)\n",
        "        print(\"SVD reduction completed!\")\n",
        "\n",
        "        return reduced\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce_tSNE(embeddings: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Applies t-SNE dimensionality reduction.\n",
        "        \"\"\"\n",
        "        print(\"Running t-SNE reduction method... (it may take a while...)\")\n",
        "        tsne = TSNE(n_components=2, n_iter=1000, metric='cosine')\n",
        "        reduced = tsne.fit_transform(embeddings)\n",
        "        print(\"t-SNE reduction completed!\")\n",
        "\n",
        "        return reduced\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce_umap(embeddings: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Applies UMAP dimensionality reduction.\n",
        "        \"\"\"\n",
        "        print(\"Running UMAP reduction method... (it may take a while...)\")\n",
        "        umap_emb = umap.UMAP(n_components=2, metric='cosine')\n",
        "        reduced = umap_emb.fit_transform(embeddings)\n",
        "        print(\"UMAP reduction completed!\")\n",
        "\n",
        "        return reduced\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S8JHdj0-bQw"
      },
      "source": [
        "# Task 1: Corpus\n",
        "\n",
        "1. Download the data\n",
        "2. Load the JSON files and encode them as a DataFrame\n",
        "3. Generate hard labels for Task 1 with majority voting\n",
        "4. Filter the DataFrame for only english tweets\n",
        "5. Remove unwanted columns\n",
        "6. Encode the hard labels column as integers\n",
        "\n",
        ">**Bonus**: explore also Spanish tweets leveraging multi-language models and assessing the performance of the model on the two languages in comparison to the English-only model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "UX6zDKbU-bQx"
      },
      "outputs": [],
      "source": [
        "detector = SexismDetector()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kB8zolx-bQx"
      },
      "source": [
        "### Download the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "zHCqDJCq-bQy"
      },
      "outputs": [],
      "source": [
        "detector.download_corpus(url='https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/refs/heads/main/2024-2025/Assignment%201/data/training.json', filename='training.json')\n",
        "detector.download_corpus(url='https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/refs/heads/main/2024-2025/Assignment%201/data/test.json', filename='test.json')\n",
        "detector.download_corpus(url='https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/refs/heads/main/2024-2025/Assignment%201/data/validation.json', filename='validation.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlbBn1uh-bQy"
      },
      "source": [
        "### Load the JSON files and encode them as a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "xffrWnDg-bQz"
      },
      "outputs": [],
      "source": [
        "train = detector.load_corpus('training.json', orient='index', encoding='utf-8')\n",
        "test = detector.load_corpus('test.json', orient='index', encoding='utf-8')\n",
        "val = detector.load_corpus('validation.json', orient='index', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "R-Iddy7j-bQ0",
        "outputId": "98626d55-a01d-4474-d8f6-b15486c6f0d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id_EXIST lang                                              tweet  \\\n",
              "100001    100001   es  @TheChiflis Ignora al otro, es un capullo.El p...   \n",
              "100002    100002   es  @ultimonomada_ Si comicsgate se parece en algo...   \n",
              "100003    100003   es  @Steven2897 Lee sobre Gamergate, y como eso ha...   \n",
              "100004    100004   es  @Lunariita7 Un retraso social bastante lamenta...   \n",
              "100005    100005   es  @novadragon21 @icep4ck @TvDannyZ Entonces como...   \n",
              "\n",
              "        number_annotators                                         annotators  \\\n",
              "100001                  6  [Annotator_1, Annotator_2, Annotator_3, Annota...   \n",
              "100002                  6  [Annotator_7, Annotator_8, Annotator_9, Annota...   \n",
              "100003                  6  [Annotator_7, Annotator_8, Annotator_9, Annota...   \n",
              "100004                  6  [Annotator_13, Annotator_14, Annotator_15, Ann...   \n",
              "100005                  6  [Annotator_19, Annotator_20, Annotator_21, Ann...   \n",
              "\n",
              "         gender_annotators                          age_annotators  \\\n",
              "100001  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "100002  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "100003  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "100004  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "100005  [F, F, F, M, M, M]  [18-22, 23-45, 46+, 46+, 23-45, 18-22]   \n",
              "\n",
              "                         labels_task1  \\\n",
              "100001  [YES, YES, NO, YES, YES, YES]   \n",
              "100002      [NO, NO, NO, NO, YES, NO]   \n",
              "100003       [NO, NO, NO, NO, NO, NO]   \n",
              "100004    [NO, NO, YES, NO, YES, YES]   \n",
              "100005   [YES, NO, YES, NO, YES, YES]   \n",
              "\n",
              "                                             labels_task2  \\\n",
              "100001  [REPORTED, JUDGEMENTAL, -, REPORTED, JUDGEMENT...   \n",
              "100002                            [-, -, -, -, DIRECT, -]   \n",
              "100003                                 [-, -, -, -, -, -]   \n",
              "100004              [-, -, DIRECT, -, REPORTED, REPORTED]   \n",
              "100005  [REPORTED, -, JUDGEMENTAL, -, JUDGEMENTAL, DIR...   \n",
              "\n",
              "                                             labels_task3     split  \n",
              "100001  [[OBJECTIFICATION], [OBJECTIFICATION, SEXUAL-V...  TRAIN_ES  \n",
              "100002       [[-], [-], [-], [-], [OBJECTIFICATION], [-]]  TRAIN_ES  \n",
              "100003                     [[-], [-], [-], [-], [-], [-]]  TRAIN_ES  \n",
              "100004  [[-], [-], [IDEOLOGICAL-INEQUALITY], [-], [IDE...  TRAIN_ES  \n",
              "100005  [[STEREOTYPING-DOMINANCE, OBJECTIFICATION], [-...  TRAIN_ES  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5608a2a-8f5a-43d9-878b-d9108d4f8a48\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_EXIST</th>\n",
              "      <th>lang</th>\n",
              "      <th>tweet</th>\n",
              "      <th>number_annotators</th>\n",
              "      <th>annotators</th>\n",
              "      <th>gender_annotators</th>\n",
              "      <th>age_annotators</th>\n",
              "      <th>labels_task1</th>\n",
              "      <th>labels_task2</th>\n",
              "      <th>labels_task3</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100001</th>\n",
              "      <td>100001</td>\n",
              "      <td>es</td>\n",
              "      <td>@TheChiflis Ignora al otro, es un capullo.El p...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_1, Annotator_2, Annotator_3, Annota...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[YES, YES, NO, YES, YES, YES]</td>\n",
              "      <td>[REPORTED, JUDGEMENTAL, -, REPORTED, JUDGEMENT...</td>\n",
              "      <td>[[OBJECTIFICATION], [OBJECTIFICATION, SEXUAL-V...</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100002</th>\n",
              "      <td>100002</td>\n",
              "      <td>es</td>\n",
              "      <td>@ultimonomada_ Si comicsgate se parece en algo...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_7, Annotator_8, Annotator_9, Annota...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[NO, NO, NO, NO, YES, NO]</td>\n",
              "      <td>[-, -, -, -, DIRECT, -]</td>\n",
              "      <td>[[-], [-], [-], [-], [OBJECTIFICATION], [-]]</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100003</th>\n",
              "      <td>100003</td>\n",
              "      <td>es</td>\n",
              "      <td>@Steven2897 Lee sobre Gamergate, y como eso ha...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_7, Annotator_8, Annotator_9, Annota...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[NO, NO, NO, NO, NO, NO]</td>\n",
              "      <td>[-, -, -, -, -, -]</td>\n",
              "      <td>[[-], [-], [-], [-], [-], [-]]</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100004</th>\n",
              "      <td>100004</td>\n",
              "      <td>es</td>\n",
              "      <td>@Lunariita7 Un retraso social bastante lamenta...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_13, Annotator_14, Annotator_15, Ann...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[NO, NO, YES, NO, YES, YES]</td>\n",
              "      <td>[-, -, DIRECT, -, REPORTED, REPORTED]</td>\n",
              "      <td>[[-], [-], [IDEOLOGICAL-INEQUALITY], [-], [IDE...</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100005</th>\n",
              "      <td>100005</td>\n",
              "      <td>es</td>\n",
              "      <td>@novadragon21 @icep4ck @TvDannyZ Entonces como...</td>\n",
              "      <td>6</td>\n",
              "      <td>[Annotator_19, Annotator_20, Annotator_21, Ann...</td>\n",
              "      <td>[F, F, F, M, M, M]</td>\n",
              "      <td>[18-22, 23-45, 46+, 46+, 23-45, 18-22]</td>\n",
              "      <td>[YES, NO, YES, NO, YES, YES]</td>\n",
              "      <td>[REPORTED, -, JUDGEMENTAL, -, JUDGEMENTAL, DIR...</td>\n",
              "      <td>[[STEREOTYPING-DOMINANCE, OBJECTIFICATION], [-...</td>\n",
              "      <td>TRAIN_ES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5608a2a-8f5a-43d9-878b-d9108d4f8a48')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5608a2a-8f5a-43d9-878b-d9108d4f8a48 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5608a2a-8f5a-43d9-878b-d9108d4f8a48');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a709cbff-ae02-4cbd-82b4-0575352a113f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a709cbff-ae02-4cbd-82b4-0575352a113f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a709cbff-ae02-4cbd-82b4-0575352a113f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 6920,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49830,\n        \"min\": 100001,\n        \"max\": 203260,\n        \"num_unique_values\": 6920,\n        \"samples\": [\n          100469,\n          101957,\n          100801\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"en\",\n          \"es\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6920,\n        \"samples\": [\n          \"@AnelPerezM Pues.... realmente sabes cu\\u00e1ndo alguien aumenta tu serotonina... porque ver una mujer atractiva pues si.... pero que realmente te enamore...lo sientes porque eso te pone realmente feliz.\",\n          \"@giuli_cc:A confesi\\u00f3n de parte relevo de prueba.Claramente el ex Minedu CUENCA sostiene q el enfoque de g\\u00e9nero es lo m\\u00e1s alejado a lo binario.\\u00bfNo q el enfoque de g\\u00e9nero era buscar la igualdad entre VAR\\u00d3N Y MUJER?Claramente el EdG es un sin fin de g\\u00e9neros que quieren ense\\u00f1ar. https://t.co/UIxAyyC5nR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number_annotators\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender_annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age_annotators\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_task1\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_task2\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels_task3\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"TRAIN_EN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "3PwyCeQc-bQ1",
        "outputId": "e32f4d75-d4ae-4df0-c22b-c04092ee102e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6920, 11), (726, 11), (312, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "train.shape, val.shape, test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fISdCga-bQ1"
      },
      "source": [
        "### Generate hard labels for Task 1 with majority voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "jVfdt1mf-bQ1"
      },
      "outputs": [],
      "source": [
        "train['hard_label_task1'] = train['labels_task1'].apply(detector.majority_voting)\n",
        "val['hard_label_task1'] = val['labels_task1'].apply(detector.majority_voting)\n",
        "test['hard_label_task1'] = test['labels_task1'].apply(detector.majority_voting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNSfxEqA-bQ2"
      },
      "source": [
        "### Filter the DataFrame for only english tweets and remove unclear tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "P3hE1ua_-bQ2"
      },
      "outputs": [],
      "source": [
        "train = train[(train['hard_label_task1'] != \"NEUTRAL\") & (train['lang'] == \"en\")]\n",
        "val = val[(val['hard_label_task1'] != \"NEUTRAL\") & (val['lang'] == \"en\")]\n",
        "test = test[(test['hard_label_task1'] != \"NEUTRAL\") & (test['lang'] == \"en\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "js6SiYSY-bQ2",
        "outputId": "67b99dfa-633f-47d1-bf92-bcc6f2215d93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2870, 12), (158, 12), (286, 12))"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "train.shape, val.shape, test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edgN4FWb-bQ2"
      },
      "source": [
        "### Remove unwanted columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "lFUcf_Ii-bQ3"
      },
      "outputs": [],
      "source": [
        "train = train[detector.columns_to_maintain]\n",
        "val = val[detector.columns_to_maintain]\n",
        "test = test[detector.columns_to_maintain]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "BEe_i8hJ-bQ3",
        "outputId": "f06531fd-1aaa-430f-a1d2-8e81f546707b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id_EXIST lang                                              tweet  \\\n",
              "200002    200002   en  Writing a uni essay in my local pub with a cof...   \n",
              "200003    200003   en  @UniversalORL it is 2021 not 1921. I dont appr...   \n",
              "200006    200006   en  According to a customer I have plenty of time ...   \n",
              "200007    200007   en  So only 'blokes' drink beer? Sorry, but if you...   \n",
              "200008    200008   en  New to the shelves this week - looking forward...   \n",
              "\n",
              "       hard_label_task1  \n",
              "200002              YES  \n",
              "200003              YES  \n",
              "200006              YES  \n",
              "200007              YES  \n",
              "200008               NO  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9091047a-52aa-4ecd-a74c-4facbfcd532f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_EXIST</th>\n",
              "      <th>lang</th>\n",
              "      <th>tweet</th>\n",
              "      <th>hard_label_task1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>200002</td>\n",
              "      <td>en</td>\n",
              "      <td>Writing a uni essay in my local pub with a cof...</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>200003</td>\n",
              "      <td>en</td>\n",
              "      <td>@UniversalORL it is 2021 not 1921. I dont appr...</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200006</th>\n",
              "      <td>200006</td>\n",
              "      <td>en</td>\n",
              "      <td>According to a customer I have plenty of time ...</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200007</th>\n",
              "      <td>200007</td>\n",
              "      <td>en</td>\n",
              "      <td>So only 'blokes' drink beer? Sorry, but if you...</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200008</th>\n",
              "      <td>200008</td>\n",
              "      <td>en</td>\n",
              "      <td>New to the shelves this week - looking forward...</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9091047a-52aa-4ecd-a74c-4facbfcd532f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9091047a-52aa-4ecd-a74c-4facbfcd532f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9091047a-52aa-4ecd-a74c-4facbfcd532f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b3ad395-b2b5-4aba-b1dc-791e4b991acd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b3ad395-b2b5-4aba-b1dc-791e4b991acd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b3ad395-b2b5-4aba-b1dc-791e4b991acd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 2870,\n  \"fields\": [\n    {\n      \"column\": \"id_EXIST\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 934,\n        \"min\": 200002,\n        \"max\": 203260,\n        \"num_unique_values\": 2870,\n        \"samples\": [\n          200504,\n          202694,\n          200852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lang\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2870,\n        \"samples\": [\n          \"Call me sexist but it just feels wrong that women are reffing the NBA like go ref the WNBA\\ud83d\\ude2c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hard_label_task1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1vO0qNe-bQ3"
      },
      "source": [
        "### Encode the hard labels column as integers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "_vKw9ugP-bQ3"
      },
      "outputs": [],
      "source": [
        "train['hard_label_task1'] = train['hard_label_task1'].apply(lambda x: 1 if x == \"YES\" else 0)\n",
        "val['hard_label_task1'] = val['hard_label_task1'].apply(lambda x: 1 if x == \"YES\" else 0)\n",
        "test['hard_label_task1'] = test['hard_label_task1'].apply(lambda x: 1 if x == \"YES\" else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "QYpFYiwx-bQ4",
        "outputId": "eb4f3686-ace7-40f8-90cf-1926603dc94f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "hard_label_task1\n",
              "0    1733\n",
              "1    1137\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hard_label_task1</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1137</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "train.hard_label_task1.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_qchDt7-bQ4"
      },
      "source": [
        "# Task 2: Data Cleaning\n",
        "\n",
        "1. Remove emojis\n",
        "2. Remove hashtags (e.g. #metoo)\n",
        "3. Remove mentions (e.g. @user)\n",
        "4. Remove URLs\n",
        "5. Remove special characters and symbols\n",
        "6. Remove specific quote characters (e.g. curly quotes)\n",
        "7. Perform lemmatization\n",
        "\n",
        ">**Bonus**: use other preprocessing strategies exploring techniques tailored specifically for tweets or methods that are common in social media text processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPZ_A3ek-bQ4"
      },
      "source": [
        "The way to go (priority order) is the following:\n",
        "1. Remove URLs\n",
        "2. Remove mentions\n",
        "3. Remove hashtags\n",
        "4. Remove emojis\n",
        "5. Remove special characters\n",
        "6. Remove specific quote characters\n",
        "7. Perform lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "vyKl2917-bQ4"
      },
      "outputs": [],
      "source": [
        "original_train = train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "xtI27hJo-bQ4"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(detector.preprocess_text)\n",
        "val['tweet'] = val['tweet'].apply(detector.preprocess_text)\n",
        "test['tweet'] = test['tweet'].apply(detector.preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFOqFd6i-bQ6"
      },
      "source": [
        "### Perform lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "lu1toksv-bQ6"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].apply(detector.lemmatize_text)\n",
        "val['tweet'] = val['tweet'].apply(detector.lemmatize_text)\n",
        "test['tweet'] = test['tweet'].apply(detector.lemmatize_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R-fL1sl-bQ7"
      },
      "source": [
        "### Cast text to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Ku484oN9-bQ7"
      },
      "outputs": [],
      "source": [
        "train['tweet'] = train['tweet'].str.lower()\n",
        "val['tweet'] = val['tweet'].str.lower()\n",
        "test['tweet'] = test['tweet'].str.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFbPle-9-bQ8"
      },
      "source": [
        "### Show the difference between the original and cleaned text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "TURQi4uE-bQ8",
        "outputId": "6b6268ed-87e4-41ed-8bd9-af1dd77d51c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original tweet:\n",
            "I think he wore a black shirt lol I don’t remember but I think\n",
            "Processed tweet:\n",
            "i think he wore a black shirt lol i don t remember but i think\n"
          ]
        }
      ],
      "source": [
        "detector.text_diff(preprocessed_text=train, original_text=original_train, random=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50Cj7hDE-bQ9"
      },
      "source": [
        "# Task 3: Text Encoding\n",
        "\n",
        "* Embed words using GloVe embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3m8P2pe-bQ-"
      },
      "source": [
        "### Embed words using GloVe embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "vEGg4Jvp-bQ-",
        "outputId": "a06a7677-a807-4a62-8792-f4b6242f7adf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400000"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "emb_model = detector.load_glove(model_name='glove-wiki-gigaword', embedding_dim=50)\n",
        "len(emb_model.key_to_index.keys())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_idx_to_word, train_word_to_idx = detector.get_vocab(train)"
      ],
      "metadata": {
        "id": "JJEQVEKJLcKF"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(emb_model.key_to_index.keys()) + 2\n",
        "embedding_dim = 50\n",
        "hits, misses = 0, 0\n",
        "\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in train_word_to_idx.items():\n",
        "    try:\n",
        "      embedding_vector = emb_model.get_vector(word)\n",
        "      hits += 1\n",
        "    except KeyError:\n",
        "      #embedding_vector = np.random.uniform(low=-0.05, high=0.05, size=embedding_dim) TODO: CHANGE THIS AND HANDLE IT\n",
        "      misses += 1\n",
        "\n",
        "    # Words not found in embedding index will be all-zeros.\n",
        "    # This includes the representation for \"padding\" and \"OOV\"\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "metadata": {
        "id": "qVT28GSNKoVp",
        "outputId": "a67293e8-cf55-4482-e104-e9cf415a46bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 8986 words (868 misses)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "EkY2XaJN-bQ_"
      },
      "outputs": [],
      "source": [
        "train_idx_to_word, train_word_to_idx = detector.get_vocab(train)\n",
        "val_idx_to_word, val_word_to_idx = detector.get_vocab(val)\n",
        "test_idx_to_word, test_word_to_idx = detector.get_vocab(test)\n",
        "\n",
        "train_word_listing = list(train_idx_to_word.values())\n",
        "val_word_listing = list(val_idx_to_word.values())\n",
        "test_word_listing = list(test_idx_to_word.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "bZSXJ51f-bRE",
        "outputId": "ec4b0a59-de61-4246-9d2b-efa1db69bd89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 868 (8.81%)\n"
          ]
        }
      ],
      "source": [
        "detector.get_oov_stats(emb_model, train_word_listing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "fnNshkRb-bRF",
        "outputId": "cba4801b-47e4-4188-bd8e-134d2e30d6d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "IM HERE\n",
            "Saving vocab to data/vocab2.json\n",
            "Vocab saved!\n"
          ]
        }
      ],
      "source": [
        "emb_model_augmented = detector.get_augmented_vocab(emb_model, train_words=train_word_listing, save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rMMto8pR-bRF"
      },
      "outputs": [],
      "source": [
        "# add the UNK token to the embedding model with the vector which is the average of all the vectors\n",
        "emb_model_augmented.add_vectors([\"[UNK]\", \"[PAD]\"], [np.mean(emb_model.vectors, axis=0), np.zeros(50)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SVYSXzcL-bRF",
        "outputId": "c1db1bab-0267-4024-b20f-11cc86003eb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total OOV terms: 0 (0.00%)\n",
            "Total OOV terms: 0 (0.00%)\n"
          ]
        }
      ],
      "source": [
        "detector.get_oov_stats(emb_model_augmented, val_word_listing)\n",
        "detector.get_oov_stats(emb_model_augmented, test_word_listing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yRw9DQEq-bRG",
        "outputId": "1c1fc2bb-7b70-4885-bc7e-2d9960853f1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400870, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "### Create the embeddings matrix\n",
        "embedding_matrix = emb_model.vectors\n",
        "embedding_matrix.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "FZvQAyL_-bRG"
      },
      "outputs": [],
      "source": [
        "# UMAP\n",
        "#reduced_embedding_umap = detector.reduce_umap(embedding_matrix)\n",
        "#detector.visualize_embeddings(reduced_embedding_umap, ['whore', 'woman', 'slut', 'girl', 'man', 'boy'], emb_model.key_to_index)\n",
        "\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UUVw8lx-bRG"
      },
      "source": [
        "# Task 4: Model definition\n",
        "\n",
        "* Baseline: Implement a Bidirectional LSTM with a Dense layer on top.\n",
        "* Model 1: add an additional LSTM layer to the baseline model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpU6TmVd-bRG"
      },
      "source": [
        "### Baseline: Implement a Bidirectional LSTM with a Dense layer on top"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaselineLSTM(keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, embedding_matrix, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.word_embeddings = keras.layers.Embedding(input_dim=vocab_size,\n",
        "                                      output_dim=embedding_dim,\n",
        "                                      weights=[embedding_matrix],\n",
        "                                      mask_zero=False,                   # automatically masks padding tokens\n",
        "                                      trainable=True)\n",
        "\n",
        "        self.bidirectional = keras.layers.Bidirectional(keras.layers.LSTM(embedding_dim, activation='tanh', return_sequences=False))\n",
        "        self.dense = keras.layers.Dense(output_dim, activation=\"sigmoid\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        embeds = self.word_embeddings(inputs)\n",
        "        lstm_out = self.bidirectional(embeds)\n",
        "        output = self.dense(lstm_out)\n",
        "        return output\n",
        "\n",
        "model = BaselineLSTM(vocab_size=num_tokens, embedding_dim=50, embedding_matrix=embedding_matrix, hidden_dim=256, output_dim=1)\n",
        "model.compile(\n",
        "    loss=keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=keras.optimizers.AdamW(learning_rate=1e-3, weight_decay=1e-5),\n",
        "    metrics=[\n",
        "        keras.metrics.BinaryAccuracy(),\n",
        "        keras.metrics.Precision(),\n",
        "        keras.metrics.Recall(),\n",
        "    ])"
      ],
      "metadata": {
        "id": "iP6eKh-5_Iqu"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_padded_sequences(data: pd.Series, embedding_model):\n",
        "  tokenizer = nltk.tokenize.NLTKWordTokenizer()\n",
        "  int_sequences = [[embedding_model.get_index(word) for word in tokenizer.tokenize(x)] for x in data.values]\n",
        "  MAX_SEQ_LENGTH = max([len(i) for i in int_sequences])\n",
        "  return tf.keras.utils.pad_sequences(int_sequences, maxlen=MAX_SEQ_LENGTH, padding='post', value=0)"
      ],
      "metadata": {
        "id": "W21JUrGsCdVo"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Now feed to the model as input the padded sequences and the labels\n",
        "\n",
        "X_train, y_train = get_padded_sequences(train['tweet'], emb_model_augmented), train['hard_label_task1'].values\n",
        "#X_val, y_val = get_padded_sequences(val['tweet'], emb_model_augmented), val['hard_label_task1'].values TODO: add [UNK] for tokens not being inside the VOCAB into the embedding model of GloVe\n",
        "\n",
        "# Now feed the padded sequences and labels to the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "Lyis4cRRFEfZ",
        "outputId": "51445c24-e06c-46ee-e4d5-75a94838c2c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - binary_accuracy: 0.5872 - loss: 0.6826 - precision: 0.4623 - recall: 0.1615\n",
            "Epoch 2/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - binary_accuracy: 0.6242 - loss: 0.6526 - precision: 0.5110 - recall: 0.1724\n",
            "Epoch 3/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - binary_accuracy: 0.7156 - loss: 0.5734 - precision: 0.7212 - recall: 0.4953\n",
            "Epoch 4/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - binary_accuracy: 0.8172 - loss: 0.4202 - precision: 0.8026 - recall: 0.7167\n",
            "Epoch 5/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - binary_accuracy: 0.8767 - loss: 0.3180 - precision: 0.8403 - recall: 0.8486\n",
            "Epoch 6/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - binary_accuracy: 0.9186 - loss: 0.2149 - precision: 0.8908 - recall: 0.9080\n",
            "Epoch 7/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - binary_accuracy: 0.9575 - loss: 0.1345 - precision: 0.9383 - recall: 0.9581\n",
            "Epoch 8/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - binary_accuracy: 0.9663 - loss: 0.1066 - precision: 0.9511 - recall: 0.9668\n",
            "Epoch 9/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - binary_accuracy: 0.9795 - loss: 0.0683 - precision: 0.9696 - recall: 0.9784\n",
            "Epoch 10/10\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - binary_accuracy: 0.9861 - loss: 0.0521 - precision: 0.9793 - recall: 0.9852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyl3DEr-bRK"
      },
      "source": [
        "# Task 5: Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_849c_EG-bRK"
      },
      "source": [
        "# Task 6: Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoCoBkHN-bRK"
      },
      "source": [
        "# Task 7: Error Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCNhVqZ9-bRL"
      },
      "source": [
        "# Task 8: Report"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}