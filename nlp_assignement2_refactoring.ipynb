{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d890930cbb1b4d54b9a65b5bb21c6699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8490c978180b43ecba3eb5ea77c7b6a4",
              "IPY_MODEL_a79b7af96f1d4b40b34ba69dfa8c6717",
              "IPY_MODEL_819a828a20b64ae694addc142ba472ca"
            ],
            "layout": "IPY_MODEL_bb80b520ebfb43b6bbb93b65db2b01c7"
          }
        },
        "8490c978180b43ecba3eb5ea77c7b6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0901a8dedbe04c5a985aab31b886ffaf",
            "placeholder": "​",
            "style": "IPY_MODEL_998086866c85414d923687e70a3ce379",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a79b7af96f1d4b40b34ba69dfa8c6717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1743b0df26b549eaa0792bbf46f9179f",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4f065a17030433db6c378d965dd43a8",
            "value": 3
          }
        },
        "819a828a20b64ae694addc142ba472ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30306a472a2b4d5689c56052867a6482",
            "placeholder": "​",
            "style": "IPY_MODEL_db872b961ff1430cbc7bc9921d2f247f",
            "value": " 3/3 [01:22&lt;00:00, 27.37s/it]"
          }
        },
        "bb80b520ebfb43b6bbb93b65db2b01c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0901a8dedbe04c5a985aab31b886ffaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "998086866c85414d923687e70a3ce379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1743b0df26b549eaa0792bbf46f9179f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4f065a17030433db6c378d965dd43a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30306a472a2b4d5689c56052867a6482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db872b961ff1430cbc7bc9921d2f247f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16c79fd62cdf44b78bfcefeea6051afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08b1732b7f074a97b71b7cdee1aff358",
              "IPY_MODEL_cc42b129858e45478f69fadb0cfe2db4",
              "IPY_MODEL_232f484a6422414e8443451d9340e41a"
            ],
            "layout": "IPY_MODEL_1d776726b8e7493c925526094bc95184"
          }
        },
        "08b1732b7f074a97b71b7cdee1aff358": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8964737df49648cc9596895a4b61554d",
            "placeholder": "​",
            "style": "IPY_MODEL_d5525b9b945e4473a2e862c828615c02",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "cc42b129858e45478f69fadb0cfe2db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec889c2f4bed4d9b94c6884e2eff863d",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31d07cff8db5401a9e895c21536f00ff",
            "value": 4
          }
        },
        "232f484a6422414e8443451d9340e41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78efd914248f4939bc3a9a8144af5d1f",
            "placeholder": "​",
            "style": "IPY_MODEL_80987f34fff04393ad33d15eea4d6523",
            "value": " 4/4 [01:19&lt;00:00, 17.07s/it]"
          }
        },
        "1d776726b8e7493c925526094bc95184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8964737df49648cc9596895a4b61554d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5525b9b945e4473a2e862c828615c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec889c2f4bed4d9b94c6884e2eff863d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d07cff8db5401a9e895c21536f00ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78efd914248f4939bc3a9a8144af5d1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80987f34fff04393ad33d15eea4d6523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatteoFasulo/Sexism-detection/blob/assignment2/Assignment_2_refactoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "\n",
        "\n",
        "**Keywords**: Sexism Detection, Multi-class Classification, LLMs, Prompting\n",
        "\n",
        "\n",
        "## Group\n",
        "\n",
        "* Luca Babboni - luca.babboni2@studio.unibo.it\n",
        "* Matteo Fasulo - matteo.fasulo@studio.unibo.it\n",
        "* Maksim Omelchenko - maksim.omelchenko@studio.unibo.it\n",
        "* Luca Tedeschini - luca.tedeschini3@studio.unibo.it\n",
        "\n"
      ],
      "metadata": {
        "id": "-WeCeITXoxLf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Description\n",
        "\n",
        "This notebook addresses [EDOS Task A](https://github.com/rewire-online/edos) on sexism detection.\n"
      ],
      "metadata": {
        "id": "Ck47wFhrLJnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem definition\n",
        "\n",
        "Given an input text sentence, the task is to label the sentence as sexist or not sexist (binary classification).\n",
        "\n",
        "### Examples:\n",
        "\n",
        "**Text**: *``Schedule a date with her, then don't show up. Then text her \"GOTCHA B___H\".''*\n",
        "\n",
        "**Label**: Sexist\n",
        "\n",
        "**Text**: *``That’s completely ridiculous a woman flashing her boobs is not sexual assault in the slightest.''*\n",
        "\n",
        "**Label**: Not sexist\n",
        "\n"
      ],
      "metadata": {
        "id": "5mtjp0cGLJnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Approach\n",
        "\n",
        "We will tackle the binary classification task with LLMs.\n",
        "\n",
        "In particular, we'll consider zero-/few-shot prompting approaches to assess the capability of some popular open-source LLMs on this task."
      ],
      "metadata": {
        "id": "3dqwRZx-QNGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminaries\n",
        "\n",
        "We are going to download LLMs from [Huggingface](https://huggingface.co/).\n",
        "\n",
        "Many of these open-source LLMs require you to accept their \"Community License Agreement\" to download them.\n",
        "\n",
        "In summary:\n",
        "\n",
        "- If not already, create an account of Huggingface (~2 mins)\n",
        "- Check a LLM model card page (e.g., [Mistral v3](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)) and accept its \"Community License Agreement\".\n",
        "- Go to your account -> Settings -> Access Tokens -> Create new token -> \"Repositories permissions\" -> add the LLM model card you want to use.\n",
        "- Save the token (we'll need it later)"
      ],
      "metadata": {
        "id": "PS3igwXpQcAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries\n",
        "In order to excecute the code we are gonna install and import the necessary libraries.\n",
        "First of all we are gonna install the last version of bitsandbytes in order to been able to use the quantization."
      ],
      "metadata": {
        "id": "U-X8hewlmS9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install -U bitsandbytes"
      ],
      "metadata": {
        "trusted": true,
        "id": "GZ1vH4IZmS9w"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we need to reload the notebook kernel"
      ],
      "metadata": {
        "id": "au5cCyPHmS9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "trusted": true,
        "id": "jr_Zow9jmS9x"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we are able to import the required libraries"
      ],
      "metadata": {
        "id": "XnZYE__amS9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "from copy import deepcopy\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
      ],
      "metadata": {
        "trusted": true,
        "id": "mDcr2AG-mS9y"
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Huggingface Login\n",
        "\n",
        "Once we have created an account and an access token, we need to login to Huggingface via code.\n",
        "\n",
        "- Type your token and press Enter\n",
        "- You can say No to Github linking"
      ],
      "metadata": {
        "id": "xqEsPH_JSxw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "_uWEUjs0THxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c902e8-a291-418f-ecf8-3916023be9ff",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:02:22.531220Z",
          "iopub.execute_input": "2024-12-21T14:02:22.531528Z",
          "iopub.status.idle": "2024-12-21T14:04:04.433864Z",
          "shell.execute_reply.started": "2024-12-21T14:02:22.531505Z",
          "shell.execute_reply": "2024-12-21T14:04:04.433009Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `Deleteme` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Deleteme`\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "secret_label = \"hf_key\"\n",
        "secret_value = UserSecretsClient().get_secret(secret_label)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:10:39.192548Z",
          "iopub.execute_input": "2024-12-21T14:10:39.192802Z",
          "iopub.status.idle": "2024-12-21T14:10:39.353436Z",
          "shell.execute_reply.started": "2024-12-21T14:10:39.192783Z",
          "shell.execute_reply": "2024-12-21T14:10:39.352613Z"
        },
        "id": "feMrJkRWmS9z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login --token {secret_value}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:10:39.354246Z",
          "iopub.execute_input": "2024-12-21T14:10:39.354521Z",
          "iopub.status.idle": "2024-12-21T14:10:40.036468Z",
          "shell.execute_reply.started": "2024-12-21T14:10:39.354500Z",
          "shell.execute_reply": "2024-12-21T14:10:40.035192Z"
        },
        "id": "vCL1mBiOmS9z"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "After login, you can download all models associated with your access token in addition to those that are not protected by an access token."
      ],
      "metadata": {
        "id": "MLxSrY-4e_0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading\n",
        "\n",
        "Since we are only interested in prompting, we do not require a train dataset.\n",
        "\n",
        "We have preparared a small test set version of EDOS in our dedicated [Github repository](https://github.com/lt-nlp-lab-unibo/nlp-course-material).\n",
        "\n",
        "Check the ``Assignment 2/data`` folder.\n",
        "It contains:\n",
        "\n",
        "- ``a2_test.csv`` → a small test set of 300 samples.\n",
        "- ``demonstrations.csv`` -> a batch of 1000 samples for few-shot prompting.\n",
        "\n",
        "Both datasets contain a balanced number of sexist and not sexist samples.\n"
      ],
      "metadata": {
        "id": "pEYMBnAQLJnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "We require you to:\n",
        "\n",
        "* **Download** the ``A2/data`` folder.\n",
        "* **Encode** ``a2_test.csv`` into a ``pandas.DataFrame`` object."
      ],
      "metadata": {
        "id": "B5XyOcFGLJnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_corpus(url: str, filename: str) -> None:\n",
        "    \"\"\"\n",
        "    Downloads a text corpus from a given URL and saves it to a specified filename within the data folder if not exist\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL from which to download the corpus.\n",
        "        filename (str): The name of the file to save the downloaded corpus.\n",
        "\n",
        "    Raises:\n",
        "        requests.exceptions.HTTPError: If the HTTP request returned an unsuccessful status code.\n",
        "\n",
        "    Side Effects:\n",
        "        Creates the data folder if it does not exist.\n",
        "        Writes the downloaded corpus to the specified file.\n",
        "    \"\"\"\n",
        "    data_folder = Path(\"./data\")\n",
        "    if not data_folder.exists():\n",
        "      data_folder.mkdir(parents=True)\n",
        "      print(f\"Created folder {data_folder}.\")\n",
        "\n",
        "    if not (data_folder / filename).exists():\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()\n",
        "      with open(data_folder / filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(response.text)\n",
        "      print(f\"Created file {data_folder / filename}.\")\n",
        "    else:\n",
        "      print(f\"File {data_folder / filename} already exists.\")"
      ],
      "metadata": {
        "id": "A3EWWaUiV_-a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:10:40.037780Z",
          "iopub.execute_input": "2024-12-21T14:10:40.038227Z",
          "iopub.status.idle": "2024-12-21T14:10:40.045979Z",
          "shell.execute_reply.started": "2024-12-21T14:10:40.038187Z",
          "shell.execute_reply": "2024-12-21T14:10:40.044663Z"
        }
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "path_test = 'https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/refs/heads/main/2024-2025/Assignment%202/data/a2_test.csv'\n",
        "path_demonstrations = 'https://raw.githubusercontent.com/nlp-unibo/nlp-course-material/refs/heads/main/2024-2025/Assignment%202/data/demonstrations.csv'"
      ],
      "metadata": {
        "id": "Fn09xmj8WCdR",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:10:40.047152Z",
          "iopub.execute_input": "2024-12-21T14:10:40.047549Z",
          "iopub.status.idle": "2024-12-21T14:10:40.066853Z",
          "shell.execute_reply.started": "2024-12-21T14:10:40.047515Z",
          "shell.execute_reply": "2024-12-21T14:10:40.066013Z"
        }
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "download_corpus(path_test, 'a2_test.csv')\n",
        "download_corpus(path_demonstrations, 'demonstrations.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlJz89U4WEQt",
        "outputId": "495eca4b-7de8-4998-d838-5071b8e1d442",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:10:40.067739Z",
          "iopub.execute_input": "2024-12-21T14:10:40.067962Z",
          "iopub.status.idle": "2024-12-21T14:10:40.084543Z",
          "shell.execute_reply.started": "2024-12-21T14:10:40.067932Z",
          "shell.execute_reply": "2024-12-21T14:10:40.083498Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created folder data.\n",
            "Created file data/a2_test.csv.\n",
            "Created file data/demonstrations.csv.\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./data/a2_test.csv', encoding='utf-8')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WDDxbr-CWKwu",
        "outputId": "27bc8f01-9ef6-4679-f964-dfae5703d094",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:10:40.085261Z",
          "iopub.execute_input": "2024-12-21T14:10:40.085567Z",
          "iopub.status.idle": "2024-12-21T14:10:40.110135Z",
          "shell.execute_reply.started": "2024-12-21T14:10:40.085538Z",
          "shell.execute_reply": "2024-12-21T14:10:40.109313Z"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  rewire_id  \\\n",
              "0  sexism2022_english-17133   \n",
              "1  sexism2022_english-14197   \n",
              "2   sexism2022_english-3018   \n",
              "3   sexism2022_english-5301   \n",
              "4  sexism2022_english-17796   \n",
              "\n",
              "                                                text label_sexist  \n",
              "0  The boys must be gaming because there goes the...   not sexist  \n",
              "1  Look at those eyes. Either someone unexpectedl...       sexist  \n",
              "2                  Old man mogs everyone in this sub   not sexist  \n",
              "3  Excellent, I was just looking at another post ...   not sexist  \n",
              "4  So you run back to daddy whenever you need hel...       sexist  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc778bbc-2a9e-4402-a8fd-8bbe50303447\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rewire_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label_sexist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sexism2022_english-17133</td>\n",
              "      <td>The boys must be gaming because there goes the...</td>\n",
              "      <td>not sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sexism2022_english-14197</td>\n",
              "      <td>Look at those eyes. Either someone unexpectedl...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sexism2022_english-3018</td>\n",
              "      <td>Old man mogs everyone in this sub</td>\n",
              "      <td>not sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sexism2022_english-5301</td>\n",
              "      <td>Excellent, I was just looking at another post ...</td>\n",
              "      <td>not sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sexism2022_english-17796</td>\n",
              "      <td>So you run back to daddy whenever you need hel...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc778bbc-2a9e-4402-a8fd-8bbe50303447')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc778bbc-2a9e-4402-a8fd-8bbe50303447 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc778bbc-2a9e-4402-a8fd-8bbe50303447');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b8ebf71-6978-4873-96f7-d3cef2c603e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b8ebf71-6978-4873-96f7-d3cef2c603e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b8ebf71-6978-4873-96f7-d3cef2c603e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"rewire_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"sexism2022_english-7642\",\n          \"sexism2022_english-15192\",\n          \"sexism2022_english-18390\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"what do you think about that ? Should i pay her ? Pay whatever she's minimally entitled to legally but kick her ass to the curb.\",\n          \"and whats new about this. a woman can be total garbage, but as long as she is fuckable she gets something.\",\n          \"Full on crotch grab from Biden. Even the baby's mom isn't holding him that way.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_sexist\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"sexist\",\n          \"not sexist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "execution_count": 85
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mistral V3 instruct in 8bit\n",
        "As first model we are gonna analyze the performance of Mistral V3"
      ],
      "metadata": {
        "id": "_cXaP301XYFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1 - Model setup\n",
        "\n",
        "Once the test data has been loaded, we have to setup the model pipeline for inference.\n",
        "\n",
        "In particular, we have to:\n",
        "- Load the model weights from Huggingface\n",
        "- Quantize the model to fit into a single-GPU limited hardware\n"
      ],
      "metadata": {
        "id": "HJp08l4yLJnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_card):\n",
        "    \"\"\"\n",
        "    Loads a pre-trained model and its tokenizer with 8-bit quantization.\n",
        "\n",
        "    Args:\n",
        "        model_card (str): The identifier of the pre-trained model to load.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the quantized model and the tokenizer.\n",
        "            - model_8bit (transformers.PreTrainedModel): The quantized model loaded in 8-bit precision.\n",
        "            - tokenizer (transformers.PreTrainedTokenizer): The tokenizer associated with the model.\n",
        "    \"\"\"\n",
        "    quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_card)\n",
        "    model_8bit = AutoModelForCausalLM.from_pretrained(model_card, quantization_config=quantization_config)\n",
        "    model_8bit.eval()\n",
        "    return model_8bit, tokenizer"
      ],
      "metadata": {
        "id": "mYXuFuCkUxOU",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:10:40.111156Z",
          "iopub.execute_input": "2024-12-21T14:10:40.111401Z",
          "iopub.status.idle": "2024-12-21T14:10:40.115425Z",
          "shell.execute_reply.started": "2024-12-21T14:10:40.111381Z",
          "shell.execute_reply": "2024-12-21T14:10:40.114609Z"
        }
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "model_card = 'mistralai/Mistral-7B-Instruct-v0.3'\n",
        "model_8bit, tokenizer = load_model(model_card)\n",
        "\n",
        "device = model_8bit.device\n",
        "print(f'Model loaded on {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "d890930cbb1b4d54b9a65b5bb21c6699",
            "8490c978180b43ecba3eb5ea77c7b6a4",
            "a79b7af96f1d4b40b34ba69dfa8c6717",
            "819a828a20b64ae694addc142ba472ca",
            "bb80b520ebfb43b6bbb93b65db2b01c7",
            "0901a8dedbe04c5a985aab31b886ffaf",
            "998086866c85414d923687e70a3ce379",
            "1743b0df26b549eaa0792bbf46f9179f",
            "c4f065a17030433db6c378d965dd43a8",
            "30306a472a2b4d5689c56052867a6482",
            "db872b961ff1430cbc7bc9921d2f247f"
          ]
        },
        "id": "U6G3bdIXW-c1",
        "outputId": "dc1e9782-c735-4bcd-c45b-8c25ad6dde54",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:10:40.116306Z",
          "iopub.execute_input": "2024-12-21T14:10:40.116568Z",
          "iopub.status.idle": "2024-12-21T14:17:19.956251Z",
          "shell.execute_reply.started": "2024-12-21T14:10:40.116536Z",
          "shell.execute_reply": "2024-12-21T14:17:19.955477Z"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d890930cbb1b4d54b9a65b5bb21c6699"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda:0\n"
          ]
        }
      ],
      "execution_count": 124
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 - Prompt setup\n",
        "\n",
        "Prompting requires an input pre-processing phase where we convert each input example into a specific instruction prompt.\n"
      ],
      "metadata": {
        "id": "TzNNzb1VLJnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Template\n",
        "\n",
        "Use the following prompt template to process input texts."
      ],
      "metadata": {
        "id": "9GaBtKXomY_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = [\n",
        "    {\n",
        "        'role': 'system',\n",
        "        'content': 'You are an annotator for sexism detection.'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': \"\"\"Your task is to classify input text as containing sexism or not. Respond only YES or NO.\n",
        "\n",
        "        TEXT:\n",
        "        {text}\n",
        "\n",
        "        ANSWER:\n",
        "        \"\"\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "7e8P-Kk8me6q",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:18:27.076797Z",
          "iopub.execute_input": "2024-12-21T14:18:27.077167Z",
          "iopub.status.idle": "2024-12-21T14:18:27.081350Z",
          "shell.execute_reply.started": "2024-12-21T14:18:27.077137Z",
          "shell.execute_reply": "2024-12-21T14:18:27.080448Z"
        }
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "In order to get Task 2 points, we require you to:\n",
        "\n",
        "* Write the ``prepare_prompts`` function"
      ],
      "metadata": {
        "id": "VHeoEN7MLJnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_prompts(texts, prompt_template, tokenizer, device):\n",
        "  \"\"\"\n",
        "    This function format input text samples into instructions prompts.\n",
        "\n",
        "    Inputs:\n",
        "      texts: input texts to classify via prompting\n",
        "      prompt_template: the prompt template provided in this assignment\n",
        "      tokenizer: the transformers Tokenizer object instance associated with the chosen model card\n",
        "\n",
        "    Outputs:\n",
        "      input texts to classify in the form of instruction prompts\n",
        "  \"\"\"\n",
        "  prompts = []\n",
        "  for text in texts:\n",
        "    prompt_with_text = deepcopy(prompt_template)\n",
        "    # add text\n",
        "    prompt_with_text[1]['content'] = prompt_with_text[1]['content'].replace('{text}', text)\n",
        "\n",
        "    prompts.append(tokenizer.apply_chat_template(prompt_with_text, tokenize=True,\n",
        "                                                 add_generation_prompt=True,\n",
        "                                                 return_dict=True,\n",
        "                                                 return_tensors=\"pt\").to(device))\n",
        "\n",
        "  return prompts"
      ],
      "metadata": {
        "id": "PUjRVMtMm9CE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:18:30.262619Z",
          "iopub.execute_input": "2024-12-21T14:18:30.263007Z",
          "iopub.status.idle": "2024-12-21T14:18:30.268023Z",
          "shell.execute_reply.started": "2024-12-21T14:18:30.262968Z",
          "shell.execute_reply": "2024-12-21T14:18:30.267212Z"
        }
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = prepare_prompts(df['text'], prompt, tokenizer, device=device)\n",
        "\n",
        "print(\"Prompt example: \\n\")\n",
        "print(tokenizer.decode(prompts[0].input_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:18:33.697325Z",
          "iopub.execute_input": "2024-12-21T14:18:33.697679Z",
          "iopub.status.idle": "2024-12-21T14:18:33.936985Z",
          "shell.execute_reply.started": "2024-12-21T14:18:33.697647Z",
          "shell.execute_reply": "2024-12-21T14:18:33.936245Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_aGPnEimS92",
        "outputId": "15885209-fe77-4318-ffcd-0cfbe11027ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt example: \n",
            "\n",
            "You are an annotator for sexism detection.\n",
            "\n",
            "Your task is to classify input text as containing sexism or not. Respond only YES or NO.\n",
            "\n",
            "        TEXT:\n",
            "        The boys must be gaming because there goes the wifi.\n",
            "\n",
            "        ANSWER:\n",
            "        \n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3 - Inference\n",
        "\n",
        "We are now ready to define the inference loop where we prompt the model with each pre-processed sample."
      ],
      "metadata": {
        "id": "lgBhkBwuLJnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "In order to get Task 3 points, we require you to:\n",
        "\n",
        "* Write a ``generate_responses`` function as the one reported below.\n",
        "* Write a ``process_response`` function as the one reported below."
      ],
      "metadata": {
        "id": "7WsrQSvcLJnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_responses(model, prompt_examples):\n",
        "  \"\"\"\n",
        "    This function implements the inference loop for a LLM model.\n",
        "    Given a set of examples, the model is tasked to generate a response.\n",
        "\n",
        "    Inputs:\n",
        "      model: LLM model instance for prompting\n",
        "      prompt_examples: pre-processed text samples\n",
        "\n",
        "    Outputs:\n",
        "      generated responses\n",
        "  \"\"\"\n",
        "  answers = []\n",
        "  for prompt in tqdm(prompt_examples):\n",
        "    response = model.generate(**prompt, max_new_tokens=1000, pad_token_id=tokenizer.eos_token_id)\n",
        "    answers.append(response)\n",
        "  return answers"
      ],
      "metadata": {
        "id": "bG3CDXNlyD5k",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:19:49.184065Z",
          "iopub.execute_input": "2024-12-21T14:19:49.184431Z",
          "iopub.status.idle": "2024-12-21T14:19:49.189395Z",
          "shell.execute_reply.started": "2024-12-21T14:19:49.184402Z",
          "shell.execute_reply": "2024-12-21T14:19:49.188294Z"
        }
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "def process_response(response):\n",
        "  \"\"\"\n",
        "    This function takes a textual response generated by the LLM\n",
        "    and processes it to map the response to a binary label.\n",
        "\n",
        "    Inputs:\n",
        "      response: generated response from LLM\n",
        "\n",
        "    Outputs:\n",
        "      parsed binary response: return 1 if YES and 0 if NO\n",
        "  \"\"\"\n",
        "  response = tokenizer.decode(response[0])\n",
        "  if 'YES' in response.split('ANSWER')[-1]:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "uiCoMrutyXTU",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:19:49.423525Z",
          "iopub.execute_input": "2024-12-21T14:19:49.423768Z",
          "iopub.status.idle": "2024-12-21T14:19:49.427967Z",
          "shell.execute_reply.started": "2024-12-21T14:19:49.423746Z",
          "shell.execute_reply": "2024-12-21T14:19:49.427029Z"
        }
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generated_response(response):\n",
        "  \"\"\"\n",
        "    This function takes a textual response generated by the LLM\n",
        "    and processes it to extract only the text generated by the LLM.\n",
        "\n",
        "    Inputs:\n",
        "      response: generated response from LLM\n",
        "\n",
        "    Outputs:\n",
        "      LLM generated text: string\n",
        "  \"\"\"\n",
        "  response = tokenizer.decode(response[0])\n",
        "  response = response.split('[/INST]')[-1]\n",
        "  cleaned_string = re.sub(r'</s>', '', response).strip()\n",
        "  return cleaned_string"
      ],
      "metadata": {
        "id": "gx-6h5Q8sykv"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = generate_responses(model_8bit, prompts)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:20:17.800166Z",
          "iopub.execute_input": "2024-12-21T14:20:17.800502Z",
          "iopub.status.idle": "2024-12-21T14:20:17.849132Z",
          "shell.execute_reply.started": "2024-12-21T14:20:17.800475Z",
          "shell.execute_reply": "2024-12-21T14:20:17.847701Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6PWskXKmS93",
        "outputId": "a33a93bd-55c2-4eee-c7b7-dfcf79e0b8db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [04:09<00:00,  1.20it/s]\n"
          ]
        }
      ],
      "execution_count": 55
    },
    {
      "cell_type": "code",
      "source": [
        "raw_answers = [tokenizer.decode(item[0]) for item in answers]\n",
        "batch_predictions = [process_response(item) for item in answers]\n",
        "generated_answers = [get_generated_response(item) for item in answers]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-21T14:04:15.097240Z",
          "iopub.status.idle": "2024-12-21T14:04:15.097592Z",
          "shell.execute_reply": "2024-12-21T14:04:15.097452Z"
        },
        "id": "wopoW3-rmS93"
      },
      "outputs": [],
      "execution_count": 69
    },
    {
      "cell_type": "code",
      "source": [
        "original_labels = [1 if label == 'sexist' else 0 for label in df['label_sexist']]"
      ],
      "metadata": {
        "id": "C56bN3DSpzoh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_predictions = pd.DataFrame({\n",
        "    'text': df['text'],\n",
        "    'original_labels': original_labels,\n",
        "    'Mistralv3_zero_shot_labels': batch_predictions,\n",
        "    'Mistralv3_zero_shot_answers': generated_answers\n",
        "})"
      ],
      "metadata": {
        "id": "KHDrhy10pY8p"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_predictions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "aJsP84Cmp7Fh",
        "outputId": "9f978805-7ae5-4a85-fc84-b2c6766cffd5"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  original_labels  \\\n",
              "0  The boys must be gaming because there goes the...                0   \n",
              "1  Look at those eyes. Either someone unexpectedl...                1   \n",
              "2                  Old man mogs everyone in this sub                0   \n",
              "3  Excellent, I was just looking at another post ...                0   \n",
              "4  So you run back to daddy whenever you need hel...                1   \n",
              "\n",
              "   Mistralv3_zero_shot_labels Mistralv3_zero_shot_answers  \n",
              "0                           1                         YES  \n",
              "1                           1                         YES  \n",
              "2                           0                          NO  \n",
              "3                           1                         YES  \n",
              "4                           1                         YES  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a7e2ae0-f67e-4a55-b24d-1c081386d8ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>original_labels</th>\n",
              "      <th>Mistralv3_zero_shot_labels</th>\n",
              "      <th>Mistralv3_zero_shot_answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The boys must be gaming because there goes the...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Look at those eyes. Either someone unexpectedl...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Old man mogs everyone in this sub</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent, I was just looking at another post ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So you run back to daddy whenever you need hel...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a7e2ae0-f67e-4a55-b24d-1c081386d8ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a7e2ae0-f67e-4a55-b24d-1c081386d8ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a7e2ae0-f67e-4a55-b24d-1c081386d8ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ef64b82-dc68-4333-9672-6b06e2ce7d08\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ef64b82-dc68-4333-9672-6b06e2ce7d08')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ef64b82-dc68-4333-9672-6b06e2ce7d08 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "models_predictions",
              "summary": "{\n  \"name\": \"models_predictions\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"what do you think about that ? Should i pay her ? Pay whatever she's minimally entitled to legally but kick her ass to the curb.\",\n          \"and whats new about this. a woman can be total garbage, but as long as she is fuckable she gets something.\",\n          \"Full on crotch grab from Biden. Even the baby's mom isn't holding him that way.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mistralv3_zero_shot_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mistralv3_zero_shot_answers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"NO (The text does not contain sexism)\",\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4 - Metrics\n",
        "\n",
        "In order to evaluate selected LLMs, we need to compute performance metrics.\n",
        "\n",
        "In particular, we are interested in computing **accuracy** since the provided data is balanced with respect to classification classes.\n",
        "\n",
        "Moreover, we want to compute the ratio of failed responses generated by models.\n",
        "\n",
        "That is, how frequent the LLM fails to follow instructions and provides incorrect responses that do not address the classification task.\n",
        "\n",
        "We denote this metric as **fail-ratio**.\n",
        "\n",
        "In summary, we parse generated responses as follows:\n",
        "- 1 if the model says YES\n",
        "- 0 if the model says NO\n",
        "- 0 if the model does not answer in either way"
      ],
      "metadata": {
        "id": "KyZ8WU09zz-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "In order to get Task 4 points, we require you to:\n",
        "\n",
        "* Write a ``compute_metrics`` function as the one reported below.\n",
        "* Compute metrics for the two selected LLMs."
      ],
      "metadata": {
        "id": "y6lu64o80iX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(responses, y_true):\n",
        "  \"\"\"\n",
        "    This function takes predicted and ground-truth labels and compute metrics.\n",
        "    In particular, this function compute accuracy and fail-ratio metrics.\n",
        "    This function internally invokes `process_response` to compute metrics.\n",
        "\n",
        "    Inputs:\n",
        "      responses: generated LLM responses\n",
        "      y_true: ground-truth binary labels\n",
        "\n",
        "    Outputs:\n",
        "      dictionary containing desired metrics\n",
        "  \"\"\"\n",
        "  y_pred = [process_response(response) for response in responses]\n",
        "  accuracy = (np.array(y_pred) == np.array(y_true)).mean()\n",
        "  fail_ratio = (np.array(y_pred) != np.array(y_true)).mean()\n",
        "  return {'accuracy': accuracy, 'fail_ratio': fail_ratio}"
      ],
      "metadata": {
        "id": "9Fmcw_9v0k9D",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 73
    },
    {
      "cell_type": "code",
      "source": [
        "mistal_base_metrics = compute_metrics(answers, original_labels)"
      ],
      "metadata": {
        "id": "rrIxiMwXryA0"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key, value in mistal_base_metrics.items():\n",
        "  print(f'{key}: {value:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1c_5q7cr2dz",
        "outputId": "c56b9115-57bd-475f-e51e-5e9bf5610381"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.61\n",
            "fail_ratio: 0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create the new dataset for storing the metrics\n",
        "model_metrics = pd.DataFrame(columns=['model', 'accuracy', 'fail_ratio'])\n",
        "#add the computed metrics to the metric dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'Mistral v3 zero shot', 'accuracy': mistal_base_metrics['accuracy'], 'fail_ratio': mistal_base_metrics['fail_ratio']}"
      ],
      "metadata": {
        "id": "RDTwjbnfzes0"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "\n",
        "responses = [process_response(response) for response in answers]\n",
        "confusion_matrix = metrics.confusion_matrix(original_labels, responses)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"not sexist\", \"sexist\"])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RmdvLO1jtkw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5 - Few-shot Inference\n",
        "\n",
        "So far, we have tested models in a zero-shot fashion: we provide the input text to classify and instruct the model to generate a response.\n",
        "\n",
        "We are now interested in performing few-shot prompting to see the impact of providing demonstration examples.\n",
        "\n",
        "To do so, we slightly change the prompt template as follows."
      ],
      "metadata": {
        "id": "nHyvV4QD2vZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_few_shot = [\n",
        "    {\n",
        "        'role': 'system',\n",
        "        'content': 'You are an annotator for sexism detection.'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': \"\"\"Your task is to classify input text as containing sexism or not. Respond only YES or NO.\n",
        "\n",
        "        EXAMPLES:\n",
        "        {examples}\n",
        "\n",
        "        TEXT:\n",
        "        {text}\n",
        "\n",
        "        ANSWER:\n",
        "        \"\"\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "pEqsOHz63ReW",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 86
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new prompt template reports some demonstration examples to instruct the model.\n",
        "\n",
        "Generally, we provide an equal number of demonstrations per class as shown in the example below.\n",
        "\n",
        "```\n",
        "prompt = [\n",
        "    {\n",
        "        'role': 'system',\n",
        "        'content': 'You are an annotator for sexism detection.'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': \"\"\"Your task is to classify input text as containing sexism or not. Respond only YES or NO.\n",
        "\n",
        "        EXAMPLES:\n",
        "        TEXT: **example 1**\n",
        "        ANSWER: YES\n",
        "        TEXT: **example 2**\n",
        "        ANSWER: NO\n",
        "\n",
        "        TEXT:\n",
        "        {text}\n",
        "\n",
        "        ANSWER:\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "```  "
      ],
      "metadata": {
        "id": "_SnaxuwN3ySF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions\n",
        "\n",
        "In order to get Task 5 points, we require you to:\n",
        "\n",
        "- Load ``demonstrations.csv`` and encode it into a ``pandas.DataFrame`` object.\n",
        "- Define a ``build_few_shot_demonstrations`` function as the one reported below.\n",
        "- Perform few-shot inference as in Task 3.\n",
        "- Compute metrics as in Task 4."
      ],
      "metadata": {
        "id": "OE0XnaVr3CZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demonstrations = pd.read_csv('./data/demonstrations.csv')\n",
        "demonstrations.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6bbJtxNst2FF",
        "outputId": "5b8e7fec-14a5-48e9-f391-b136caa426d7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  rewire_id  \\\n",
              "0  sexism2022_english-10348   \n",
              "1   sexism2022_english-7950   \n",
              "2   sexism2022_english-7742   \n",
              "3  sexism2022_english-16170   \n",
              "4   sexism2022_english-9857   \n",
              "\n",
              "                                                text label_sexist  \n",
              "0  I would never have my kid go to a daycare with...   not sexist  \n",
              "1           Democrat women are so butt fucking ugly.       sexist  \n",
              "2  If you really wanted to twist the knife you’d ...   not sexist  \n",
              "3  Those women are pro-rape. They didn’t care abo...       sexist  \n",
              "4  Married a bitch... Is it the standard scenario...       sexist  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8b3babe-b850-44c5-b7a6-9b4bd3a492b0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rewire_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label_sexist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sexism2022_english-10348</td>\n",
              "      <td>I would never have my kid go to a daycare with...</td>\n",
              "      <td>not sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sexism2022_english-7950</td>\n",
              "      <td>Democrat women are so butt fucking ugly.</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sexism2022_english-7742</td>\n",
              "      <td>If you really wanted to twist the knife you’d ...</td>\n",
              "      <td>not sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sexism2022_english-16170</td>\n",
              "      <td>Those women are pro-rape. They didn’t care abo...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sexism2022_english-9857</td>\n",
              "      <td>Married a bitch... Is it the standard scenario...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8b3babe-b850-44c5-b7a6-9b4bd3a492b0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8b3babe-b850-44c5-b7a6-9b4bd3a492b0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8b3babe-b850-44c5-b7a6-9b4bd3a492b0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b976635-2422-48e5-9061-72d628cb5e31\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b976635-2422-48e5-9061-72d628cb5e31')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b976635-2422-48e5-9061-72d628cb5e31 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "demonstrations",
              "summary": "{\n  \"name\": \"demonstrations\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"rewire_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"sexism2022_english-1375\",\n          \"sexism2022_english-278\",\n          \"sexism2022_english-7964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1000,\n        \"samples\": [\n          \"untouched Not after 6 years, especially not if she went to college\",\n          \"I understand. We will purge hidden eurofag scum from Holy City of Miami, burn down their illegal particle accelerator labs stretching underneath the capital!\",\n          \"A Mississippi state senator hits the DC women protesters with a serious burn.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_sexist\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"sexist\",\n          \"not sexist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_few_shot_demonstrations(demonstrations, num_per_class=2):\n",
        "  \"\"\"\n",
        "    Inputs:\n",
        "      demonstrations: the pandas.DataFrame object wrapping demonstrations.csv\n",
        "      num_per_class: number of demonstrations per class\n",
        "\n",
        "    Outputs:\n",
        "      a list of textual demonstrations to inject into the prompt template.\n",
        "  \"\"\"\n",
        "  yes_samples = demonstrations[demonstrations['label_sexist'] == 'sexist'].sample(num_per_class)\n",
        "  no_samples = demonstrations[demonstrations['label_sexist'] == 'not sexist'].sample(num_per_class)\n",
        "\n",
        "  few_shot_demonstrations = list(pd.concat([yes_samples['text'], no_samples['text']]))\n",
        "\n",
        "  return few_shot_demonstrations"
      ],
      "metadata": {
        "id": "6oyxypUG3ltH",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 88
    },
    {
      "cell_type": "code",
      "source": [
        "build_few_shot_demonstrations(demonstrations, num_per_class=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK1krdxZuANq",
        "outputId": "ec060e0f-3bf8-4c96-957f-0a7fce2f3bfd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['she is the nastiest jew bitch ever born',\n",
              " 'all very banal tasks that the average female \\\\(and simp\\\\) complains about',\n",
              " 'Well thats a couple of life terms for this piece of shit. Actually with the record of piss weak Australian judges she will likely get a $100 fine. I am not surprised, govt hires anyone at all.',\n",
              " 'I would never have my kid go to a daycare with a nog working there. But I also would keep it to myself. Also that font she used should be considered a hate crime']"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_prompts_few_shot(texts, demonstrations, prompt_template, tokenizer, device):\n",
        "  \"\"\"\n",
        "    This function format input text samples into instructions prompts.\n",
        "\n",
        "    Inputs:\n",
        "      texts: input texts to classify via prompting\n",
        "      prompt_template: the prompt template provided in this assignment\n",
        "      tokenizer: the transformers Tokenizer object instance associated with the chosen model card\n",
        "\n",
        "    Outputs:\n",
        "      input texts to classify in the form of instruction prompts\n",
        "  \"\"\"\n",
        "  prompts = []\n",
        "  for text in texts:\n",
        "    prompt_with_text = deepcopy(prompt_template)\n",
        "    demonstration = ''\n",
        "    for i, d in enumerate(demonstrations):\n",
        "      if i < len(demonstrations) // 2:\n",
        "        demonstration += '\\tTEXT: ' + d + '\\n\\tANSWER: YES\\n'\n",
        "      else:\n",
        "        demonstration += '\\tTEXT: ' + d + '\\n\\tANSWER: NO\\n'\n",
        "\n",
        "    # remove extra \\t\n",
        "    demonstration = demonstration[1:]\n",
        "    prompt_with_text[1]['content'] = prompt_with_text[1]['content'].replace('{examples}', demonstration)\n",
        "\n",
        "    prompt_with_text[1]['content'] = prompt_with_text[1]['content'].replace('{text}', text)\n",
        "    prompts.append(tokenizer.apply_chat_template(prompt_with_text, tokenize=True, add_generation_prompt=True,\n",
        "              return_dict=True,\n",
        "              return_tensors=\"pt\").to(device))\n",
        "\n",
        "  return prompts"
      ],
      "metadata": {
        "id": "b5YuWhWouTDg"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-shot leaning"
      ],
      "metadata": {
        "id": "zSDUqAWDuVQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_few_shot = prepare_prompts_few_shot(df['text'], build_few_shot_demonstrations(demonstrations, num_per_class=2), prompt_few_shot, tokenizer, device=device)"
      ],
      "metadata": {
        "id": "9RX9riA6u3kW"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(prompts_few_shot[0].input_ids[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaKx8kinvY3S",
        "outputId": "9a610823-083d-41aa-edc7-de46c4a3b42f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] You are an annotator for sexism detection.\n",
            "\n",
            "Your task is to classify input text as containing sexism or not. Respond only YES or NO.\n",
            "\n",
            "        EXAMPLES:\n",
            "        TEXT: That's what stupid gullible women do. I know of one woman who had children with different black men. Another stupid shit who married a muhammedan got beat up. Both are now divorced and living on welfare. But yes, their children are not geniuses.\n",
            "\tANSWER: YES\n",
            "\tTEXT: Normies will never admit that the best they can hope for is beta buxxing. Glorified baby sitters (since women are children) that get to sleep in the same bed as a women while getting starfish sex once a month all while fueling her lavish lifestyle\n",
            "\tANSWER: YES\n",
            "\tTEXT: It's bluepilled as fuck and none of their memes are funny, but I can't really hate on it because in the end it's just coping incels in denial. In time, they will embrace the blackpill\n",
            "\tANSWER: NO\n",
            "\tTEXT: And you have saved how many from an ass kicking.\n",
            "\tANSWER: NO\n",
            "\n",
            "\n",
            "        TEXT:\n",
            "        The boys must be gaming because there goes the wifi.\n",
            "\n",
            "        ANSWER:\n",
            "        [/INST]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answers = generate_responses(model_8bit, prompts_few_shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yr6VsBDwT8H",
        "outputId": "463c1a7b-9e69-4d9c-c505-bf289792fa4c"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [09:23<00:00,  1.88s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_predictions = [process_response(item) for item in answers]\n",
        "generated_answers = [get_generated_response(item) for item in answers]\n",
        "models_predictions['mistalv3_4_shot'] = batch_predictions\n",
        "models_predictions['mistralv3_zero_4_answers'] = generated_answers"
      ],
      "metadata": {
        "id": "_DT4tBF2w0nn"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the metrics\n",
        "mistalv3_4_shot_metrics = compute_metrics(answers, original_labels)\n",
        "\n",
        "#add the metric to the dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'Mistral v3 4 shot', 'accuracy': mistalv3_4_shot_metrics['accuracy'], 'fail_ratio': mistalv3_4_shot_metrics['fail_ratio']}\n",
        "\n",
        "#print the metrics\n",
        "for key, value in mistalv3_4_shot_metrics.items():\n",
        "  print(f'{key}: {value:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKFryTDD3ECP",
        "outputId": "78de88c8-6aea-4fd7-a967-15891e7f6589"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.75\n",
            "fail_ratio: 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8-shot leaning"
      ],
      "metadata": {
        "id": "Q3vNuk3GuadK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_few_shot = prepare_prompts_few_shot(df['text'], build_few_shot_demonstrations(demonstrations, num_per_class=4), prompt, tokenizer, device=device)"
      ],
      "metadata": {
        "id": "ChUH3qt2uUcs"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = generate_responses(model_8bit, prompts_few_shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrNb7wUOxe0P",
        "outputId": "953e0987-b4b5-4fdb-b54d-40c75144b952"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [04:01<00:00,  1.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the metrics\n",
        "mistalv3_8_shot_metrics = compute_metrics(answers, original_labels)\n",
        "\n",
        "#add the metric to the dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'Mistral v3 8 shot', 'accuracy': mistalv3_8_shot_metrics['accuracy'], 'fail_ratio': mistalv3_8_shot_metrics['fail_ratio']}\n",
        "\n",
        "#print the metrics\n",
        "for key, value in mistalv3_8_shot_metrics.items():\n",
        "  print(f'{key}: {value:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab--sadwxgbK",
        "outputId": "fe4bc1ed-bcb5-4a79-e060-db25679792a0"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.61\n",
            "fail_ratio: 0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_predictions = [process_response(item) for item in answers]\n",
        "generated_answers = [get_generated_response(item) for item in answers]\n",
        "\n",
        "models_predictions['mistralv3_8_shot_labels'] = batch_predictions\n",
        "models_predictions['mistralv3_8_shot_answers'] = generated_answers"
      ],
      "metadata": {
        "id": "i0FHL9Nnxi6b"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12 shot"
      ],
      "metadata": {
        "id": "-7UHhNdB1RFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_few_shot = prepare_prompts_few_shot(df['text'], build_few_shot_demonstrations(demonstrations, num_per_class=6), prompt, tokenizer, device=device)"
      ],
      "metadata": {
        "id": "4qMuNSec1PNV"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = generate_responses(model_8bit, prompts_few_shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYZ0Y88a1PhU",
        "outputId": "cfa21619-abcd-420a-b21f-d645240ed4b6"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [05:37<00:00,  1.13s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the metrics\n",
        "mistalv3_12_shot_metrics = compute_metrics(answers, original_labels)\n",
        "\n",
        "#add the metric to the dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'Mistral v3 12 shot', 'accuracy': mistalv3_12_shot_metrics['accuracy'], 'fail_ratio': mistalv3_12_shot_metrics['fail_ratio']}\n",
        "\n",
        "#print the metrics\n",
        "for key, value in mistalv3_12_shot_metrics.items():\n",
        "  print(f'{key}: {value:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUOaBaDS1Pxe",
        "outputId": "60b45fdc-0da9-4457-c976-e0ec11d7ae4c"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.61\n",
            "fail_ratio: 0.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_predictions = [process_response(item) for item in answers]\n",
        "generated_answers = [get_generated_response(item) for item in answers]\n",
        "\n",
        "models_predictions['mistralv3_12_shot_labels'] = batch_predictions\n",
        "models_predictions['mistralv3_12_shot_answers'] = generated_answers"
      ],
      "metadata": {
        "id": "741Mq1AS1Z6y"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Llama 2 8B"
      ],
      "metadata": {
        "id": "mk4fkuU63rud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1 - Model setup"
      ],
      "metadata": {
        "id": "3sBEW4Bt4XZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del model_8bit"
      ],
      "metadata": {
        "id": "Lkf7FHBC_fo4",
        "outputId": "8004fd01-8e5a-4395-98e5-9873467e200d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_8bit' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-bfe84c9c2bb4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel_8bit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_8bit' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "with torch.no_grad():\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eO1_XJW8UVy",
        "outputId": "85f28a40-c37a-44da-b8dc-2b6fc30d5be5"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_card = 'meta-llama/Meta-Llama-3.1-8B-Instruct'\n",
        "model_8bit, tokenizer = load_model(model_card)\n",
        "\n",
        "device = model_8bit.device\n",
        "print(f'Model loaded on {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "16c79fd62cdf44b78bfcefeea6051afd",
            "08b1732b7f074a97b71b7cdee1aff358",
            "cc42b129858e45478f69fadb0cfe2db4",
            "232f484a6422414e8443451d9340e41a",
            "1d776726b8e7493c925526094bc95184",
            "8964737df49648cc9596895a4b61554d",
            "d5525b9b945e4473a2e862c828615c02",
            "ec889c2f4bed4d9b94c6884e2eff863d",
            "31d07cff8db5401a9e895c21536f00ff",
            "78efd914248f4939bc3a9a8144af5d1f",
            "80987f34fff04393ad33d15eea4d6523"
          ]
        },
        "id": "JxLvpCzs31tB",
        "outputId": "e08aa7fa-ac7f-4c40-8429-a7e9088502f7"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16c79fd62cdf44b78bfcefeea6051afd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 - Prompt setup"
      ],
      "metadata": {
        "id": "iScyBUeZ4Sa_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = prepare_prompts(df['text'], prompt, tokenizer, device=device)\n",
        "\n",
        "print(\"Prompt example: \\n\")\n",
        "print(tokenizer.decode(prompts[0].input_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFjp7Bre4SAN",
        "outputId": "4053e179-dd93-49c4-c97a-1e6f78ebf3cd"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt example: \n",
            "\n",
            "system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 Jul 2024\n",
            "\n",
            "You are an annotator for sexism detection.user\n",
            "\n",
            "Your task is to classify input text as containing sexism or not. Respond only YES or NO.\n",
            "\n",
            "        TEXT:\n",
            "        The boys must be gaming because there goes the wifi.\n",
            "\n",
            "        ANSWER:assistant\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3 - Inference\n"
      ],
      "metadata": {
        "id": "B14-Hife4ffk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generated_response(response):\n",
        "  \"\"\"\n",
        "    This function takes a textual response generated by the LLM\n",
        "    and processes it to extract only the text generated by the LLM.\n",
        "\n",
        "    Inputs:\n",
        "      response: generated response from LLM\n",
        "\n",
        "    Outputs:\n",
        "      LLM generated text: string\n",
        "  \"\"\"\n",
        "  response = tokenizer.decode(response[0])\n",
        "  response = response.split('<|end_header_id|>')[-1]\n",
        "  response = re.sub(r'</s>', '', response).strip()\n",
        "  response = re.sub(r'<\\|eot_id\\|>', '', response).strip()\n",
        "  return response"
      ],
      "metadata": {
        "id": "W_YXwBmeDy7l"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = generate_responses(model_8bit, prompts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZ8WN74e4ega",
        "outputId": "e86ada16-9861-4401-db93-faaa587ee3ae"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [01:50<00:00,  2.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_predictions = [process_response(item) for item in answers]\n",
        "generated_answers = [get_generated_response(item) for item in answers]"
      ],
      "metadata": {
        "id": "i6qZ3dok4nLs"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_predictions['llama3_zero_shot_labels'] = batch_predictions\n",
        "models_predictions['llama3_zero_shot_answers'] = generated_answers"
      ],
      "metadata": {
        "id": "8pxVobfF4oM5"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4 - Metrics"
      ],
      "metadata": {
        "id": "iyy6Cb9a7iFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#compute the metrics\n",
        "llama3_base_metrics = compute_metrics(answers, original_labels)\n",
        "\n",
        "#add the metric to the dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'llama3 base metrics', 'accuracy': llama3_base_metrics['accuracy'], 'fail_ratio': llama3_base_metrics['fail_ratio']}\n",
        "\n",
        "#print the metrics\n",
        "for key, value in mistalv3_4_shot_metrics.items():\n",
        "  print(f'{key}: {value:.2f}')"
      ],
      "metadata": {
        "id": "lVVeIDjI77WC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ec92cc3-1411-42be-c8df-e58c1298949a"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.75\n",
            "fail_ratio: 0.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5 - Few-shot Inference"
      ],
      "metadata": {
        "id": "p6AQAD-S8xUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4-shot leaning"
      ],
      "metadata": {
        "id": "9cTQNJHK84PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_few_shot = prepare_prompts_few_shot(df['text'], build_few_shot_demonstrations(demonstrations, num_per_class=2), prompt_few_shot, tokenizer, device=device)"
      ],
      "metadata": {
        "id": "HnVClc6U8wTn"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = generate_responses(model_8bit, prompts_few_shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju_hng3_9BQJ",
        "outputId": "fd0a4c65-870b-4ce1-d695-415651a23f31"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [02:00<00:00,  2.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_predictions = [process_response(item) for item in answers]\n",
        "generated_answers = [get_generated_response(item) for item in answers]\n",
        "\n",
        "models_predictions['llama3_4_shot_labels'] = batch_predictions\n",
        "models_predictions['llama3_4_shot_answers'] = batch_predictions"
      ],
      "metadata": {
        "id": "t1HKRXTO9N4W"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute metrics\n",
        "llama3_4_shot_metrics = compute_metrics(answers, original_labels)\n",
        "\n",
        "#add the metric to the dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'llama3 4 shot metrics', 'accuracy': llama3_4_shot_metrics['accuracy'], 'fail_ratio': llama3_4_shot_metrics['fail_ratio']}\n",
        "\n",
        "#print the metrics\n",
        "for key, value in llama3_4_shot_metrics.items():\n",
        "  print(f'{key}: {value:.2f}')"
      ],
      "metadata": {
        "id": "wcBhjqEmAbyJ",
        "outputId": "696eb429-0459-4616-a3a8-7e056186caa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.72\n",
            "fail_ratio: 0.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8-shot leaning"
      ],
      "metadata": {
        "id": "7uaGQ3vL9UqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_few_shot = prepare_prompts_few_shot(df['text'], build_few_shot_demonstrations(demonstrations, num_per_class=4), prompt, tokenizer, device=device)"
      ],
      "metadata": {
        "id": "7zG6LSBm9UL3"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = generate_responses(model_8bit, prompts_few_shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR42AHOn9YGV",
        "outputId": "7926bd8e-a7af-4738-b21d-9dd7b46264c2"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [01:34<00:00,  3.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_predictions = [process_response(item) for item in answers]\n",
        "generated_answers = [get_generated_response(item) for item in answers]\n",
        "\n",
        "models_predictions['llama3_8_shot_labels'] = batch_predictions\n",
        "models_predictions['llama3_8_shot_answers'] = generated_answers"
      ],
      "metadata": {
        "id": "Xco3lncXBgSb"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute metrics\n",
        "llama3_8_shot_metrics = compute_metrics(answers, original_labels)\n",
        "\n",
        "#add the metric to the dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'llama3 8 shot metrics', 'accuracy': llama3_8_shot_metrics['accuracy'], 'fail_ratio': llama3_8_shot_metrics['fail_ratio']}\n",
        "\n",
        "for key, value in llama3_8_shot_metrics.items():\n",
        "  print(f'{key}: {value:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAlUXz2x9aPi",
        "outputId": "fd3cc489-d8ef-4daa-d385-c787326295c7"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.65\n",
            "fail_ratio: 0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12-shot leaning"
      ],
      "metadata": {
        "id": "cqv6SP5qB4Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_few_shot = prepare_prompts_few_shot(df['text'], build_few_shot_demonstrations(demonstrations, num_per_class=6), prompt, tokenizer, device=device)"
      ],
      "metadata": {
        "id": "4sF0N5WvCAcl"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = generate_responses(model_8bit, prompts_few_shot)"
      ],
      "metadata": {
        "id": "jJP4sunkCARi",
        "outputId": "22f86776-764b-4a19-9b8c-e989313a48f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [01:34<00:00,  3.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_predictions = [process_response(item) for item in answers]\n",
        "generated_answers = [get_generated_response(item) for item in answers]\n",
        "\n",
        "models_predictions['llama3_12_shot_labels'] = batch_predictions\n",
        "models_predictions['llama3_12_shot_answers'] = generated_answers"
      ],
      "metadata": {
        "id": "7sdiQpnj9rXA"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compute metrics\n",
        "llama3_12_shot_metrics = compute_metrics(answers, original_labels)\n",
        "\n",
        "#add the metric to the dataset\n",
        "model_metrics.loc[len(model_metrics)] = {'model': 'llama3 12 shot metrics', 'accuracy': llama3_12_shot_metrics['accuracy'], 'fail_ratio': llama3_12_shot_metrics['fail_ratio']}\n",
        "\n",
        "for key, value in llama3_12_shot_metrics.items():\n",
        "  print(f'{key}: {value:.2f}')"
      ],
      "metadata": {
        "id": "23EfefQ0CLQB",
        "outputId": "53c1fd22-76d3-48df-8539-c99a7c20d2ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.66\n",
            "fail_ratio: 0.34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_predictions.head()"
      ],
      "metadata": {
        "id": "IPjLhy2ACcjA",
        "outputId": "43c535d1-e9d0-4677-f74b-16c328666c53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        }
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  original_labels  \\\n",
              "0  The boys must be gaming because there goes the...                0   \n",
              "1  Look at those eyes. Either someone unexpectedl...                1   \n",
              "2                  Old man mogs everyone in this sub                0   \n",
              "3  Excellent, I was just looking at another post ...                0   \n",
              "4  So you run back to daddy whenever you need hel...                1   \n",
              "\n",
              "   Mistralv3_zero_shot_labels Mistralv3_zero_shot_answers  mistalv3_4_shot  \\\n",
              "0                           1                         YES                0   \n",
              "1                           1                         YES                1   \n",
              "2                           0                          NO                0   \n",
              "3                           1                         YES                1   \n",
              "4                           1                         YES                1   \n",
              "\n",
              "  mistralv3_zero_4_answers  mistalv3_8_shot_labels mistralv3_zero_8_answers  \\\n",
              "0                       NO                       1                      YES   \n",
              "1                      YES                       1                      YES   \n",
              "2                       NO                       0                       NO   \n",
              "3                      YES                       1                      YES   \n",
              "4                      YES                       1                      YES   \n",
              "\n",
              "   mistralv3_12_shot_labels mistralv3_12_shot_answers  llama3_zero_shot  \\\n",
              "0                         1                       YES                 0   \n",
              "1                         1                       YES                 1   \n",
              "2                         0                        NO                 0   \n",
              "3                         1                       YES                 1   \n",
              "4                         1                       YES                 1   \n",
              "\n",
              "  llama3_zero_shot_answers  llama3_zero_shot_labels  llama3_4_shot_labels  \\\n",
              "0                       NO                        0                     0   \n",
              "1                      YES                        1                     1   \n",
              "2                      YES                        1                     0   \n",
              "3                      YES                        1                     1   \n",
              "4                      YES                        1                     1   \n",
              "\n",
              "   llama3_4_shot_answers  llama3_8_shot_labels llama3_8_shot_answers  \\\n",
              "0                      0                     0                    NO   \n",
              "1                      1                     1                   YES   \n",
              "2                      0                     1                   YES   \n",
              "3                      1                     1                   YES   \n",
              "4                      1                     1                   YES   \n",
              "\n",
              "   llama3_12_shot_labels llama3_12_shot_answers  \n",
              "0                      0                     NO  \n",
              "1                      1                    YES  \n",
              "2                      0                     NO  \n",
              "3                      1                    YES  \n",
              "4                      1                    YES  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b07600ee-bf3b-4ab2-85b7-542a52e096ae\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>original_labels</th>\n",
              "      <th>Mistralv3_zero_shot_labels</th>\n",
              "      <th>Mistralv3_zero_shot_answers</th>\n",
              "      <th>mistalv3_4_shot</th>\n",
              "      <th>mistralv3_zero_4_answers</th>\n",
              "      <th>mistalv3_8_shot_labels</th>\n",
              "      <th>mistralv3_zero_8_answers</th>\n",
              "      <th>mistralv3_12_shot_labels</th>\n",
              "      <th>mistralv3_12_shot_answers</th>\n",
              "      <th>llama3_zero_shot</th>\n",
              "      <th>llama3_zero_shot_answers</th>\n",
              "      <th>llama3_zero_shot_labels</th>\n",
              "      <th>llama3_4_shot_labels</th>\n",
              "      <th>llama3_4_shot_answers</th>\n",
              "      <th>llama3_8_shot_labels</th>\n",
              "      <th>llama3_8_shot_answers</th>\n",
              "      <th>llama3_12_shot_labels</th>\n",
              "      <th>llama3_12_shot_answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The boys must be gaming because there goes the...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Look at those eyes. Either someone unexpectedl...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Old man mogs everyone in this sub</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "      <td>0</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>0</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Excellent, I was just looking at another post ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So you run back to daddy whenever you need hel...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "      <td>1</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b07600ee-bf3b-4ab2-85b7-542a52e096ae')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b07600ee-bf3b-4ab2-85b7-542a52e096ae button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b07600ee-bf3b-4ab2-85b7-542a52e096ae');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d52d88aa-6256-4607-96a2-6ad45e21ea2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d52d88aa-6256-4607-96a2-6ad45e21ea2e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d52d88aa-6256-4607-96a2-6ad45e21ea2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "models_predictions",
              "summary": "{\n  \"name\": \"models_predictions\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"what do you think about that ? Should i pay her ? Pay whatever she's minimally entitled to legally but kick her ass to the curb.\",\n          \"and whats new about this. a woman can be total garbage, but as long as she is fuckable she gets something.\",\n          \"Full on crotch grab from Biden. Even the baby's mom isn't holding him that way.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mistralv3_zero_shot_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mistralv3_zero_shot_answers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"NO (The text does not contain sexism)\",\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mistalv3_4_shot\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mistralv3_zero_4_answers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 61,\n        \"samples\": [\n          \"NO\",\n          \"YES (The text contains a racial slur and derogatory language towards a person, which is not specific to gender, but it's important to note that such language is disrespectful and offensive.)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mistalv3_8_shot_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mistralv3_zero_8_answers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"NO (The text does not contain sexism)\",\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mistralv3_12_shot_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mistralv3_12_shot_answers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"NO (The text does not contain sexism)\",\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llama3_zero_shot\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llama3_zero_shot_answers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"YES\",\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llama3_zero_shot_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llama3_4_shot_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llama3_4_shot_answers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llama3_8_shot_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llama3_8_shot_answers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"YES\",\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llama3_12_shot_labels\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llama3_12_shot_answers\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"YES\",\n          \"NO\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models_predictions.to_csv('models_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "7JxrNPr8Ce5m"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Task 6 - 1.0 points] Error Analysis\n",
        "\n",
        "We are now interested in evaluating model responses and comparing their performance.\n",
        "\n",
        "This analysis helps us in understanding\n",
        "\n",
        "- Classification task performance gap: are the models good at this task?\n",
        "- Generation quality: which kind of responses do models generate?\n",
        "- Errors: which kind of mistakes do models do?"
      ],
      "metadata": {
        "id": "XHuT1a1GLJnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "In order to get Task 6 points, we require you to:\n",
        "\n",
        "* Compare classification performance of selected LLMs in a Table.\n",
        "* Compute confusion matrices for selected LLMs.\n",
        "* Briefly summarize your observations on generated responses."
      ],
      "metadata": {
        "id": "7kjEAHD4LJne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "JR-i3l97qJbw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to being able to analyze all the answer given by the LLMs without re running all the answer evaluation we saved all the data inside the `models_predictions.csv` dataset, that can be easily imported using pandas.\n",
        "We are gonna then proceed doing some evaluation of the model, and show what are the most common error and which model is the best performing one  "
      ],
      "metadata": {
        "id": "3GdAQ2CqqXtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_predictions = pd.read_csv('models_predictions.csv')"
      ],
      "metadata": {
        "id": "Ym2OzqLTqWnU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_predictions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "ZlNP3idWsDpl",
        "outputId": "bf9964bd-f037-407f-cac6-da3ca4d1f533"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                 rewire_id  \\\n",
              "0           0  sexism2022_english-17133   \n",
              "1           1  sexism2022_english-14197   \n",
              "2           2   sexism2022_english-3018   \n",
              "3           3   sexism2022_english-5301   \n",
              "4           4  sexism2022_english-17796   \n",
              "\n",
              "                                                text label_sexist  \n",
              "0  The boys must be gaming because there goes the...   not sexist  \n",
              "1  Look at those eyes. Either someone unexpectedl...       sexist  \n",
              "2                  Old man mogs everyone in this sub   not sexist  \n",
              "3  Excellent, I was just looking at another post ...   not sexist  \n",
              "4  So you run back to daddy whenever you need hel...       sexist  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3029f917-dad9-4098-99fc-1d73f2e9b439\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>rewire_id</th>\n",
              "      <th>text</th>\n",
              "      <th>label_sexist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>sexism2022_english-17133</td>\n",
              "      <td>The boys must be gaming because there goes the...</td>\n",
              "      <td>not sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>sexism2022_english-14197</td>\n",
              "      <td>Look at those eyes. Either someone unexpectedl...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>sexism2022_english-3018</td>\n",
              "      <td>Old man mogs everyone in this sub</td>\n",
              "      <td>not sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>sexism2022_english-5301</td>\n",
              "      <td>Excellent, I was just looking at another post ...</td>\n",
              "      <td>not sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>sexism2022_english-17796</td>\n",
              "      <td>So you run back to daddy whenever you need hel...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3029f917-dad9-4098-99fc-1d73f2e9b439')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3029f917-dad9-4098-99fc-1d73f2e9b439 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3029f917-dad9-4098-99fc-1d73f2e9b439');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4a661ab8-a91f-4d84-80e1-fbc163498bf8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a661ab8-a91f-4d84-80e1-fbc163498bf8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4a661ab8-a91f-4d84-80e1-fbc163498bf8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "models_predictions",
              "summary": "{\n  \"name\": \"models_predictions\",\n  \"rows\": 300,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86,\n        \"min\": 0,\n        \"max\": 299,\n        \"num_unique_values\": 300,\n        \"samples\": [\n          203,\n          266,\n          152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rewire_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"sexism2022_english-7642\",\n          \"sexism2022_english-15192\",\n          \"sexism2022_english-18390\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"what do you think about that ? Should i pay her ? Pay whatever she's minimally entitled to legally but kick her ass to the curb.\",\n          \"and whats new about this. a woman can be total garbage, but as long as she is fuckable she gets something.\",\n          \"Full on crotch grab from Biden. Even the baby's mom isn't holding him that way.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label_sexist\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"sexist\",\n          \"not sexist\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nYl-IbolsDIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Task 7 - 1.0 points] Report\n",
        "\n",
        "Wrap up your experiment in a short report (up to 2 pages)."
      ],
      "metadata": {
        "id": "8QWlVXJgLJne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions\n",
        "\n",
        "* Use the NLP course report template.\n",
        "* Summarize each task in the report following the provided template."
      ],
      "metadata": {
        "id": "_fsdV99TLJne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recommendations\n",
        "\n",
        "The report is not a copy-paste of graphs, tables, and command outputs.\n",
        "\n",
        "* Summarize classification performance in Table format.\n",
        "* **Do not** report command outputs or screenshots.\n",
        "* Report learning curves in Figure format.\n",
        "* The error analysis section should summarize your findings."
      ],
      "metadata": {
        "id": "z-hUXYaLLJne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission\n",
        "\n",
        "* **Submit** your report in PDF format.\n",
        "* **Submit** your python notebook.\n",
        "* Make sure your notebook is **well organized**, with no temporary code, commented sections, tests, etc..."
      ],
      "metadata": {
        "id": "fURV8zfPLJne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ\n",
        "\n",
        "Please check this frequently asked questions before contacting us."
      ],
      "metadata": {
        "id": "zn1tUeYzLJne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model cards\n",
        "\n",
        "You can pick any open-source model card you like.\n",
        "\n",
        "We recommend starting from those reported in this assignment."
      ],
      "metadata": {
        "id": "FYAOVGvKhtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation\n",
        "\n",
        "Everything can be done via ``transformers`` APIs.\n",
        "\n",
        "However, you are free to test frameworks, such as [LangChain](https://www.langchain.com/), [LlamaIndex](https://www.llamaindex.ai/) [LitParrot](https://github.com/awesome-software/lit-parrot), provided that you correctly address task instructions."
      ],
      "metadata": {
        "id": "PWG72N-LLJne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bonus Points\n",
        "\n",
        "0.5 bonus points are arbitrarily assigned based on significant contributions such as:\n",
        "\n",
        "- Outstanding error analysis\n",
        "- Masterclass code organization\n",
        "- Suitable extensions\n",
        "- Evaluate A1 dataset and perform comparison\n",
        "\n",
        "Note that bonus points are only assigned if all task points are attributed (i.e., 6/6)."
      ],
      "metadata": {
        "id": "9cplnq3dLJne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Template\n",
        "\n",
        "Do not change the provided prompt template.\n",
        "\n",
        "You are only allowed to change it in case of a possible extension."
      ],
      "metadata": {
        "id": "coy_pJ40LJne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizations\n",
        "\n",
        "Any kind of code optimization (e.g., speedup model inference or reduce computational cost) is more than welcome!"
      ],
      "metadata": {
        "id": "aSiH0Xqj79wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The End"
      ],
      "metadata": {
        "id": "Jpr-LSK7LJnh"
      }
    }
  ]
}